{"posts":[{"title":"周易","text":"周易易德易理易术卦术梅花易数命理学四柱八字紫微斗数风水学三元纳气玄空风水八宅","link":"/2020/06/08/essay/%E5%91%A8%E6%98%93/"},{"title":"国学经典积累","text":"国学经典积累国学通识名言警句[[知者不惑，仁者不忧，勇者不惧]][[无欲则刚]] 风流人物","link":"/2020/06/08/essay/%E5%9B%BD%E5%AD%A6%E7%BB%8F%E5%85%B8%E7%A7%AF%E7%B4%AF/"},{"title":"无欲乃刚","text":"无欲乃刚人生而有欲，天经地义。但只能有正当之欲，且应加以节制。林则徐曾经说过：“海纳百川，有容乃大；壁立千仞，无欲则刚。”林则徐在禁毒时不畏凶险，把一切都置之度外。如果顾虑自己的身家性命，他是不可能完成禁毒大业的。 《史记》上说：“欲而不知止，失其所以欲；有而不知足，失其所以有。”寡欲，才能胸怀宽广、乐观旷达。 春秋时晋国的大夫祁奚，可以称得上无欲则刚的典范。 祁奚，字黄羊，春秋时期晋国大夫，历经晋国景、厉、悼、平四世，可谓四朝元老。悼公继位后，立祁奚为中军尉。平公时，复起为公族大夫。祁奚在位约60年，忠公体国，急公好义，誉满朝野，深受人们爱戴。 祁奚因年事已高，向晋悼公请求告老退休。晋悼公问祁奚：“你退休以后，谁接任你的职务较为合适呢？” 祁奚回答说：“解狐这个人可以。”晋悼公大惑不解，问道：“解狐不是跟你有仇吗？”祁奚说：“君问我谁适合担任中军尉，并非问谁是我的仇人。” 晋悼公正准备立解狐为中军尉，解狐却死了。晋悼公又征求祁奚的意见，祁奚回答说：“祁午可以任中军尉。”晋悼公见祁奚推荐祁午，于是问道：“祁午不是你的儿子吗？”祁奚回答说：“君问谁适合担任中军尉，并非问谁是我的儿子。” 祁奚在推荐继任者的问题上，外举不避仇，内举不避亲，历来为人们所称道。 后来的事实证明，祁奚的举荐确实具有独到的眼光。祁午担任中军尉后，“好学而不戏，守业而不淫，柔惠小物而镇定大事，有质直而无流心”“军无秕政”，的确是中军尉的合格人选。 祁奚以大公无私赢得朝野内外的赞誉，他的言行也随之成为衡量是非曲直的标准。 祁奚退休以后，晋国大臣范宣子审查一个叛乱案件时，抓了一个叫叔向的大臣。叔向的弟弟参与了叛乱，叔向却不是同党。 叔向有可能以叛乱罪问斩，他却一点儿也不畏惧，他说：“祁大夫外举不弃仇，内举不失亲，难道就只不管我的事吗？” 祁奚听说后，就去找范宣子，请求范宣子赦免叔向。他对范宣子说，叔向惠而有谋，是国家栋梁之才，以其弟之故而杀之，是弃国家社稷于不顾，这样做，是非常愚蠢的。范宣子听了祁奚的话，就赦免了叔向。 祁奚见目的已经达成，就准备回去。随从说，你这次专为叔向的事而来，已经办成了，你不去见一下叔向吗？祁奚认为自己救叔向是出于公心而非私谊，所以就没有见叔向而直接回家了。 叔向的一个部下准备去向祁奚道谢，叔向劝他不要去，但那个部下还是执意去了。 祁奚说：“我救叔向，不是为了他那条命，而是为了公家，我无恩于你们，你们也没有必要谢我。” 祁奚正是因为断绝私欲，才能公事公办，成就刚正美名。另一个刚正不阿、光明磊落的例子是大书法家颜真卿。","link":"/2020/06/08/essay/%E6%97%A0%E6%AC%B2%E5%88%99%E5%88%9A/"},{"title":"知者不惑，仁者不忧，勇者不惧","text":"知者不惑，仁者不忧，勇者不惧原文《论语·子罕》：子曰：”知者不惑，仁者不忧，勇者不惧。” 翻译孔子说：“智慧的人不疑惑，仁德的人不忧愁，勇敢的人不畏惧。”意思是说:有仁爱之心的人,不会有忧愁,他会用宽容来对待给他带来忧愁的人和事;有大智大慧的人,遇见有迷惑的事物,不解的地方,他会利用他的聪明才智去求得解决问题的方法;勇敢的人,面对强敌,是不会有所畏惧的,他会义无反顾的去迎接挑战. 典故有一次孔子的弟子司马牛请教如何去做一个君子，孔子回答说：“君子不忧愁，不恐惧”。司马牛不大明白，接着又问：“不忧愁不恐惧，这样就可以称作君子了吗？”孔子的回答是：“内省不疚，夫何忧何惧？”也就是说，如果自己问心无愧，那有什么可以忧愁和恐惧的呢？当然，君子坦荡荡，不仅是一个行为端正的问题，同时也来自于人的内在品德。古人认为，君子有三种基本品德——仁爱、智慧和勇敢。孔子说：“仁者不忧，智者不惑，勇者不惧”，也就是说人如果有着一颗博爱之心，有着高远的人生智慧，有着勇敢坚强的意志，那么他就必然会具有良好的心理和精神状态，从而心底宽广、胸怀坦荡。 解读在儒家传统道德中，智、仁、勇是三个重要的范畴，也是仁之精神境界的不同体现，是君子的基本品质。《礼记·中庸》说：“知、仁、勇，三者天下之达德也。”有智慧的人能将事理看得明白透彻，所以不会迷惑。仁者存公心，去私欲，乐天知命，不患得患失，所以不忧虑。有勇气的人不畏惧困难，见义勇为，所以不惧。 古为今用作为近代中国启蒙思想家、教育家的梁启超，他的九个孩子个个俊秀，皆成大才。关于教育，关于做人，梁先生就很好的践行了孔子的话，他认为“知育要教到人不惑，情育要教到人不忧，意育要教到人不惧。” 下面是梁启超先生于1922年在苏州学生联合会上的讲演部分内容整理所得, 他对于教育的目的、方法做了详细的阐述，他引用孔老夫子说过的“知者不惑，仁者不忧，勇者不惧”，认为教育应分为知育、情育、意育三方面，现在讲的知育、德育、体育不对，德育范围太笼统，体育范围太狭隘。知育要教导人不惑，情育要教导人不忧，意育要教导人不惧。教育家教学生，应该以这三件为究竟。我们自动的自己教育自己，也应该以这三件为究竟。 那么如何做到以上三点？ 首先，怎样才能不惑呢？最要紧的是养成我们的判断力。想要养成判断力︰第一步，最少须有相当的常识﹔进一步，对于自己要做的事须有专门知识﹔再进一步，还须有遇事能判断的智慧。假如一个人连常识都没有了，听见打雷，说是雷公发威﹔看见月蚀，说是蛤蟆贪嘴。那么，一定闹到什么事都没有主意，成了最可怜的人了。学校里小学、中学所教，就是要人有了许多基本的常识，免得凡事都暗中摸索。但仅仅有这点常识还不够。我们做人，总要各有一件专门职业。这职业也并不是我一人破天荒去做，从前已经许多人做过。他们积了无数经验，发现出好些原理、原则，这就是专门学识。我打算做这项职业，就应该有这项专门学识。例如我想做农吗？怎样的改良土壤，怎样的改良种子，怎样的防御水罕、病虫‥‥等等，都是前人经验有得成为学识的。我们有了这种学识，应用他来处置这些事，自然会不惑﹔反是则惑了。教育家、军事家‥‥等等，都各各有他的专门学识，也是如此。我们在高等以上学校所求得的知识，就是这一类。但专靠这种常识和学识就够吗？还不能。宇宙和人生是活的，不是呆的﹔我们每日所碰见的事理，是复杂、变化的，不是单纯的、印板的。倘若我们只是学过这一件才懂这一件，那么，碰著一件没有学过的事来到跟前，便手忙脚乱了。所以还要养成总体的智慧，才能得有根本的判断力。这种总体的智慧如何才能养成呢？第一件，要把我们向来粗浮的脑筋，着实磨练他，叫他变成细密而且踏实﹔那么，无论遇着如何繁难的事，一定可以彻头彻尾想清楚他的条理，自然不至于惑了。第二件，要把我们向来昏浊的脑筋，着实将养他，叫他变成清明﹔那么，一件事理到跟前，我才能很从容、很莹澈的去判断他，自然不至于惑了。以上所说常识、学识和总体智慧，都是知育的要件﹔目的是教人做到“知者不惑”。 其次，怎么样才能不忧呢？为什么仁者便会不忧呢？想明白这个道理，先要知道中国先哲的人生观是怎么样。“仁”之一字，儒家人生观的全体大用都包在里头。“仁”到底是什么，很难用言语来说明。勉强下个解释，可以说是︰“普遍人格之实现。”孔子说︰“仁者，人也。”意思说是人格完成就叫做“仁”。但我们要知道︰人格不是单独一个人可以表见的，要从人和人的关系上看出来。所以“仁”字从二人，郑康成解他做“相人偶”。总而言之，要彼我交感互发，成为一体，然后我的人格才能实现。所以我们若不讲人格主义，那便无话可说﹔讲到这个主义，当然归宿到普遍人格。换句话说，宇宙即是人生，人生即是宇宙，我的人格和宇宙无二无别。体验得这个道理，就叫做“仁者”。然则这种“仁者”为什么会不忧呢？大凡忧之所从来，不外两端︰一曰忧成败，一曰忧得失。我们得着“仁”的人生观，就不会忧成败。为什么呢？因为我们知道，宇宙和人生是永远不会圆满的，所以易经六十四卦，始“乾”而终于“未济”﹔正为在这永远不圆满的宇宙中，才永远容得我们创造进化。我们所做的事，不过在宇宙进化几万里的长途中，往前挪一寸两寸，那里配说成功呢？然则不做怎么样？不做便连一寸两寸都不往前挪，那可真失败了。“仁者”看透这种道理，信得过只有不做事才算失败，凡做事便不会失败﹔所以易经说︰“君子以自强不息。”换一方面来看，他们又信得过凡事不会成功的﹔几万里路挪了一两寸，算成功吗？所以论语说︰“知其不可而为之。”你想︰有这种人生观的人，还有什么成败可说呢？ 再者，我们得着“仁”的人生观，便不会忧得失。为什么呢？因为认定这件东西是我的，才有得失之可言。连人格都不是单独存在，不能明确的画出这一部分是我的，那一部分是人家的，然则那里有东西可以为我所得？既已没有东西为我所得，当然亦没有东西为我所失。我只是为学问而学问，为劳动而劳动，并不是拿学问劳动等等做手段来达某种目的— 可以为我们“所得”的。所以老子说︰“生而不有，为而不持。”“既以为人，己愈有﹔既以与人，己愈多。”你想︰有这种人生观的人，还有什么得失可忧呢？总而言之，有了这种人生观，自然会觉得“天地与我并生，而万物与我为一”﹔自然会“无入而不自得。”他的生活，纯然是趣味化、艺术化。这是最高的情感教育，目的是教人做到“仁者不忧”。 怎么样才能不惧呢？有了不惑、不忧功夫，惧当然会减少许多了。但这是属于意志方面的事。一个人若是意志力薄弱，便有很丰富的知识，临时也会用不着，便有很优美的情操，临时也会变了卦。然则意志怎样才会坚强呢？头一件须要心地光明。孟子曰︰“浩然之气，至大至刚。” “行有不慊之心，则馁矣。” 曾子曰︰“自反而不缩，虽褐寛博，吾不惴焉？自反而缩，虽千万人，吾往矣。”（曾子说：自我反省，觉得是我理屈，即使对方是穿粗衣的卑贱之人，我也不会吓唬他。自我反省，觉得理直，即使对方有千万人之众，我一定要前去和他们论个是非曲直。）俗词说得好︰“生平不作亏心事，夜半敲门也不惊。”一个人要保持勇气，须要从一切行为可以公开做起，这是第一著。第二件要不为劣等欲望所牵制。论语说︰“子曰︰‘吾未见刚者。’或对曰︰‘申枨（cheng，孔子的弟子）。’子曰︰‘枨也欲，焉得刚？’”，翻译过来就是孔子说：“我没有见过刚毅不屈的人。”有人回答说：“申枨是这样的人。”孔子说：“申枨啊，他的欲望太多，怎么能刚毅不屈？”。被物质上无聊的嗜欲东拉西扯，那么，百链钢也会变为绕指柔了。总之，一个人的意志，由刚强变为薄弱极易，由薄弱返到刚强极难。一个人有了意志薄弱的毛病，这个人可就完了。自己作不起自己的主，还有什么事可做！受别人压制，做别人奴隶，自己只要肯奋斗，终能恢复自由。自己的意志做了自己嗜欲的奴隶，那么，真是万劫沉沦，永无恢复的余地，终身畏首畏尾，成了个可怜人了。孔子说︰“和而不流，强哉矫﹔中立而不倚，强哉矫﹔国有道，不变塞焉，强哉矫﹔国无道，至死不变，强哉矫。”我老实告诉诸君吧，做人不做到如此，决不会成一个人。但是做到如此真是不容易，非时时刻刻做磨练意志的工夫不可。意志磨练得到家，自然是看着自己应做的事，一点不迟疑，扛起来便做，“虽千万人吾往矣”。这样才算顶天立地做一世人，绝不会有藏头露尾、左支右绌chu的丑态。这便是意育的目的，要人做到“勇者不惧”。","link":"/2020/06/08/essay/%E7%9F%A5%E8%80%85%E4%B8%8D%E6%83%91%EF%BC%8C%E4%BB%81%E8%80%85%E4%B8%8D%E5%BF%A7%EF%BC%8C%E5%8B%87%E8%80%85%E4%B8%8D%E6%83%A7/"},{"title":"为什么要写卡片","text":"为什么要写卡片from: Day2—《用卡片实现善思会写》听课链接：https://jcg.h5.xeknow.com/s/HzDLj听课密码：1210 核心概念 存入越难提取越容易 卡片即知识，卡片即知识管理，卡片即写作 方便写作， 写作就是：话题、逻辑、卡片 定期按照标签进行复习，产生新的链接，进而丰富了自己的知识体系 ![[Pasted image 20231022151242.png]] ![[Pasted image 20231022152923.png]] ![[Pasted image 20231022153917.png]] 个人体会 如何更容易的提取知识才是难点 行动指引 当需要写作时可以利用卡片进行填充 ![[Pasted image 20231022154316.png]]","link":"/2020/06/08/softskills/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%86%99%E5%8D%A1%E7%89%87/"},{"title":"为什么要读经典","text":"为什么要读经典from: Day3—《我们为什么读经典》听课链接：https://jcg.h5.xeknow.com/s/i5V0J听课密码：1210date: 2023-10-22 15:55 核心概念 书籍分三类： 感受性读书，陶冶情操类：比如边城，无需共读，个人体验，放松的读就可以，不用逼自己，这些书籍是给你的知识体系增加底色的。 经典书，架构性读书，适合用卡片：这类书籍像是你知识体系当中的大节点，链接了很多东西，打个比喻，普通知识是葡萄，而他是葡萄藤，可能不一定提供新的知识给你，但是他帮你搭建起知识体系，可以把你已有的知识串联、升华，让你在更高的纬度去理解过往的经验和知识，常看常新， 技能工具类：这类书籍根据实际需要去读就好，属于功利性读书、增量型读书。 如何判断是否是经典呢： 能提高知识维度，能够串联起一堆书，比如《动机心理学》《穷查理宝典》 一个行业或领域的起源之作，比如《卓有成效的管理者》《反脆弱》《物种起源》，这类书籍诞生于行业之初，具有通识性，大家之作，反而在后来领域细分之后再难有此大家 另一个世界，但具有同构性，比如《邓小平传》《心若菩提》。虽然可能和我们的生活离得很远，但是却有共鸣，能让你从中反省自己的生活，提升自己的心性。 知识的周期![[Pasted image 20231022160819.png]] 知识工作者的全套手艺 选书 内化 输出： 知识体系：建立自己的知识库 写作：变现 -![[Pasted image 20231022161122.png]] 个人体会 我有一个经验、体验、感悟、发现 行动指引 当。。。时候，要。。做 1.你觉得接下来应该读哪些书？ 书籍应该分为三类 工具类：我理解为“长本事的书”：它往往可以具体解决我们当下遇到的问题和困惑，带着功利性读书可以快速扩张我们的知识增量，给我们现成的好用的工具和方法。 经典性：我理解为“长知识的书”，它提供完整的知识架构，扩充知识边界且自带体系，提高知识维度串联性很强，填补我们知识体系中的空白和缺失。比如理论、教材、科学、哲学类的书籍。 陶冶性：我理解为“长见识的书”，它是一种解离体验型，我们可以进入到作者的视角去体验他人的生活和经历，它可以提供给我们知识底色，让我们体验不一样的人生，比如传记、回忆录，历史等。 2.你觉得选书和掌握一套善思会写的方法哪个更帮到你？为什么？ 1) 善思会写是一种方法论，它是把输入的信息和内容经过内化加工后，转化成输出的外化过程。 2) 通过产出知识卡片，形成无数个锚点，把自己和书籍链接起来，把自己与他人的进行链接。 3) 通过知识卡片交朋友、读精典，与巨人对话，实现脑机连接与共振，它是由内循环（自读苦修）向外循环（分享与交流）的转化，也是把外界能量反向输入给自己的一种路径。 4) 通过选书、内化、输出、知识体系、写作，做知识的创造者，而不是知识的工作者","link":"/2020/06/08/softskills/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AF%BB%E7%BB%8F%E5%85%B8/"},{"title":"什么是读书卡片","text":"什么是读书卡片from: 古典少侠 Day2—《用卡片实现善思会写》听课链接：https://jcg.h5.xeknow.com/s/HzDLj听课密码：1210 核心概念 卡片是知识理解的最小单元 是用自己的过往的生活体验去理解知识，与自己的生活进行关联，用自己的话来整理和存储知识，方便后续的提取和使用。 卡片不是复制粘贴 卡片不应该太长，应该是一个独立的概念，字数控制在100-500之间。 ![[Pasted image 20231022154143.png]] 个人体会行动指引 积累知识卡片 用卡片+标签搭建自己的知识体系。","link":"/2020/06/08/softskills/%E4%BB%80%E4%B9%88%E6%98%AF%E8%AF%BB%E4%B9%A6%E5%8D%A1%E7%89%87/"},{"title":"如何写卡片","text":"如何写卡片from: Day2—《用卡片实现善思会写》听课链接：https://jcg.h5.xeknow.com/s/HzDLj听课密码：1210 核心概念 格式：核心概念+个人体会+行动指引 勾连个人体验，有情绪更好 行动指引 一张卡片一个概念 100-500字即可。 一周有3-6张即可，一本书有10-15个卡片就不错 个人体会 以前虽然也会去记录一些知识点，但是没有清晰的格式，有时还是简单的复制粘贴，用的时候就记不起来了。 没有把个人体验和行动指引清晰的写出来，导致理解的不够深刻，知识没有用起来。 行动指引 当读到有感触的文章时可以写一篇卡片 不要太长，别顺着思路王霞溜，围绕单一概念 准备写作时可以先搜集相关的概念和知识汇集成一堆卡片，以备写作时使用。","link":"/2023/06/08/softskills/%E5%A6%82%E4%BD%95%E5%86%99%E5%8D%A1%E7%89%87/"},{"title":"金字塔思维","text":"金字塔思维为什么选金字塔 它符合人类思维基本规律 1 序言结构的体现 拉平与听众的认识 让听众有兴趣，从已知到未知 2 纵向结构的体现 能理解 自然的疑问，回答式反应 2 横向结构的体现 记得住 分类更容易记得住 结构检查表1 结论先行（用TOPS法则来检查，只有一个，结论应该是解决某个原因，而不应是一个现象2 上下对应（每一层次的概念都应该是对下一层思想观点的概括）3 分类清楚（归纳-并（独立，完整）， 演绎-串（p2p还可以，一断全断））每一组的观点都应该是属于同一个范畴4 排序逻辑（有逻辑顺序）5 最后写序言（SCQ）情景-冲突-问题，最后写更容易对全局把握的更好，更容易出采清晰的表达的下一步是说服","link":"/2020/06/08/softskills/%E9%87%91%E5%AD%90%E5%A1%94%E6%80%9D%E7%BB%B4%20/"},{"title":"CentOS7 安装Python3","text":"CentOS7 安装Python3 本文主要介绍在CentOS7上通过源码编译的方式案头Python3, 文中用到的是CentOS7.2, Python版本是3.6.7,其他类似版本的处理也是大致相同的. 在安装Python3之前需要解决两个问题： 一是 开发环境安装，比如gcc等 二是 openssl的安装， 因为CentOS自带的openssl版本比较低，导致Python3安装完后，在python命令行中执行import ssl会报错：ImportError: No module named _ssl。 特别是第二个ssl错误，相信很多人都遇到过，我自己也在这个问题上纠缠了很长时间， 现在将亲测有效的解决方案分享给大家。 1.安装开发环境依赖123sudo yum -y groupinstall developmentsudo yum -y install zlib-develsudo yum -y install libffi-devel 2.更新openssl先通过命令看看筷的openssl版本，如果返回是0.9.x， 那肯定需要升级了 1openssl version 按照如下方式升级openssl 1234567wget http://www.openssl.org/source/openssl-1.0.2e.tar.gztar xvzf openssl-1.0.2e.tar.gzcd openssl-1.0.2e./config --prefix=/usr/local/openssl --openssldir=/usr/local/opensslmakemake testmake install 到这openssl安装完成了， 接下来可以开始编译安装Python3了， 注意我们指定的openssl安装路径是在/usr/local/openssl， 这个后面要用到。 3.安装Python3 先下载解压Python3.6.7安装包 123wget https://www.python.org/ftp/python/3.6.7/Python-3.6.7.tgztar xvzf Python-3.6.7.tgzcd Python-3.6.7 然后修改Setup.dist, 指定ssl位置 1vi Modules/Setup.dist 搜索ssl, 取消以下几行注释， 并且修改SSL的值为我们实际安装openssl的值， 即：/usr/local/openssl 12345678_socket socketmodule.c# Socket module helper for SSL support; you must comment out the other# socket line above, and possibly edit the SSL variable:SSL=/usr/local/openssl_ssl _ssl.c \\ -DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\ -L$(SSL)/lib -lssl -lcrypto 注： 网上很多说在./configure 后面加–with-openssl的方法来指定openssl的方法自测无效， 通过修改Setup.dist方才生效。 完成以上修改后，即可开始编译Python3, 命令如下。 123./configuremakemake install 4.验证Python312python3import ssl 正常不会报错， 则Python3安装成功。另外，给大家推荐一个Python虚拟环境的包pipenv, 强大又好用， 大家可以试试。 1python3 -m pip install pipenv 至此，CentOS7上安装Python3完毕。这个是我参考的文章，感谢前人的分享！How to Compile and Install Python with OpenSSL Support?","link":"/2020/06/08/technology/201904_CentOS7%20%E5%AE%89%E8%A3%85Python3/"},{"title":"GIT修炼","text":"GIT修炼git 删除分支 切换到要操作的项目文件夹命令行: $ cd 查看项目的分支们(包括本地和远程) … 删除本地分支命令行: $ git branch -d 删除远程分支命令行: $ git push origin –delete git分支重命名1. 本地分支重命名(还没有推送到远程) 1git branch -m oldName newName 2. 远程分支重命名 (已经推送远程-假设本地分支和远程对应分支名称相同) a. 重命名远程分支对应的本地分支 1git branch -m oldName newName b. 删除远程分支 1git push --delete origin oldName c. 上传新命名的本地分支 1git push origin newName d.把修改后的本地分支与远程分支关联 1git branch --set-upstream-to origin/newName git回滚代码只commit并未push的代码回滚 1234567891011git reset --hard &lt;版本号&gt;或git reset --soft HEAD~1撤销最近一次的commit(撤销commit，不撤销git add)git reset --mixed HEAD~1撤销最近一次的commit(撤销commit，撤销git add)git reset --hard HEAD~1 撤销最近一次的commit(撤销commit，撤销git add，工作区的代码改动将丢失。操作完成后回到上一次commit状态) 如果已经push: 12执行完上面的rest之后再继续git push origin &lt;分支名&gt; --force // 需要有force权限 git 放弃本地修改1git checkout . &amp;&amp; git clean -xdf 修改最后一次commits ,已经push过的1git commit --amend git 撤回commit写完代码后，我们一般这样 git add . //添加所有文件 git commit -m “本功能全部完成” 执行完commit后，想撤回commit，怎么办？ 这样凉拌： git reset –hard HEAD 这样就成功的撤销了你的commit 注意，仅仅是撤回commit操作，您写的代码仍然保留。 说一下个人理解：HEAD^的意思是上一个版本，也可以写成HEAD~1 如果你进行了2次commit，想都撤回，可以使用HEAD~2 至于这几个参数： –mixed 意思是：不删除工作空间改动代码，撤销commit，并且撤销git add . 操作 这个为默认参数,git reset –mixed HEAD^ 和 git reset HEAD^ 效果是一样的。 –soft 不删除工作空间改动代码，撤销commit，不撤销git add . –hard 删除工作空间改动代码，撤销commit，撤销git add . 注意完成这个操作后，就恢复到了上一次的commit状态。 顺便说一下，如果commit注释写错了，只是想改一下注释，只需要：git commit –amend 此时会进入默认vim编辑器，修改注释完毕后保存就好了。 git 回退本地修改Git checkout . &amp;&amp; git clean -xdf git reset -soft HEAD^ 忽略本地所有，和远程分支保持一致git reset –hard origin/dev/internal_ipv6","link":"/2021/04/08/technology/GIT%E4%BF%AE%E7%82%BC/"},{"title":"Linux系统管理常用命令","text":"Linux系统管理常用命令1 文件管理识别文件类型 ls 文件类开：d:目录文件，l： 链接文件， b: 块设备文件， -: 普通文件 -l 列表显示 ls -lt/-lrt # 按时间排序或倒序 ll | grep ^d 显示所有文件夹 -a 显示包含隐藏 列出目录结构 tree目录结构 Linux树状目录结构，最上层目录为根目录 / 一切皆文件 vi 和 vim区别 vi 是内置的 ， vim 算是增强版 i I , a A , o O , r R :set nu 输入行数，shift+g gg, GG 3yy, 3dd, u, x pwdls -a 显示包含隐藏 -l 列表显示 cd cd ~/ cd ; —–切到当前用户目录 使用绝对或相对路径 cd .. 上一级 mkdir 默认只能创建一级 -p 一次性创建多级 文件权限修改 chmod rwx 421 chmod +x *.sh chmod -R 777 /tmp/test/ 注：-R参数递归所有子目录，给所有文件加了 777权限 修改文件或目录的归属信息 chown chown zhangsan 123.txt # 把123.txt归属到zhangsan名下 chown zhangsan:group_name 123.txt # 把123.txt归属到zhangsan名下 查看文件状态 stat stat 123.txt 设置默认文件、目录权限 umask 文件 666-umask 目录 777-umask 打开文件的几种方式cat 从首至尾的顺序打印, 只能看不能改 -n 显示行号 -A 显示尾部隐藏符号，经常windows上的文件在linux环境无法使用问题查看 cat 有连接功能，可以一次打开多个文件，比如cat 1.txt 2.txt | more 分页显示， 按空格翻到下一页 tac 反序打印出来more 以全屏按页显示文件打 b, f 上下翻屏 空格 翻页， 回车，换行， ctrl+b, ctrl+f 上一屏，下一屏， q 离开 less 按页显示，一页页加载，对于查看大文件，效率高 pageUp, pageDown翻页 head 显示文件前面的内容,默认前 10 行 默认打印前十行 可以和其他命令组合，比如： netstat -tunp | head tail **tail -f 实时查看文件的更新， 很有用， 比如日志追踪 ** tail 显示文件最后面的内容,默认最后 10 行 默认打印最后十行 tail -100 a.txt ** tail -f 实时查看文件的更新， 很有用， 比如日志追踪 ** &gt; 重定向， &gt;&gt; 追加 ‘&gt;’ 重定向，会覆盖原有文件 ，不存在则创建 ‘&gt;&gt;’ 追加， 不会覆盖原有文件 ， echo “afsafasf” &gt;&gt; file echo 输出内容到控制台 输出环境变量 输出简单文件 head 显示文件前面的内容,默认前 10 行 head -n 5 显示前5行 paste 两个文件按列合并ln 符号链接 ln -s [source] [dest] rmdir 删除空目录rm -rf 目录下有文件一起删除touch ab.txt 创建一个空文件 可以一次性创建多个空文件， touch a.txt b.txt cp 拷贝文件 cp [option] source dest cp -r 递归目录下所有文件 **\\cp 强制覆盖 ** rm -r 递归 -f 强制 mv 移动文件或目录，或重命名 mv source target 文件搜索find find [搜索范围] [选项] find -name , find /home -name hello.txt find -user , find / -user nobody find -size, find /home -size +20M, 在home目录下，查找超过 20m 的文件, k小写 locate 快速定位文件路径 ，通过查库，所以快 第一次使用，需要 updatedb 创建locate数据库 grep 和 | grep 过滤 | 管道符，将前一命令的结果交给下一命令执行 grep [option] 查找内容 源文件 -n显示出行号， -i 不管大小写 cat abc.txt | grep -i yes 压缩和解压缩gzip, gunzip gzip 压缩后不会保留原来的文件 zip, unzip zip [option] xxx.zip [source]， -r 递归目录 , zip -r dog.zip dog/ unzip [option] xx.zip, -d 指定解压后的存方目录 , unzip -d dog1/ dog.zip tar 打包指令 x.tar.gz c, v, f, z, x tar -zcfv abcd.tar.gz ab.txt cd.txt 打包 tar -zcfv abcd.tar.gz /home tar -zxvf abcd.tar.gz 解压到当前目录 tar -zxvf abcd.tar.gz -C /myhome/ 指定解压到某一目录，这个目录必须存在 2 用户管理用户 Id 加用户名，查看用户信息 切换用户 su 用户名 useradd username -g 指定组 Passwd username 用户组 Whoami Groupadd groupdel 修改用户组 usermod -g 用户信息相关的文件 Etc/group etc/shadow 用户切换及信息查看 su - zhangsan 切换用户 sudo su 切换到root cat /etc/passwd | grep zhangsan 查看当前系统下某用用户信息 id zhangsan 查看账户信息 whoami 查看当前用户 新增用户 useradd d 指定用户目录, useradd -d /data/123 zhangsan, g 指定所属主组, u 指定uid, 场景：通过uid筛选用户 删除用户 userdel r 删除用户及其家目录, userdel -rf zhangsan f 强制删除用户，即使该用户下存在运行中的进程 logout 退出当前用户 更改密码 passwd /etc/passwd 查看当前系统下怕有用户 passwd zhangsan # 这是在root下修改任一用户密码，root下可能修改任何用户密码 ， 且不需要验证原密码，也没有密码复杂度的要求 passwd 直接修改当前用户密码 更改用户信息 usermod usermod -g 修改组 shadow 文件 cat /etc/shadow # 只有root有权查看，存放有加密后的密码 chage -l zhangsan 查看用户密码修改信息 3 网络管理查看本地ip信息 ifconfig 或 ip address查看本地路由信息 route -n flag: UG才能访问外网 traceroute www.baidu.com 查看网络访问跳转过程 cat /etc/resolv.conf 查看DNSethtool eth1 查看网卡信息网络诊断 ping, traceroute ping dest-ip traceroute dest-ip 查看网络连接状态 netstat netstat (-tunlp or -tunp) 查看本机端口占用情况 netstat -ano netstat -ano | grep 800 查看文件被占用的情况 lsof lsof -c mysql 查看以关键字开头的进程占用的文件信息 lsof -i tcp 列出所有tcp 网络连接信息 lsof -i :3306 列出谁在使用某个端口 lsof -a -u test -i 列出某个用户的所有活跃的网络端口 抓包 tcpdump tcpdump -nn -i eth0 dst 61.135.169.121 and port 8080 linux防火墙 iptables iptables -nvl dig 查看域名的DNS dig baidu.com 网络问题排查 系统环境： uname -a, free -m , top 查系统版本，内存、cpu使用情况 系统log：dmesg; /var/log/messages， 有没有error, failed,bug 日志 netstate 统计，tcpdump抓包， 是否有丢包，重传 网卡信息：lspci | grep Eth; ethtool 确定网卡类型 4 磁盘管理查看磁盘分区 lsblk or df lsblk 包括未挂载，未格式化，未分区的磁盘也能显示出来，包括插入的u盘等 df 只显示所有已经分区的磁盘 硬盘分区 fdisk fdisk dev/vdb 挂载 mount mount /dev/vdc1 /mountpointA 持久化挂载：在/etc/rc.local 中加入上述命令 找出哪些文件占空间多 du du -xks * | sort -rn | head -20 du -sh xxxxx 显示某个文件或目录的大小 5 系统运行情况查看Linux内核版本 cat /proc/version uname -a CPU lscpu /proc/cpuinfo top sar -u -P ALL 1 # 查询CPU历史情况 内存 free /proc/meminfo sar -r 1 # 监控每一秒的内存情况 硬盘 iostat -xm -1 # 看io繁忙情况 iotop # 查看哪些进程产生大IO du # 查看有哪些目录 sar -d 1 网络 sar -n DEV 1 # 监控每秒网络流量 安全 cat /var/log/secure # 看看谁登录过这台机器 w # 看当前被谁登录 last # 看所有登录信息, su zhangsan, cat ~/.bash_history 看最近执行的命令 last rebot / uptime # 查看机器启动时间 ps xf ps -eo pid,lstart | grep xxpid # 查看某进程的启动时间 lsof | grep xxx # 哪个文件被打开了 ll /proc/xxpid 查看进程的启动命令, 目录, 可执行文件位置等 6 正则表达式与文本处理正则表达式文本处理 sed (按行处理器) 打印指定范围的行 sed -n ‘10, 20 p’ test.txt 打印包括指定关键字（范围）的行： sed -n ‘/2014/, /2018/ p’ test.txt 匹配到关键字的行并做整行替换：sed ‘/running/ c\\ ‘stop’’ test.txt 删除包含指定关键字的行 sed ‘/running/ d’ test.txt 删除指定范围的行 sed ‘1, 100 d’ test.txt , 注：加上-i参数后才会真正修改这个文件，否则只是在内存中修改 在文件中查找 grep grep keyword test.txt | tail/head/… grep -B/A/C 10 keyword test.txt # 查看关键字上/下/上下 10行的信息 grep -nr keword xxx.log | wc -l 统计某关键字在某类文件里出现的次数 拆字段 awk cat /etc/passwd | awk -F: ‘{print $1, $3, $5, $NF}’ 按冒号分割每一行，并打印出分割后的第 1,3, 5和最后一列 cat /etc/passwd | awk -F: ‘$3&gt;100 {print $1, $3}’ # 加条件，第三列大于100 $0 所有列 NF 最后一列索引 $NF 最后一列值 7 VIMvim 有四个模式 正常模式 (Normal-mode), 默认模式， 进入按esc, 如果在命令模式下需要按两次 插入模式 (Insert-mode), 在正常模式中按下个别字母键（后面会详细介绍），会进入插入，比如i 命令模式 (Command-mode), 在正常模式中，按下：（冒号）键或者/ （撇号），会进入命令模式。在命令模式中可以执行一些输入并执行一些 VIM 或插件提供的指令，就像在shell里一样。这些指令包括设置环境、文件操作、调用某个功能等等 可视模式 (Visual-mode), 在正常模式下，进入用v/V/Ctrl+v， 可视模式中的操作有点像拿鼠标进行操作，选择文本的时候有一种鼠标选择的即视感，有时候会很方便 vim一次打开多个文件 vim a.txt b.txt 按下键盘上的冒号 ：这时会在显示屏底部出现冒号 ：（进入了 VIM 的命令模式），然后在输入 ls 屏幕上会出现打开的所有文件的序号和文件名，我们继续输入冒号 ： ，然后输入 bn (这里的 n需要做一个解释并不是键盘上的 n ,而是文件序号的代指，如 b1 代表显示屏上切换到第一个文件，b2 代表显示屏上切换到第二个文件 vim -On file1 file2 … filen 左右分屏 vim -on file1 file2 … filen 上下分屏 vim 退出 :w 保存当前对文件的修改，但是不退出文件。 :w! 强制保存但是不退出文件。 :w file 保存当前的文件修改到 file 文件当中。 :q! 退出文件，对文件的修改不做保存。 :qa! 退出所有的文件，对所有的文件修改都不做保存 :wq 退出文件并保存对文件的修改 :x 退出文件并保存对文件的修改 :e 打开另一个文件 :e! 放弃对文件的所有修改，恢复文件到上次保存的位置。 :saveas file 另存为 file :bn 和 :bp 当打开多个文件的时候可以输入 :bn 和 :bp 进行上一个文件或者下一个文件的切换。 vim编辑模式 i是在光标所在的字符之前插入需要录入的文本。 I 是在光标所在行的行首插入需要录入的文本。 a 是在光标所在的字符之后插入需要录入的文本。 A 是在光标所在行的行尾插入需要录入的文本。 o 是光标所在行的下一行行首插入需要录入的文本。 O 是光标所在行的上一行行首插入需要录入的文本。 s 删除光标所在处的字符然后插入需要录入的文本。 S 删除光标所在行，在当前行的行首开始插入需要录入的文本。 cw ，删除从光标处开始到该单词结束的所有字符，然后插入需要录入的文本（这个命令是两个字符的合体 cw ）。 vim命令模式 :set nu 该命令会显示行号。 :set nonu 该命令会取消行号。 :n 定位到 n 行。 /{目标字符串} 查找文本中匹配的目标字符串，查到以后，输入键盘上的 n 会去寻找下一个匹配，N 会去寻找上一个匹配。 :set ic 编辑器将不会区分大小写,如果你进行该设置之后，进行关键字查询如 /zempty 如果文本中有 Zempty ,zEmpty,….,只要是字符相同不会区分大小写都会进行匹配。 :set noic 区分大小写的查询 :n1,n2d 删除多行文本，n1 和 n2 指的是起始行号和结束行号，d 是删除关键字 :s/old/new/g 将会把当前光标所在行的 old 替换成 new :%s/zempty/handsome/gi 将会把全文中的 old 替换成 new :n1,n2s/zempty/handsome/gIc 这里的 n1 和 n2 值得是行号，将会替换掉 n1 到 n2 的所有old 替换为 new. 注：最后的g代表global即全局替换，如果去掉则只替换掉第一次出现的。i/I分别代表大小写不敏感和大小写敏感。c代表是否需要确认 。 :!command VIM 执行 Linux 命令, : 后面紧跟着 ! ，! 后面紧跟着 linux 命令（ command 指操作 Linux 系统的一系列命令，如创建文件，新建文件夹，查询文件的属性的等）， 如:!date :r !command VIM 执行命令，并且添加结果至操作文本光标处 VIM 的正常模式（Normal-model) 快速移动光标：请记住这几个快捷键 h,j,k,l 这几个按键主要是用来快速移动光标的，h 是向左移动光标，l 是向右移动光标，j 是向下移动光标，k 是向上移动光标，h , j , k ,l 在主键盘区完全可以取代键盘上的 ↑ ,↓ ,← , → 的功能。 0 移动到行头 ^ 移动到本行的第一个不是 blank 字符 $ 移动到行尾 fa 移动到本行下一个为 a 的字符处，fb 移动到下一个为 b 的字符处 Fa 同 fa 一样，光标移动方向同 fa 相反 w 光标移动到下一个单词的开头 e 光标移动到下一个单词的结尾 ; 和, 当使用 f, F, t ,T, 关键字指定字符跳转的时候，使用 ；可以快速跳转到写一个指定的字符，, 是跳到前一个指定的字符 nG 光标定位到第 n 行的行首 gg 光标定位到第一行的行首 G 光标定位到最后一行的行首 H 光标定位到当前屏幕的第一行行首 M ML光标移动到当前屏幕的中间 L 光标移动到当前屏幕的尾部 ctrl+f 查看下一页内容 ctrl+b 查看上一页内容 VIM 的复制，黏贴 ，删除** d 是删除的意思，通常搭配一个字符 ( 删除范围 ) 实现删除功能，常用的如下：** dw 删除一个单词 dnw 删除 n 个单词， dfa 删除光标处到下一个 a 的字符处（ fa 定位光标到 a 处 ） dnfa 删除光标处到第 n 个 a 的字符处 dd 删除一整行 x 删除一个字符 ndd 删除光标处开始的 n 行 – dG一直删除到文件末尾，gg,dG删除整个文件内容 d$ 删除光标到本行的结尾 dH 删除屏幕显示的第一行文本到光标所在的行 dG 删除光标所在行到文本的结束** y 是复制的意思，通常搭配一个字符（复制范围）实现复制的功能，常用的如下：** yw 复制一个单词，还有 ynw yfa 复制光标到下一个 a 的字符处,还有ynfa yy 复制一行，还有 nyy y$ 复制光标到本号的结尾 yH 复制屏幕显示的第一行文本到光标所在的行 yG 复制光标所在行到文本的结束** p, P是黏贴的意思，当执行完复制或者黏贴的命令以后，VIM 会把文本寄存起来** p 在光标后开始粘贴 P 大写的 P 光标前开始粘贴 撤销操作和恢复 u 撤销刚才的操作 ctrl + r 恢复撤销操作 删除字符操作和替换 x 删除光标当前所在的字符 r 替换掉光标当前所在的字符 R 替换掉从光标开始以后的所有字符，除非 退出 大小写转换 ~ 将光标下的字母改变大小写 3~ 将光标位置开始的3个字母改变其大小写 g~~ 改变当前行字母的大小写 gUU 将当前行的字母改成大写 guu 将当前行的字母全改成小写 VIM 的重复命令 . 该命令是重复上一个操作的命令 n重复某个命令 n 次， 如 10p复制 10 次，10dd 删除十次。 VIM可视化 v 字符可视化 V 行可视化 Ctrl+v 块状可视化 可视化模式下操作文本可视化模式下选择操作区域以后： 按下 d会删除选择的区域， 按下 y 会复制选择的区域， 按下 p 会黏贴选择的区域 VIM 的代码提示功能 在编辑模式下 ，快捷键 Ctrl+n 或者 Ctrl+p 会有代码提示功能，我们可以实现快速录入的效果。 8 搭配管道使用的工具最通俗常用的grep 可搭配正则 cat test.txt | grep keyword wc 统计文本行数 cat test.txt | wc -l # 查看行数 wc -l test.txgt cut 类似awk的拆分功能sort 排序 netstat -tunp | sort -rn -k3 # 按第三列倒序排 uniq 去重 cat test | sort | uniq tee 既输入到屏幕又保存到文件 ls -al /home | tee result tr 替换 cat a.log | tr -s ‘c’ ‘C’ # 把小c换成大C cat a.log | tr -s ‘\\n’ ‘ ‘ # 去掉换行变空格 tr -d ‘abc’ a.log # 删除abc xargs cat a.log | xargs # 竖的变横的 9 安装包管理RPM redhat package manager rpm -qa | grep firefox 查询是否安装了某个包 rpm -qi python 查询安装的某个饭的信息 rpm -ql python 查看安装包安装了哪些文件 rpm -qf /etc/passwd 查询某个文件属于哪个安装包 rpm -e firefox 删除 rpm包， –nodeps 强制删除 rpm -i firefox的安装路径， 安装某个安装包 -h 进度条， -v 提示 , rpm -ivh 安装包路径 Yum 是一个shell 前端包管理器 基于rpm，能够从指定的服务器自动下载 rpm 安装包 ， 可以自动处理依赖关系 一次安装所有依赖的软件包 Yum 的基本指令 yum list | grep firefox 查询服务器上是否有需要的安装包 yum install firefox 安装某个指定的包 , 默认会安装最新版本 10 其他运维命令显示历史执行过的命令 history c 清除历史命令 显示最近的 10 个 history 10 ! num, 执行编号为 num的指令 压缩与解压缩 tar 压缩： tar czf test.tar.gz /data/test 解压：tar xf test.tar.gz 查看但不解压： tar tvf test.tar.gz 脚本执行 用expect 编写自动化脚本以提高效率，典型的场景比如登录, 用alias 给常用的执行命令加上别名，方便快捷 Shell提供了一些用于调试脚本的选项： -n，读一遍脚本中的命令但不执行，用于检查脚本中的语法错误。bash/sh -n xxx.sh # 检测脚本语法错误 -v，一边执行脚本，一边将执行过的脚本命令打印到标准错误输出。 -x，提供跟踪执行信息，将执行的每一条命令和结果依次打印出来。 用curl下载ftp文件 curl ftp://a.b.c.d/test.zip -u name:passwd -O # -O保留原来的文件名，-o:自定义文件名 列出本机监控端口及服务, 包括正在listen的, netstat -tunlp netstat -tunlp 列出本机所有连接，不包括本地监听端口 netstat -tunp netstat -tunp 命令置于后台 nohup &amp; nohup /bin/bash /data/test.sh &amp; screen 生成一个指定大小的文件 dd dd if=/dev/zero of=/data/matt/2G bs=1M count=2048 # if指定生成器，of指定文件名 time 统计命令执行花费的时间 time netstat -tunp 获取本机ip ifconfig | grep inet[^6] | grep -v 127.0.0.1 | awk ‘{print $2}’ | cut -d’:’ -f2 移动行光标, 特别在敲长命令时 ctrl a/e 首：Ctrl+a 末：Ctrl+e 历史命令快速查找 Ctrl r Ctrl + r 输入关键字后开始查找，按ctrl+r继续向前查找，如果找到，按下箭头确认 ！在shell中的应用 !^ 表示上一个成功执行的命令的第一个参数 !$ 表示上一个成功执行的命令的最后一个参数 !* 表示上一个成功执行的命令的所有参数， 用空格隔开 eg: mkdir -p a/b/c/d, cd !$ find的应用 find /data/logs/ -mtime +7 -name ‘.log’ -type f | xargs rm # 删除这目录下 7天之前修改过的.log文件 find /abc -user zhangsan -perm -szie +50G find /data/logs -name abc.log find / -mtime -7 全盘找最近7天改过的文件 find / -mmin -10 全盘找最近10分钟内改过的文件 时间日期类date 显示当前时间 date “+%Y %m %d “ date -s “2019-10-01 21:23:13” 设置日期 cal cal 2020 显示某一年的 mysql -uroot -p’w14i#t1NPW’ -h100.121.190.3 -P3477 CCDB_239 man man ls help shell 内置命令帮助 help cd","link":"/2023/10/08/technology/Linux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"title":"玩转Python","text":"玩转PythonPython 基础篇Python 进阶Python WebPython 爬虫Python 数据分析","link":"/2020/06/08/technology/201911_%E7%8E%A9%E8%BD%ACPython/"},{"title":"Redis常用操作","text":"Redis常用操作1.基本概念微博上的热度排行榜用什么数据结构答：Zset，讲了讲zrangebyscore 补充： Zset 类型（Sorted Set，有序集合） 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。 在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，可以优先考虑使用 Sorted Set。 有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。 我们以博文点赞排名为例，小林发表了五篇博文，分别获得赞为 200、40、100、50、150。 `# arcticle:1 文章获得了200个赞 ZADD user:xiaolin:ranking 200 arcticle:1 (integer) 1 # arcticle:2 文章获得了40个赞 &gt; ZADD user:xiaolin:ranking 40 arcticle:2 (integer) 1 # arcticle:3 文章获得了100个赞 &gt; ZADD user:xiaolin:ranking 100 arcticle:3 (integer) 1 # arcticle:4 文章获得了50个赞 &gt; ZADD user:xiaolin:ranking 50 arcticle:4 (integer) 1 # arcticle:5 文章获得了150个赞 &gt; ZADD user:xiaolin:ranking 150 arcticle:5 (integer) 1 ` 文章 arcticle:4 新增一个赞，可以使用 ZINCRBY 命令（为有序集合key中元素member的分值加上increment）： &gt; ZINCRBY user:xiaolin:ranking 1 arcticle:4 &quot;51&quot; 查看某篇文章的赞数，可以使用 ZSCORE 命令（返回有序集合key中元素个数）： &gt; ZSCORE user:xiaolin:ranking arcticle:4 &quot;50&quot; 获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）： # WITHSCORES 表示把 score 也显示出来 &gt; ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES 1) &quot;arcticle:1&quot; 2) &quot;200&quot; 3) &quot;arcticle:5&quot; 4) &quot;150&quot; 5) &quot;arcticle:3&quot; 6) &quot;100&quot; 获取小林 100 赞到 200 赞的文章，可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员，分数由低到高排序）： &gt; ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES 1) &quot;arcticle:3&quot; 2) &quot;100&quot; 3) &quot;arcticle:5&quot; 4) &quot;150&quot; 5) &quot;arcticle:1&quot; 6) &quot;200&quot; rehash的过程讲一下答：新旧表双写，逐渐迁移 补充： 为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。 渐进式 rehash 步骤如下： 给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍； 在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上； 随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。 这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash 的耗时操作。 在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。 比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。 另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。 迁移过程中老表是什么时候释放，怎么知道老表可以释放了答：通过数据长度 补充： 每个 hash table 都有存着一个 used 字段，每次单步 rehash 完成的时候，最后都会检查老表即 ht[0].used 是否变成了 0，变成 0 后，就说明老的哈希表里已经没有数据了，此时就会去 free 掉老表，交换老表新表的指针，rehashidx 置为 -1，然后就完成了整个 rehash。","link":"/2020/06/08/technology/Redis%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"title":"Typroa 使用指导","text":"Typroa 使用指导常用快捷键 标题：Ctrl+数字 *加粗：Ctrl+b* *倾斜：Ctrl+i* 下划线：Ctrl+u Ctrl+L 选中一整行 Ctrl+d 选中某个单词 ctrl+e 选中相同格式的文字 Alt+shift+5（或者~~删除~~） 删除线 Ctrl+Home 返回Typora顶部 Ctrl+End 返回Typora底部 Ctrl+t 创建表格 Ctrl+K 创建超链接 Ctrl+Shift+q(直接输入 &gt; ) 引用 Ctrl+Shift+i（或直接拖动到指定位置） 插入图片 注：一些实体符号需要在实体符号之前加”\\”才能够显示 Shift+Alt+L 显示大纲/文件 Ctrl+p 快速打开最近文档 换行符 在markdown中，段落由多个空格分隔。在Typora中，只需回车即可创建新段落。 列表 有序列表：Ctrl+Shift+[ 无序列表：Ctrl+Shift+】 或 +-*(按一下这三个中的任一个然后按空格) 任务列表：-空格[空格]空格 文字或者Shift+Alt+R \\ -[ ] 不勾选 \\ -[x] 勾选 增大列表缩进：Ctrl + [ 减小列表缩进：Ctrl + ] - [ ]不勾选 - [ ]勾选 不勾选 勾选 代码块 单行代码用两个` 如code 多行用下面 Typora 中代码的插入也可以分为行内和块间两种： 行内代码：用 ... 或 ... 括起代码，代码会以主题中设置的样式出现在行内，但不会实现代码高亮。 代码块：输入 ``` 后并输入语言名，换行，开始写代码，Typora 就会自动帮你实现代码高亮。Typora 原生支持许多编程语言代码块的语法高亮。 除此以外，你也可以直接换行开始写，而后再选择语言。 输入``` + 回车 Ctrl+Shift+K 1int a; 数学表达式(公式块) Ctrl+Shift+M LaTeX 行内公式（inline）：用 $...$ 括起公式，公式会出现在行内。 块间公式（display）：用$$...$$ 括起公式（注意 $$ 后需要换行），公式会默认显示在行中间。 脚注 链接引用: 类似于我们常在论文末尾看到的「参考文献」的写法，你可以通过 []: 的语法来为你的文档加上链接引用。 这个例子的脚注为2 你可以创建一个脚注，像这样1. 脚注: 在需要插入脚注标号的位置写 number ，再在下方通过 [ number ] 在文档中插入脚注。注意不要遗漏了脚注编号 number 前后的空格。 分割线 输入***或--- 再按回车即可绘制一条水平线 目录（TOC） 输入[toc]然后回车 typora快捷键常用快捷键换行符列表代码块数学表达式(公式块)脚注分割线目录（TOC）内部链接网址图片斜体表情符号上下标高亮文本居中换行符转义HTML换行另外 内部链接 这是一个带有标题属性的 [链接](http://example.com/ &quot;标题&quot;) 这是一个没有标题属性的 [链接](http://example.net/) 效果如下 这是一个带有标题属性的链接 这是一个没有标题属性的链接. 网址 Typora允许用&lt;括号括起来&gt;, 把URL作为链接插入。 www.baidu.com Typora还会自动链接标准网址。 www.baidu.com 图片 显示da文字 斜体 使用 *单个星号* 或者 _单下划线_ 可以字体倾斜。快捷键 Ctrl + I 狼来了 啦啦啦 表情符号 输入不同的符号码（两个冒号包围的字符）可以显示出不同的表情 :+英文: 😄 上下标 可以使用 &lt;sub&gt;文本&lt;/sub&gt;或者~2~实现下标。 使用^2^实现上标 H2o H2o X2 高亮 ==高亮== 高亮 文本居中 使用 &lt;center&gt;这是要居中的内容&lt;/center&gt;可以使文本居中 这是要居中的内容 换行符 使用 空格 + 空格 + Enter可以实现换行，例如： 或者可以使用&lt;br/&gt;实现换行。 换行 转义 \\ 反斜线 ` 反引号 * 星号 _ 下划线 {} 花括号 [] 方括号 () 小括号 # 井字号 + 加号 - 减号 . 英文句点 ! 感叹号 HTML 目前支持的 HTML 元素有：&lt;kbd&gt; &lt;b&gt; &lt;i&gt; &lt;em&gt; &lt;sup&gt; &lt;sub&gt; &lt;br&gt;等 ，如： 12使用 &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;Alt&lt;/kbd&gt;+&lt;kbd&gt;Del&lt;/kbd&gt; 重启电脑&lt;kbd&gt; &lt;/kbd&gt; -- 白色框框 效果： 使用 Ctrl+Alt+Del 重启电脑 换行 区快； 空格：在输入连续的空格后，Typora 会在编辑器视图里为你保留这些空格，但当你打印或导出时，这些空格会被省略成一个。你可以在源代码模式下，为每个空格前加一个 \\ 转义符，或者直接使用 HTML 风格的 &amp;nbps; 来保持连续的空格。 软换行：Shift + Enter 只在编辑界面可见，当文档被导出时换行会被省略。 硬换行：空格 + 空格 + Shift + Enter 文档被导出时将被保留，没有换段的段后距。 换段：你可以通过 Enter 完成一次换段。Typora 会自动帮你完成两次 Shift + Enter 的软换行，从而完成一次换段。这也意味着在 Markdown 语法下，换段是通过在段与段之间加入空行来实现的。 Windows 风格（CR+LF）与 Unix 风格（CR）的换行符：CR 表示回车 \\r ，即回到一行的开头，而 LF 表示换行 \\n ，即另起一行。 所以 Windows 风格的换行符本质是「回车 + 换行」，而 Unix 风格的换行符是「换行」。这也是为什么 Unix / Mac 系统下的文件，如果在 Windows 系统直接打开会全部在同一行内。 你可以在 文件 - 偏好设置 - 编辑器 - 默认换行符 中对此进行切换。 emoji :emoji: 打出 emoji，自动给出图形的提示。 另外 文件系统 导入：支持的文件格式：.docx, .latex, .tex, .ltx, .rst, .rest, .org, .wiki, .dokuwiki, .textile, .opml, .epub。 导出：支持导出 PDF，HTML等格式。可安装 Pandoc 插件来导出更多例如 docx，LaTeX 等格式。 [2] 1 这是上面脚注的实际内容 [1] 定义脚注 for my test: 加黑一下 加下划线 加链接 :smile: http://www.baidu.com &lt;www.baidu.com&gt; www.baidu.com 1 fsaf $$a=b+c$$ afasf yi ers fasfa [] 引用 \\ -、、、、、’‘’；；；‘’；；‘’[] fafaf","link":"/2020/06/08/technology/Typroa%20%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/"},{"title":"MYSQL常用操作","text":"MYSQL常用操作1 基本概念mysql的事务是什么在数据库中，事务（Transaction）是一组操作单元，这些操作单元要么全部执行成功，要么全部执行失败。事务是保证数据库一致性的重要机制之一，它可以将一系列的操作看作一个整体，从而保证数据库的完整性和正确性。 事务具有四个特性，即ACID： 原子性（Atomicity）：事务中的所有操作要么全部执行成功，要么全部执行失败，不会出现部分执行的情况。 一致性（Consistency）：事务执行前后数据库的状态是一致的，即数据库中的约束和规则都得到了保持。 隔离性（Isolation）：多个事务并发执行时，相互之间不会影响彼此的执行结果。 持久性（Durability）：事务执行完成后，对数据库所作的修改将被永久保存到数据库中。 MySQL是一种常见的关系型数据库，支持事务的机制。在MySQL中，事务可以 通过使用事务控制语句（Transaction Control Statements）来进行管理，包括以下三个语句： START TRANSACTION：开始一个事务。 COMMIT：提交一个事务，使之生效。 ROLLBACK：回滚一个事务，使之失效。 在MySQL中，事务默认是关闭的，需要通过设置autocommit参数为0来启用事务。启用事务后，可以通过执行SQL语句来进行事务操作， 数据库的事务的4个特性是什么？并发事务会带来什么问题？ 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 并发事务的问题： 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。 不可重复读（Unrepeatableread）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 事务隔离的级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。（MySQL默认） SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 一条语句，问怎么加索引比较好？什么情况应该加索引，什么情况不应该加？在 MySQL 中，创建索引可以提高查询性能。为了给某个列添加索引，我们可以使用以下语句：CREATE INDEX index_name ON table_name(column_name);在这里，index_name是你为索引指定的名称，table_name是你要添加索引的表名，而column_name是你要添加索引的列名。在选择要添加索引的列时，请考虑以下几点：对于经常用于查询条件的列，添加索引可以提高查询速度。对于具有许多重复值的列，添加索引的性能提升可能不明显。尽量避免在非常大的表上创建过多索引，因为这会影响插入和更新操作的性能。 2 数据库操作字符集切换123set names utf8; set names latin1;... 知道字段名，反查在哪张表1select table_name from information_schema.columns where table_schema = '库名' and column_name='字段名'; 知道表名，反查在哪个库里1SELECT table_schema FROM information_schema.TABLES WHERE table_name = '表名'; 修改表名1rename table MyClass to YouClass; 备份表123mysqldump -h10.18.110.12 -umysql_user -pmysql_passwd -P22001 tgwoss_apd tb_isp &gt; tb_isp.sqlmysqldump -h10.18.110.12 -umysql_user -pmysql_passwd -P22001 tgwoss_apd &lt; tb_isp.sql 导出数据库123456789101112131415161718192021导出整个数据库结构和数据mysqldump -h localhost -uroot -p123456 database &gt; dump.sql导出单个数据表结构和数据mysqldump -h localhost -uroot -p123456 database table &gt; dump.sql 导出整个数据库结构（不包含数据）mysqldump -h localhost -uroot -p123456 -d database &gt; dump.sql 导出单个数据表结构（不包含数据）mysqldump -h localhost -uroot -p123456 -d database table &gt; dump.sql导出多个表 mysqldump -t database -u username -ppassword --tables table_name1 table_name2 table_name3 &gt;D:\\db_script.sql导入sqlmysql -h localhost -P 3306 -u root -p 数据库名&lt; a.sql // sql文件可以包含创建表、存储过程等的语句 建议用online ddl（网上可以查）修改，就是逗号后面的参数另外，添加字段要加上after，根据表结构看看fromWanIp适合在哪个字段后ALTER TABLE cEip ALTER COLUMN ispId SET DEFAULT -1, ALGORITHM=INPLACE, LOCK=NONE;","link":"/2020/06/08/technology/MYSQL%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"title":"Ubuntu如何利用别名快速访问云主机","text":"Ubuntu如何利用别名快速访问云主机问： 在Ubuntu上访问云主机，共分几步？答： 分以下三步: 打开记事本，找到要访问的主机的IP、用户名和密码，并拷贝 输入ssh命令,如ssh root@12.23.45.67 输入或粘贴密码，然后回车，进入云主机 问：你感觉这样的操作复杂吗？答：不复杂啊，只要三步呀问：那如果你同时要管理十台甚到几十台云主机呢，每次访问一台都要这么做吗？你不累吗？答：滚！ 好了，进入正题，让我们看看如何优雅快速的访问你的云主机吧。 先说方案，其实很简单: 利用别名（alias）, 事先为每一台云主机设置一个别名（见名知义的那种），并且上传ssh密钥到每一台云主机，这样以后访问该云主机时只需要输入它对应的别名就可以了!什么IP,用户名，密码统统不要了，即安全又省事！PS:关于别名这个小技巧也是我从其他同事那学到的，所谓三人行必有我师，真是学到老活到老啊。另外，别名的用途可不仅仅如此啊，可以对很多常用又复杂的命令设置别名，达到快速执行的目的哦！ 来（wo）看(yao)看(kai)怎(shi)么(zhuang)做(bi)吧（la） 1.配置别名 编辑.bashrc文件, 输入别名和对应的云主机登录命令.按G跳到最后一行，输入别名和别名对应的云主机信息,这里假设我的云主机 ip=12.23.45.56,user=root,密码=123456, 别名=zhuji112vi ~/.bashrcalias zhuji1=&quot;ssh root@12.23.45.56&quot; #123456这里可以备注下密码，方便以后查看 2.生成ssh密钥1ssh-keygen -t rsa 直接三次回车，保存rsa格式的密钥到默认位置， 当然你也可以指定位置。这里的密钥生成一次就可以了，如果提示提示已经有密钥了，跳过此步即可。## 3.上传密钥到目标云主机上1ssh-copy-id root@12.23.45.56按照提示，输入该云主机的root账号密码即可。## 4.让别名生效1source ~/.bashrc好了，别名已经设置好了,现在试试吧 1zhuji1 输入刚才设置好的别名， 敲下回车，已经安全进入到我们的云主机了，是不是很方便啊！ 如果你有多台云主机，就继续重复1,3,4步即可。","link":"/2018/10/08/technology/Ubuntu%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E5%88%AB%E5%90%8D%E5%BF%AB%E9%80%9F%E8%AE%BF%E9%97%AE%E4%BA%91%E4%B8%BB%E6%9C%BA/"},{"title":"动态vps环境初始化配置","text":"动态vps环境初始化配置最近在做一个自动化项目，用到了动态VPS, 刚刚拿到一个新的VPS难免要对系统环境进行一番配置，特此记录下主要的操作步骤，方便自己也方便同道中人。 注：我的VPS 系统是CentOS 7.2， 采用ADSL拨号方式。 1.登录由于本人使用的ubuntu系统,所以采用以下命令方式登录。当然也可以借助xshell/putty 等ssh工具方便的进行登录。如果是windows系统我强烈推荐使用用MobaXterm, 强大好用！ 1ssh -p port user@host 如: ssh -p 20110 root@100.200.300.400 输上以上命令后，按提示输入正确的密码，登录成功。 2.修改root密码(建议)以root身份登录成功后，建议先修改root密码，一是为了安全; 二是方便自己登录, 不用每次都拷贝粘贴复杂难记的初始密码。 使用如下命令，按提示输入两次新密码即可 1passwd 3.查看系统信息1cat /etc/redhat-release 本人使用的环境信息是：CentOS Linux release 7.2.1511 (Core)注：还可以通过 df/top等命令查看磁盘、cpu负载信息 4.拨号网络配置如果不进行网络配置是无法正常上网的，这一步很重要。主要使用的命令有： 1234pppoe-setuppppoe-startpppoe-stoppppoe-status 先通过pppoe-setup命令进行拨号网络配置，此时需要用到VPS服务商给你的ADSL账号及密码，按照提示进行即可。详细操作步骤可参考如何正确的使用动态VPS（Linux）自动更换IP 5.切换国内源先对原源进行备份， 然后切换国内163镜像源，提供安装下载速度，特是针对国内VPS 1234mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupwget -O /etc/yum.repos.d/CentOS-163-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repoyum clean allyum makecache 以上操作完成后, 你的VPS就可以正常使用了, 接下来按照自己的需求自如的使用你的VPS吧。","link":"/2019/11/08/technology/%E5%8A%A8%E6%80%81vps%E7%8E%AF%E5%A2%83%E5%88%9D%E5%A7%8B%E5%8C%96%E9%85%8D%E7%BD%AE/"},{"title":"python数据挖掘","text":"1 先贴一个鹅厂的招聘信息看下数据挖掘相关的能力要求1岗位信息1、计算机、机器学习、统计等相关专业，本科及以上学历，3年以上相关工作经验。2、有较强的算法基础和编码能力，熟练掌握Python、SQL、Java、Scala等至少一门语言。3、熟练掌握常见的特征处理方法和机器学习算法，熟练使用各类常见的机器学习算法库，例如sklearn、tensorflow、pytorch、spark mllib等。4、熟悉金融领域（银行、券商、保险等）的常见业务流程与业务问题，有相关建模经验者优先。5、善于沟通，工作积极主动，责任心强，具备良好的团队协作能力。 通过腾讯云从业资格证或同等资格认证的优先录取6、针对客户实际业务问题，负责大规模数据场景下的数据分析和建模工作。7、针对各类常见的具体业务问题，负责相关案例和应用在产品侧的沉淀与积累。8、具有扎实的数据结构和算法功底，能熟练应用各类机器学习模型（逻辑回归、聚类、树模型、图网络等）；9、对数据分析和数据挖掘有深入理解，有相关项目经验；10、能够运用hadoop、spark等大数据计算平台进行数据分析挖掘，熟练掌握python、hivesql、sparkscala，有相关项目经验；11、有较强学习能力和逻辑思维能力，具备良好的问题分析与解决能力；12、善于沟通，工作积极主动，责任心强，具备良好的团队协作能力；13、有toB+toC业务数据分析经验者优先。 通过腾讯云从业资格证或同等资格认证的优先录取。 备注：此岗位为腾讯集团旗下全资子公司编制岗位 2岗位职责1、负责腾讯会议的数据仓库、数据建模、数据分析、数据可视化开发工作；2、负责优化现有业务数据分析工具，通过科学方法持续优化数据分析效能；3、负责提升产品&amp;运营团队基于数据驱动决策的效率和准确性，针对各行业数据的指标进行体系化梳理和建设；4、负责腾讯会议数据治理，通过数据入库、校验、清洗，保证数据质量；5、负责腾讯会议的数据标签挖掘、运营模型搭建工作；6、持续产出行业洞察，跟踪分析竞争对手、行业趋势等，形成商业分析并洞察其中的商业机会。 2 根据岗位信息整理技术能力点 数据仓库， 数据建模，数据分析，数据可视化， 数据标签挖掘， 运营模型搭建，行业趋势，商业机会 大数据：spark, hadoop, Sql, hivesql, python, sparkscala, 统计学：AB test 机器学习：逻辑回归、聚类、树模型、图网络， 决策树， 随机森林， xgboost 数据预处理：缺失、重复、冲突， 清洗 数据入库 数据挖掘：tensoflow, keras, pytorch, 模型搭建 可视化：tableau, power_bi 网页抓取 数仓工具Hive、MR、Flink、Mysql 数仓建模理论，数仓分层、星形模型、雪花模型等，有大规模业务数仓实践经验优 握数据etl过程，熟悉spark/hadoop/Hbase/es等大数据处理框架； 探索和抽象通用的数据分析方法，如流失预测，归因分析，路径分析，用户分群 从事过机器学习平台研发或参加kaggle等比赛获得优异成绩者优先 3 数据挖掘的应用场景思考 做版本规划的时候，如何设立指标来进行功能验证？ 功能上线后，如何做数据复盘？ 如何通过数据来快速定位问题？ 在众多的数据中如何识别哪些是需要呈现的重要数据 通过数据仅能让你找到局部最大值，而更高的山峰只会建立在你更广阔的视野与深厚的认知上。 4 技术学习4.1 数据分析流程梳理数据分析：用适当的统计方法对收集来的数据进行分析，以求最大化的开发数据资料的功能， 发挥数据的作用， 是为了提取有用的信息和形成结论而对数据加以详细研究和概括总结的过程。数据挖掘：从海量的数据库中选择、探索、识别出有效的、新颖的、具有潜在效用的乃至最终可理解的模式以获取商业利益的非平凡的过程 定义挖掘目标：问题和想达到的效果， 明确分析的目的和思路 为什么展开数据分析，遇到什么问题，有没有其他更好的办法 方法：逻辑树分析法， 5w2h, 4p营销理论， PEST分析法 想多一点点 ####数据取样：相关性， 可靠性，有效性 来自：数据库，问卷，互联网，公开出版物 ####数据探索：异常值分析， 缺失值分析， 相关性分析，周期分析 ####数据预处理：筛选， 变量转换， 缺失值处理，坏数据处理，数据标准化， 主成分分析，属性选择， 数据规约 数据清洗–》数据加工 从业务角度检查数据：不完整性， 噪音数据， 类型冲突， 单位冲突 从技术角度检查数据：统计描述， 箱体图，直方图， 散点图——》 数据预分析过程 数据分析方法： 对比分析， 交叉分析， 漏斗图分析， 矩阵关联分析，综合评价分析，杜邦分析 对比分析：将两个或两个以上的数据进行比较， 分析他们的差异， 从而揭示这些数据所代表的事务发展变化情况和规律性。 特地昂是非常直观的看出事务某方面的变化和差距， 并且可以准确、量化的表示出这种变化或者差距是多少。 例如列出国内各省的人均消费金额，对比差异 交叉分析：通常用于分析两个变量之间的关系，即同时将两个有一定联系的变量及其值交叉排列在一张表格内，是各个变量值成为不同变量的交叉节点， 形成交叉表， 从而分析交叉表中变量之间的关系。比如每月星巴克卖出的咖啡中白咖啡和黑咖啡的占比 漏斗分析：漏斗图是一个适合业务流程比较规范、周期比较长、各流程环节涉及复杂业务过程比较多的管理分析工具。是对业务流程最直观的一种表现形式， 可以快速发现业务流程中存在问题的环节。比如浏览商品-》放入购物车-》生成订单-》支付订单-》完成交易，每一步的转换率怎样 矩阵关联分析：是指根据事务的两个重要属性作为横纵轴， 组成一个坐标系， 在两坐标轴上分辨按某一标准进行刻度划分，构成四个象限， 将要分析的每个事务对应投身至这四个象限内， 直观的将两个属性的关联性表现出来， 进而分析每一个事务在这两个属性上的表现， 为决策者提供重要的参考依据。 挖掘建模：根据哪类问题（分类，聚类，关联规则， 时序模式， 智能推荐），选择合适的算法 常用的数据挖掘的方法：回归分析，关联分析，决策树，聚类分析， 因子分析，神经网络 回归分析：线性回归， 非线性回归， logistic回归 关联分析：推荐系统常用 决策树：决策树中最顶部的结点称为根结点， 是整个决策树的开始。 每个决策结点代表一个问题或者决策，结点连线代表某个属性满足的条件， 每个叶结点代表一种分类结果。 聚类分析：根据研究对象多个变量取值情况利用分类算法将研究对象划分到相对同质的多个群组， 使得群组内对象之间具有较高相似度，不通群组间对象之间差异较大——层次聚类法， k-means均值聚类法：随机选择k个对象，每个对象初试的代表一个类的平均值或者中心， 对剩余每个对象，根据其到各类中心的欧式距离，被划分到最近的类；然后重新计算每个类的中心值。不断重复这个过程，直到所有的样本都不能再分到任何一类为止。 模型评价：对比模型发布数据展示 a picture is worth a thousand words; 表格、图表（成分图、排序（直方图），频率分布（直方图、折线图）， 相关性（矩阵、散点）， 多位图（多重数据比较））、词云图、 地域分布图、艺术图 Excel, spss, sas, matlab, stata, T 撰写报告 分析的目的和背景：目的，数据来源 主要分析结果：1，2， x 总结与建议： 详细分析：1XXXX，图表，结果， 2xxxx, 图表，结果 附录：参考数据，模型说明等 心得体会 分析的关键在于从起伏跌宕中发现规律和信息 宁缺毋滥，切记过度推理 4.2 数据分析工具 Hadoop, sqlserver, mysql, TDW(腾讯大数据平台) http://www.199it.com/ 中文互联网数据咨询 4.3 常见的数据分析、挖掘模型分类模型：解决的是事务自动学习，然后进行类别判定的问题 聚类模型：解决的是将数据对象自动组成对象划定为不同类族 预测模型：解决根据已有实测规律，预测下一周期数据的问题 关联模型：解决大规模数据集中，寻找有关联关系的数据的问题 推荐模型：解决基于现有数据进行有效推荐 4.4 机器学习 4.4.1 有监督学习 K-近邻算法 决策树 逻辑回归 svm 朴素贝叶斯 4.1.2 无监督学习 K-means PCA FP-growth 关联规则 PageRank 4.1.3 分类模型常用算法 朴素贝叶斯 svm k-近邻 逻辑回归 决策树 4.1.4 聚类模型常用算法对大量未标注的数据集进行特征处理–》按照数据内在相似性将数据集划分为多个类别–》使类别内的数据相似度较大，而类别间的数据相似度较小 4.2 spark 4.5 数据分析技术点梳理5.1 数据分析方法1）拆解①树形拆解适合构成类数据分析，每一个数据由多个子项构成下一层是上一层的支撑和论据 ②线性拆解适合流程分析，挖掘用户操作流程中的问题点关注相邻项间的转化和用户流失情况优化方向：去掉过程步骤等 5.2 数据清洗和特征处理https://tech.meituan.com/2015/02/10/machinelearning-data-feature-process.html https://www.cnblogs.com/jasonfreak/p/5448385.html 其本质是一项工程活动，目的是最大限度地从原始数据中提取特征以供算法和模型使用 数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已 数据清洗=&gt;特征 标注数据生成=&gt;模型学习=&gt;模型应用 蓝色-离线 绿色-在线 主要的区别在于1.不需要清洗标注数据，只需要处理得到特征数据，在线模型使用特征数据预测出样本可能的标签。2.最终生成数据的用处，最终生成的数据主要用于模型的预测，而不是训练。 在离线的处理部分，可以进行较多的实验和迭代，尝试不同的样本采样、样本权重、特征处理方法、特征组合方法等，最终得到一个最优的方法，在离线评估得到好的结果后，最终将确定的方案在线上使用。 另外，由于在线和离线环境不同，存储数据、获取数据的方法存在较大的差异。例如离线数据获取可以将数据存储在Hadoop，批量地进行分析处理等操作，并且容忍一定的失败。而在线服务获取数据需要稳定、延时小等，可以将数据建入索引、存入KV存储系统等。 离线我们用常用的衡量排序结果的AUC指标，在线的我们通过ABTest来测试算法对下单率、用户转化率等指标的影响。 模型评价: 离线AUC, 在线ABTest AUC:AUC值为ROC曲线下的面积，是一个概率值，越大越好。简单来说这个指标的含义其实就是随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率。AUC是一个二分类模型的评价指标，还有很多其他指标比如logloss，accuracy，precision。在数据挖掘比赛中，AUC和logloss比accuracy更常用。因为很多机器学习的模型对分类问题的预测结果都是概率，如果要计算accuracy，需要先把概率转化成类别，这就需要手动设置一个阈值，如果对一个样本的预测概率高于阈值，那该样本就被预测为正样本，低于这个阈值，则为负样本。所以这个阈值很大程度上影响了accuracy的计算。然而，使用AUC和logloss可以避免把预测概率转换成类别。 Logloss: logloss越小越好，物理意义为：衡量预估ctr与实际ctr的拟合程度。 数据获取：准确性， 难度、数据量大小 数据采样：随机采样，固定比例采样 1.结合业务情况进行数据的过滤，例如去除crawler抓取，spam，作弊等数据。 2.异常点检测，采用异常点检测算法对样本进行分析，常用的异常点检测算法包括 - 偏差检测，例如聚类，最近邻等。 - 基于统计的异常点检测算法 例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。 - 基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。 - 基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法 特征分类 离线特征获取方案 离线可以使用海量的数据，借助于分布式文件存储平台，例如HDFS等，使用例如MapReduce，Spark等处理工具来处理海量的数据等 在线特征获取方案 在线特征比较注重获取数据的延时，由于是在线服务，需要在非常短的时间内获取到相应的数据，对查找性能要求非常高，可以将数据存储在索引、kv存储等。而查找性能与数据的数据量会有矛盾，需要折衷处理，我们使用了特征分层获取方案 特征数据只有在和标注数据合并之后，才能用来做为模型的训练 可以将特征分为(1)Low level特征和High level特征。(2)稳定特征与动态特征。(3)二值特征、连续特征、枚举特征。 Low level特征是较低级别的特征，主要是原始特征，不需要或者需要非常少的人工处理和干预，例如文本特征中的词向量特征，图像特征中的像素点，用户id，商品id等。Low level特征一般维度比较高，不能用过于复杂的模型。High level特征是经过较复杂的处理，结合部分业务逻辑或者规则、模型得到的特征，例如人工打分，模型打分等特征，可以用于较复杂的非线性模型。Low level 比较针对性，覆盖面小。长尾样本的预测值主要受high level特征影响。 高频样本的预测值主要受low level特征影响。 稳定特征是变化频率(更新频率)较少的特征，例如评价平均分，团购单价格等，在较长的时间段内都不会发生变化。动态特征是更新变化比较频繁的特征，有些甚至是实时计算得到的特征，例如距离特征，2小时销量等特征。或者叫做实时特征和非实时特征。针对两类特征的不同可以针对性地设计特征存储和更新方式，例如对于稳定特征，可以建入索引，较长时间更新一次，如果做缓存的话，缓存的时间可以较长。对于动态特征，需要实时计算或者准实时地更新数据，如果做缓存的话，缓存过期时间需要设置的较短。 二值特征主要是0/1特征，即特征只取两种值：0或者1，例如用户id特征：目前的id是否是某个特定的id，词向量特征：某个特定的词是否在文章中出现等等。连续值特征是取值为有理数的特征，特征取值个数不定，例如距离特征，特征取值为是0~正无穷。枚举值特征主要是特征有固定个数个可能值，例如今天周几，只有7个可能值：周1，周2，…，周日。在实际的使用中，我们可能对不同类型的特征进行转换，例如将枚举特征或者连续特征处理为二值特征。枚举特征处理为二值特征技巧：将枚举特征映射为多个特征，每个特征对应一个特定枚举值，例如今天周几，可以把它转换成7个二元特征：今天是否是周一，今天是否是周二，…，今天是否是周日。连续值处理为二值特征方法：先将连续值离散化（后面会介绍如何离散化)，再将离散化后的特征切分为N个二元特征，每个特征代表是否在这个区间内。 特征选择 特征选择的目标是寻找最优特征子集。特征选择能剔除不相关(irrelevant)或冗余(redundant )的特征，从而达到减少特征个数，提高模型精确度，减少运行时间的目的。另一方面，选取出真正相关的特征简化模型，协助理解数据产生的过程。 特征选择的一般过程如下图所示：主要分为产生过程，评估过程，停止条件和验证过程 特征抽取和归一化之后，如果发现特征太多，导致模型无法训练，或很容易导致模型过拟合，则需要对特征进行选择，挑选有价值的特征。 Filter： 假设特征子集对模型预估的影响互相独立，选择一个特征子集，分析该子集和数据Label的关系，如果存在某种正相关，则认为该特征子集有效。衡量特征子集和数据Label关系的算法有很多，如Chi-square，Information Gain。 Wrapper： 选择一个特征子集加入原有特征集合，用模型进行训练，比较子集加入前后的效果，如果效果变好，则认为该特征子集有效，否则认为无效。 Embedded： 将特征选择和模型训练结合起来，如在损失函数中加入L1 Norm ，L2 Norm。 完全搜索(Complete) 广度优先搜索( Breadth First Search ) 广度优先遍历特征子空间。枚举所有组合，穷举搜索，实用性不高。 分支限界搜索( Branch and Bound ) 穷举基础上加入分支限界。例如：剪掉某些不可能搜索出比当前最优解更优的分支。 其他，如定向搜索 (Beam Search )，最优优先搜索 ( Best First Search )等 启发式搜索(Heuristic) 序列前向选择( SFS ， Sequential Forward Selection ) 从空集开始，每次加入一个选最优。 序列后向选择( SBS ， Sequential Backward Selection ) 从全集开始，每次减少一个选最优。 增L去R选择算法 ( LRS ， Plus-L Minus-R Selection ) 从空集开始，每次加入L个，减去R个，选最优（L&gt;R)或者从全集开始，每次减去R个，增加L个，选最优(L&lt;R)。 其他如双向搜索( BDS ， Bidirectional Search )，序列浮动选择( Sequential Floating Selection )等 随机搜索(Random) 随机产生序列选择算法(RGSS， Random Generation plus Sequential Selection) 随机产生一个特征子集，然后在该子集上执行SFS与SBS算法。 模拟退火算法( SA， Simulated Annealing ) 以一定的概率来接受一个比当前解要差的解，而且这个概率随着时间推移逐渐降低 遗传算法( GA， Genetic Algorithms ) 通过交叉、突变等操作繁殖出下一代特征子集，并且评分越高的特征子集被选中参加繁殖的概率越高。 随机算法共同缺点:依赖随机因素，有实验结果难重现。 特征选择—相关性 对特征的有效性进行分析，得到各个特征的特征权重，根据是否与模型有关可以分为1.与模型相关特征权重，使用所有的特征数据训练出来模型，看在模型中各个特征的权重，由于需要训练出模型，模型相关的权重与此次学习所用的模型比较相关。不同的模型有不同的模型权重衡量方法。例如线性模型中，特征的权重系数等。2.与模型无关特征权重。主要分析特征与label的相关性，这样的分析是与这次学习所使用的模型无关的。与模型无关特征权重分析方法包括(1)交叉熵，(2)Information Gain，(3)Odds ratio，(4)互信息，(5)KL散度等 于重要的特征进行监控与有效性分析，了解模型所用的特征是否存在问题，当某个特别重要的特征出问题时，需要做好备案，防止灾难性结果 特征选择–距离 运用距离度量进行特征选择是基于这样的假设：好的特征子集应该使得属于同一类的样本距离尽可能小，属于不同类的样本之间的距离尽可能远。常用的距离度量（相似性度量）包括欧氏距离、标准化欧氏距离、马氏距离等。 特征选择–一致性 若样本1与样本2属于不同的分类，但在特征A、 B上的取值完全一样，那么特征子集{A，B}不应该选作最终的特征集 特征处理 无量纲化 标准化：标准化需要计算特征的均值和标准差，公式表达为， 代码from sklearn.preprocessing import StandardScaler 区间缩放法：区间缩放法的思路有多种，常见的一种为利用两个最值进行缩放，公式表达为,代码 from sklearn.preprocessing import MinMaxScaler 特征归一化： Normalizer 主要用于单个特征的处理。 - 归一化 不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括1.函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。 2.分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。 3.排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。 标准化和归一化的区别：简单来说，标准化是依照特征矩阵的列处理数据，其通过求z-score（标准分数）的方法，将样本的特征值转换到同一量纲下。归一化是依照特征矩阵的行处理数据，其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准，也就是说都转化为“单位向量”。规则为l2的归一化公式如下： 对定量特征二值化：定量特征二值化的核心在于设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0 12341 from sklearn.preprocessing import Binarizer2 3 #二值化，阈值设置为3，返回值为二值化后的数据4 Binarizer(threshold=3).fit_transform(iris.data) 对定性特征亚编码 one-hot独热编码介绍 https://blog.csdn.net/qq_41853758/article/details/81252174 独热码，在英文文献中称做 one-hot code, 又称独热编码、一位有效编码,直观来说就是有多少个状态就有多少比特，而且只有一个比特为1，其他全为0的一种码制。其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都有它独立的寄存器位，并且在任意时候，其中只有一位有效。 自然状态码为：000,001,010,011,100,101 独热编码为：000001,000010,000100,001000,010000,100000 离散化–等值划分，等量划分 离散化 在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，…，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。正如上文所言，独热编码（哑变量 dummy variable）是因为大部分算法是基于向量空间中的度量来进行计算的，为了使非偏序关系的变量取值不具有偏序性，并且到圆点是等距的。使用one-hot编码，将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。将离散型特征使用one-hot编码，会让特征之间的距离计算更加合理。离散特征进行one-hot编码后，编码后的特征，其实每一维度的特征都可以看做是连续的特征。就可以跟对连续型特征的归一化方法一样，对每一维特征进行归一化。比如归一化到[-1,1]或归一化到均值为0,方差为1。 为什么特征向量要映射到欧式空间？ 将离散特征通过one-hot编码映射到欧式空间，是因为，在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的，而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。 缺省值处理 from sklearn.preprocessing import Imputer 有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等 数据变换：常见的数据变换有基于多项式的、基于指数函数的、基于对数函数的 特征降维 在介绍特征降维之前，先介绍下特征升维。在机器学习中，有一个VC维理论。根据VC维理论，VC维越高，打散能力越强，可容许的模型复杂度越高。在低维不可分的数据，映射到高维是可分。可以想想，给你一堆物品，人脑是如何对这些物品进行分类，依然是找出这些物品的一些特征，例如：颜色，形状，大小，触感等等，然后根据这些特征对物品做以归类，这其实就是一个先升维，后划分的过程。比如我们人脑识别香蕉。可能首先我们发现香蕉是黄色的。这是在颜色这个维度的一个切分。但是很多东西都是黄色的啊，例如哈密瓜。那么怎么区分香蕉和哈密瓜呢？我们发现香蕉形状是弯曲的。而哈密瓜是圆形的，那么我们就可以用形状来把香蕉和哈密瓜划分开了，即引入一个新维度：形状，来区分。这就是一个从“颜色”一维特征升维到二维特征的例子。 那问题来了，既然升维后模型能力能变强，那么是不是特征维度越高越好呢？为什么要进行特征降维&amp;特征选择？主要是出于如下考虑：1. 特征维数越高，模型越容易过拟合，此时更复杂的模型就不好用。2. 相互独立的特征维数越高，在模型不变的情况下，在测试集上达到相同的效果表现所需要的训练样本的数目就越大。 3. 特征数量增加带来的训练、测试以及存储的开销都会增大。4.在某些模型中，例如基于距离计算的模型KMeans，KNN等模型，在进行距离计算时，维度过高会影响精度和性能。5.可视化分析的需要。在低维的情况下，例如二维，三维，我们可以把数据绘制出来，可视化地看到数据。当维度增高时，就难以绘制出来了。在机器学习中，有一个非常经典的维度灾难的概念。用来描述当空间维度增加时，分析和组织高维空间，因体积指数增加而遇到各种问题场景。例如，100个平均分布的点能把一个单位区间以每个点距离不超过0.01采样；而当维度增加到10后，如果以相邻点距离不超过0.01小方格采样单位超一单位超正方体，则需要10^20 个采样点。 正是由于高维特征有如上描述的各种各样的问题，所以我们需要进行特征降维和特征选择等工作。特征降维常用的算法有PCA，LDA等。特征降维的目标是将高维空间中的数据集映射到低维空间数据，同时尽可能少地丢失信息，或者降维后的数据点尽可能地容易被区分 .是对数据在高维空间下的一个投影转换，通过一定的投影规则将原来从一个角度看到的多个维度映射成较少的维度 PCA算法 (主成分分析)通过协方差矩阵的特征值分解能够得到数据的主成分，以二维特征为例，两个特征之间可能存在线性关系（例如运动的时速和秒速度），这样就造成了第二维信息是冗余的。PCA的目标是发现这种特征之间的线性关系，并去除。 出发思想不同。PCA主要是从特征的协方差角度，去找到比较好的投影方式，即选择样本点投影具有最大方差的方向.在信号处理中认为信号具有较大的方差，噪声有较小的方差，信噪比就是信号与噪声的方差比，越大越好 LDA算法(线性判别分析) 考虑label，降维后的数据点尽可能地容易被区分. LDA则更多的是考虑了分类标签信息，寻求投影后不同类别之间数据点距离更大化以及同一类别数据点距离最小化，即选择分类性能最好的方向. LDA的思想可以用一句话概括，就是“投影后类内方差最小，类间方差最大” 降维后可用维度数量不同。LDA降维后最多可生成C-1维子空间（分类标签数-1），因此LDA与原始维度N数量无关，只有数据标签分类数量有关；而PCA最多有n维度可用，即最大可以选择全部可用维度。 上图左侧是PCA的降维思想，它所作的只是将整组数据整体映射到最方便表示这组数据的坐标轴上，映射时没有利用任何数据内部的分类信息。因此，虽然PCA后的数据在表示上更加方便（降低了维数并能最大限度的保持原有信息），但在分类上也许会变得更加困难；上图右侧是LDA的降维思想，可以看到LDA充分利用了数据的分类信息，将两组数据映射到了另外一个坐标轴上，使得数据更易区分了（在低维上就可以区分，减少了运算量）。 线性判别分析LDA算法由于其简单有效性在多个领域都得到了广泛地应用，是目前机器学习、数据挖掘领域经典且热门的一个算法；但是算法本身仍然存在一些局限性： ​ 当样本数量远小于样本的特征维数，样本与样本之间的距离变大使得距离度量失效，使LDA算法中的类内、类间离散度矩阵奇异，不能得到最优的投影方向，在人脸识别领域中表现得尤为突出 ​ LDA不适合对非高斯分布的样本进行降维 ​ LDA在样本分类信息依赖方差而不是均值时，效果不好 ​ LDA可能过度拟合数据 LDA用于降维，和PCA有很多相同，也有很多不同的地方，因此值得好好的比较一下两者的降维异同点。首先我们看看相同点： 1）两者均可以对数据进行降维。 2）两者在降维时均使用了矩阵特征分解的思想。 3）两者都假设数据符合高斯分布。我们接着看看不同点： 1）LDA是有监督的降维方法，而PCA是无监督的降维方法 2）LDA降维最多降到类别数k-1的维数，而PCA没有这个限制。 3）LDA除了可以用于降维，还可以用于分类。 4）LDA选择分类性能最好的投影方向，而PCA选择样本点投影具有最大方差的方向。 12345当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的降维方法除了以上提到的基于L1惩罚项的模型以外，另外还有主成分分析法（PCA）和线性判别分析（LDA），线性判别分析本身也是一个分类模型。PCA和LDA有很多的相似点，其本质是要将原始的样本映射到维度更低的样本空间中，但是PCA和LDA的映射目标不一样：PCA是为了让映射后的样本具有最大的发散性；而LDA是为了让映射后的样本有最好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。 5.3 特征选择当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征： 特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。 特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。除方差法外，本文介绍的其他方法均从相关性考虑。 根据特征选择的形式又可以将特征选择方法分为3种： Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。 Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。 Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。 我们使用sklearn中的feature_selection库来进行特征选择。 5.3.1 方差选择法用方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。使用feature_selection库的VarianceThreshold类来选择特征的代码如下： 4.6 sklearn进行数据挖掘https://www.cnblogs.com/jasonfreak/p/5448462.html 4.6.1 关键技术 并行处理，流水线处理，自动化调参，持久化是使用sklearn优雅地进行数据挖掘的核心。并行处理和流水线处理将多个特征处理工作，甚至包括模型训练工作组合成一个工作（从代码的角度来说，即将多个对象组合成了一个对象）。在组合的前提下，自动化调参技术帮我们省去了人工调参的反锁。训练好的模型是贮存在内存中的数据，持久化能够将这些数据保存在文件系统中，之后使用时无需再进行训练，直接从文件系统中加载即可 并行处理：并行处理使得多个特征处理工作能够并行地进行。根据对特征矩阵的读取方式不同，可分为整体并行处理和部分并行处理。整体并行处理，即并行处理的每个工作的输入都是特征矩阵的整体；部分并行处理，即可定义每个工作需要输入的特征矩阵的列 部分并行处理： 整体并行处理有其缺陷，在一些场景下，我们只需要对特征矩阵的某些列进行转换，而不是所有列。pipeline并没有提供相应的类（仅OneHotEncoder类实现了该功能），需要我们在FeatureUnion的基础上进行优化 流水线处理： pipeline包提供了Pipeline类来进行流水线处理。流水线上除最后一个工作以外，其他都要执行fit_transform方法，且上一个工作输出作为下一个工作的输入。最后一个工作必须实现fit方法，输入为上一个工作的输出；但是不限定一定有transform方法，因为流水线的最后一个工作可能是训练！ 自动化调参：网格搜索为自动化调参的常见技术之一，grid_search包提供了自动化调参的工具，包括GridSearchCV类。穷举搜索：在所有候选的参数选择中，通过循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果。其原理就像是在数组里找最大值。 存在问题：原始数据集划分成训练集和测试集以后，其中测试集除了用作调整参数，也用来测量模型的好坏；这样做导致最终的评分结果比实际效果要好。 耗时 对训练集再进行一次划分，分成训练集和验证集，这样划分的结果就是：原始数据划分为3份，分别为：训练集、验证集和测试集；其中训练集用来模型训练，验证集用来调整参数，而测试集用来衡量模型表现好坏。 持久化： externals.joblib包提供了dump和load方法来持久化和加载内存数据：","link":"/2021/06/08/technology/python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"},{"title":"机器学习算法四大金刚","text":"四大金刚介绍由上图我们可以看到，机器学习分为四大金刚，分别是 classification (分类)，regression (回归),clustering (聚类),dimensionality reduction (降维)。 1，给定一个样本特征 , 我们希望预测其对应的属性值 , 如果 是离散的, 那么这就是一个分类问题，反之，如果 是连续的实数, 这就是一个回归问题。 2，如果给定一组样本特征 , 我们没有对应的属性值 , 而是想发掘这组样本在 二维空间的分布, 比如分析哪些样本靠的更近，哪些样本之间离得很远, 这就是属于聚类问题。 3，如果我们想用维数更低的子空间来表示原来高维的特征空间, 那么这就是降维问题。 无论是分类还是回归，都是想建立一个预测模型 ，给定一个输入 , 可以得到一个输出，不同的只是在分类问题中,结果是离散的; 而在回归问题中结果是连续的 分类 classification有监督学习的两大应用之一，产生离散的结果 分类问题最常用的学习算法包括 SVM (支持向量机) , SGD (随机梯度下降算法), Bayes (贝叶斯估计), Ensemble, KNN 等。而回归问题也能使用 SVR, SGD, Ensemble 等算法，以及其它线性回归算法。 例如向模型输入人的各种数据的训练样本，产生“输入一个人的数据，判断是否患有癌症”的结果，结果必定是离散的，只有“是”或“否”。（即有目标和标签，能判断目标特征是属于哪一个类型） 回归 regression有监督学习的两大应用之一，产生连续的结果。 例如向模型输入人的各种数据的训练样本，产生“输入一个人的数据，判断此人20年后今后的经济能力”的结果，结果是连续的，往往得到一条回归曲线。当输入自变量不同时，输出的因变量非离散分布（不仅仅是一条线性直线，多项曲线也是回归曲线）。 classification &amp; regression：分类与回归无论是分类还是回归，都是想建立一个预测模型 ，给定一个输入 , 可以得到一个输出 : 不同的只是在分类问题中, 是离散的; 而在回归问题中 是连续的。所以总得来说，两种问题的学习算法都很类似。所以在这个图谱上，我们看到在分类问题中用到的学习算法，在回归问题中也能使用。分类问题最常用的学习算法包括 SVM (支持向量机) , SGD (随机梯度下降算法), Bayes (贝叶斯估计), Ensemble, KNN 等。而回归问题也能使用 SVR, SGD, Ensemble 等算法，以及其它线性回归算法。 聚类 clustering聚类也是分析样本的属性, 有点类似classification, 不同的就是classification 在预测之前是知道 的范围, 或者说知道到底有几个类别, 而聚类是不知道属性的范围的。所以 classification 也常常被称为 supervised learning, 而clustering就被称为unsupervised learning。clustering 事先不知道样本的属性范围，只能凭借样本在特征空间的分布来分析样本的属性。这种问题一般更复杂。而常用的算法包括 k-means (K-均值), GMM (高斯混合模型) 等。 无监督学习的结果。聚类的结果将产生一组集合，集合中的对象与同集合中的对象彼此相似，与其他集合中的对象相异。 降维 dimensionality reduction降维是机器学习另一个重要的领域, 降维有很多重要的应用, **特征的维数过高, 会增加训练的负担与存储空间, 降维就是希望去除特征的冗余, 用更加少的维数来表示特征.**降维算法最基础的就是PCA了, 后面的很多算法都是以PCA为基础演化而来。","link":"/2021/06/08/technology/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%9B%9B%E5%A4%A7%E9%87%91%E5%88%9A/"},{"title":"网络问题运维常用命令","text":"网络问题运维常用命令ipcalc1ipcalc 192.168.1.0/24 ip addr12ip addr add 192.168.120.125/24 dev ens3 --添加一个网络的地址,可以指定一个网络接口名字，在示例中它的名字是 ens3。这不需要去添加一个网络前缀，在本案例中，它是 /24，但是显式地添加它并没有什么坏处。你可以使用 ip 命令去检查你的配置ip addr route123456sysctl net.ipv4.ip_forward -- 查看路由转发是否开启,路由器必须配置去转发数据包。数据包转发默认是禁用的echo 1 &gt; /proc/sys/net/ipv4/ip_forward -- 开启sysctl -p 让变化生效ip route show 查看路由ip route add 192.168.120.0/24 via 192.168.110.126 dev ens3 -- 增加静态路由， 主机 1 可以通过路由器接口 192.168.110.126 去访问 192.168.110.0/24 网络。看一下它们是如何工作的？主机 1 和路由器需要连接到相同的地址空间，然后路由器转发到其它的网络。ip route del 192.168.120.0/24 删除路由 telnet1234567891.你可以使用 lsof 命令来查看某一端口是否开放。查看端口可以这样来使用，我就以80端口为例：lsof -i:80如果有显示说明已经开放了，如果没有显示说明没有开放2.netstat -aptn执行看看，是否监听在0.0.0.0:33063.netstat -nupl (UDP类型的端口)netstat -ntpl (TCP类型的端口)4.查看端口的状态/etc/init.d/iptables status Netstat -antsocket Recv-Q 是否积压，积压值较大且长时间没有清空 调大 /proc/sys/net/ipv4/tcp_rmem，如果问题不能解决说明发送端发送流量确实较大，超过了接收端的处理速度，需要分流","link":"/2020/06/08/technology/%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98%E8%BF%90%E7%BB%B4%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"title":"面试八股之编码","text":"面试八股之编码C++ 1.全局变量可不可以定义在可被多个.C文件包含的头文件中？为什么？ 可以，在不同的C文件中以static形式来声明同名全局变量。可以在不同的C文件中声明同名的全局变量，前提是其中只能有一个C文件中对此变量赋初值，此时连接不会出错. 2.static全局变量与普通的全局变量有什么区别？static局部变量和普通局部变量有什么区别？Static函数与普通函数有什么区别？ (1)把全局变量改变为静态变量后是改变了它的作用域，限制了它的使用范围。 全局变量(外部变量)的说明之前再冠以static 就构成了静态的全局变量。全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。 这两者在存储方式上并无不同。这两者的区别在于非静态全局变量的作用域是整个源程序， 当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的。 而静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。(2)把局部变量改变为静态变量后是改变了它的存储方式即改变了它的生存期。(3)static函数与普通函数作用域不同,仅在本文件。 综上所述: static全局变量与普通的全局变量有什么区别： static全局变量只初使化一次，防止在其他文件单元中被引用; static局部变量和普通局部变量有什么区别： static局部变量只被初始化一次，下一次依据上一次结果值； static函数与普通函数有什么区别： static函数在内存中只有一份，普通函数在每个被调用中维持一份拷贝 3.以下代码存在的问题？ char string[] = “Linux C”; char *p = “Linux C”; string[0] = 'a'; p[0] = 'a'; 注：”Linux C”是一个字符串常量。C语言对于字符串常量通常是这样处理的：在内存中开辟一个字符数组来存储该字符串常量，并把开辟出的字符数组的首地址赋给p. 注：string[0] = ‘a’是可以的，而p[0] = ‘a’是非法的，因为p指向的是字符串常量，常量的内容不可改变。把p指向一个字符串常量或字符数组时合法的，例如：p = “Hello World!”; p= string; 写一个实现字符串拷贝的函数。给定字符串拷贝函数strcpy的原型：char *strcpy(char *dest,const char *src); 要求：（1）不调用任何库函数。（2）说明函数为什么返回char *. char *strcpy(char *dest,char *src) { if( (dest == NULL) || (src == NULL) ) { return NULL; } char *ret_string = dest; while( *dest ++ = *src++)!=’\\0′); return ret_string; } Python 可变类型与不可变类型，如何判断一个变量是可变还是不可变 逻辑表达式中，哪些值是假？（0，空串，空容器，False，None） 列表和元组有什么不同？ range和xrange有什么区别？ for循环如何同时遍历索引和值 什么是静态方法，如何定义 静态方法和类方法的区别是什么？ list如何去重？ 如何判断字符串是否含有某个字串（in比str.find好）为什么？ is None和== None有什么区别？ 什么是GIL type isinstance区别 字符串拼接用 join和+的区别 python实现单例 Linux网络上机编程编程题本身不考察算法掌握程度，但是考察基本的逻辑思维，把算法转换为代码的能力，以及基本的错误处理。现场面试用纸笔，白板，电脑都可以，远程面试可以用在线代码平台，比如collabedit，codeshare.io，codeinterview.io复杂的算法不太容易验证，二十行内能解决的不太复杂的算法题为宜，速度越快越好，代码不能有明显的语法错误和低级错误，例如： 1. 纯算法 链表逆序 二叉树求宽度/深度 字符串处理：Split, Trim，逆序 编码：UTF8编解码，Varint编解码，十六进制编解码 数组去重，保持顺序 [1, 2, 3, 1, 2] -&gt; [1, 2, 3] 数组去重，保持顺序，后面的出现后，前面的去掉，[1, 2, 3, 2, 1] -&gt; [3, 2, 1] 位图中查找第一个设置/未设置的位的偏移量 2. 接口设计 比如String类的接口设计（构造函数，拷贝，赋值，拼接等），用数组实现循环队列 可以考察一些函数的实现，比如String类+=的实现，主要关注正确性和内存泄漏和越界 设计模式中间件人员本身 自我介绍 项目亮点难点 项目的领域模型可以画一下吗？ JD example腾讯云后端开发工程师（西安） 职责：负责腾讯云网络产品的研发与设计工作，打造更稳定、安全、高效和可靠的专业后台支撑体系， 保障海量网络业务的稳定运行。 必须具备的：1、本科及以上学历，计算机相关专业，三年以上后台开发工作经验；2、熟悉Linux操作系统下C++、python(或php)开发，能运用常见工具定位和调试问题代码；3、熟悉http、tcp/ip协议， 进程间通讯编程，多线程编程等，熟悉Linux常见网络服务器模型；4、具有扎实的软件开发基础知识，包括算法、操作系统、软件工程、设计模式、数据结构、数据库系统、网络安全等；5、具有良好的团队合作、沟通与口头、书面表达能力， 严谨的工作态度与高质量意识；6、对新技术敏感，求知欲强，能快速学习并具备较强的技术领悟能力。 有一定了解的：1、Shell 、 Perl 等脚本语言；2、MySQL及 SQL 语言、编程；3、Docker、K8s、Nginx等常用技术组件；4、常见的网络协议，包括但不限于arp、ip、vpn、gre等。 可以加分的：1、具备分布式系统设计与开发、负载均衡技术、系统容灾设计、高可用系统等知识；2、通过腾讯云从业资格证认证或同等资格认证。 注：此岗位为腾讯集团旗下全资子公司编制岗位 base 西安 雁塔区 **10、什么函数不能声明为虚函数？*******答：**constructor*** **12、不能做switch()的参数类型*******答** **：**switch的参数不能为实型。*** **14、如何引用一个已经定义过的全局变量？*******答** **、可以用引用头文件的方式，也可以用**extern关键字，如果用引用头文件方式来引用某个在头文件中声明的全局变量，假定你将那个变量写错了，那么在编译期间会报错，如果你用extern方式引用时，假定你犯了同样的错误，那么在编译期间不会报错，而在连接期间报错。*** 虚函数： 实现类的多态性 关键字：虚函数；虚函数的作用；多态性；多态公有继承；动态联编 C++中的虚函数的作用主要是实现了多态的机制。基类定义虚函数，子类可以重写该函数；在派生类中对基类定义的虚函数进行重写时，需要再派生类中声明该方法为虚方法。 当子类重新定义了父类的虚函数后，当父类的指针指向子类对象的地址时，[即B b; A a = &amp;b;] 父类指针根据赋给它的不同子类指针，动态的调用子类的该函数，而不是父类的函数（如果不使用virtual方法，请看后面★*），且这样的函数调用发生在运行阶段，而不是发生在编译阶段，称为动态联编。而函数的重载可以认为是多态，只不过是静态的。注意，非虚函数静态联编，效率要比虚函数高，但是不具备动态联编能力。 ★如果使用了virtual关键字，程序将根据引用或指针指向的 对 象 类 型 来选择方法，否则使用引用类型或指针类型来选择方法。 下面的例子解释动态联编性： ————————————————版权声明：本文为CSDN博主「BigoSprite」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/iFuMI/article/details/51088091 实现原理：虚函数表+虚表指针 关键字：虚函数底层实现机制；虚函数表；虚表指针 编译器处理虚函数的方法是：为每个类对象添加一个隐藏成员，隐藏成员中保存了一个指向函数地址数组的指针，称为虚表指针（vptr），这种数组成为虚函数表（virtual function table, vtbl），即，每个类使用一个虚函数表，每个类对象用一个虚表指针。 举个例子：基类对象包含一个虚表指针，指向基类中所有虚函数的地址表。派生类对象也将包含一个虚表指针，指向派生类虚函数表。看下面两种情况： 如果派生类重写了基类的虚方法，该派生类虚函数表将保存重写的虚函数的地址，而不是基类的虚函数地址。 如果基类中的虚方法没有在派生类中重写，那么派生类将继承基类中的虚方法，而且派生类中虚函数表将保存基类中未被重写的虚函数的地址。注意，如果派生类中定义了新的虚方法，则该虚函数的地址也将被添加到派生类虚函数表中。————————————————版权声明：本文为CSDN博主「BigoSprite」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/iFuMI/article/details/51088091 链接：https://www.nowcoder.com/questionTerminal/4ef1d67edee049c78aa597067c519246来源：牛客网 参见《Effective C++》 条款09：绝不在构造函数或析构函数中调用虚函数。 这个链接有电子档：http://blog.csdn.net/hxz_qlh/article/details/14089895 简要结论： １. 从语法上讲，调用完全没有问题。 ２. 但是从效果上看，往往不能达到需要的目的。 Effective 的解释是： 派生类对象构造期间进入基类的构造函数时，对象类型变成了基类类型，而不是派生类类型。 同样，进入基类析构函数时，对象也是基类类型。 所以，虚函数始终仅仅调用基类的虚函数（如果是基类调用虚函数），不能达到多态的效果，所以放在构造函数中是没有意义的，而且往往不能达到本来想要的效果。 2.3 依赖倒置原则 抽象不应该依赖于具体类，具体类应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。 依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。 在引入抽象层后，系统将具有很好的灵活性，在程序中尽量使用抽象层进行编程，而将具体类写在配置文件中，这样一来，如果系统行为发生变化，只需要对抽象层进行扩展，并修改配置文件，而无须修改原有系统的源代码，在不修改的情况下来扩展系统的功能，满足开闭原则的要求。 优点：通过抽象来搭建框架，建立类和类的关联，以减少类间的耦合性。而且以抽象搭建的系统要比以具体实现搭建的系统更加稳定，扩展性更高，同时也便于维护。 作者：xietao3链接：https://juejin.im/post/5c8756e6e51d456cda2e7ff1来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 单例模式（Singleton Pattern） 观察者模式(Observer Pattern)：定义对象之间的一种一对多依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象皆得到通知并被自动更新。观察者模式的别名包括发布-订阅（Publish/Subscribe）模式、模型-视图（Model/View）模式、源-监听器（Source/Listener）模式或从属者（Dependents）模式。观察者模式是一种对象行为型模式。 作者：xietao3链接：https://juejin.im/post/5c8756e6e51d456cda2e7ff1来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 3. 详细介绍一下TCP的四次挥手机制，为什么要有TIME_WAIT状态，为什么需要四次握手？服务器出现了大量CLOSE_WAIT状态如何解决当客户端要服务器断开连接时，客户端 TCP 会向服务器发送一个特殊的报文段，该报文段的 FIN 标志位会被置1，接着服务器会向客户端发送一个确认报文段。然后服务器也会客户端发送一个 FIN 标志位为1的终止报文段，随后客户端回送一个确认报文段，服务器立即断开连接。客户端等待一段时间后也断开连接。 其实四次挥手的过程是很容易理解的，由于 TCP 协议是全双工的，也就是说客户端和服务端都可以发起断开连接。两边各发起一次断开连接的申请，加上各自的两次确认，看起来就像执行了四次挥手。 为什么要有 TIME_WAIT 状态？因为客户端最后向服务器发送的确认 ACK 是有可能丢失的，当出现超时，服务端会再次发送 FIN 报文段，如果客户端已经关闭了就收不到了。还有一点是避免新旧连接混杂。 大量 CLOSE_WAIT 表示程序出现了问题，对方的 socket 已经关闭连接，而我方忙于读或写没有及时关闭连接，需要检查代码，特别是释放资源的代码，或者是处理请求的线程配置 \\3. TIME_WAIT状态 经过前面的铺垫，终于要讲到与本文主题相关的内容了。 ^_^ 从TCP状态迁移图可知，只有首先调用close()发起主动关闭的一方才会进入TIME_WAIT状态，而且是必须进入（图中左下角所示的3条状态迁移线最终均要进入该状态才能回到初始的CLOSED状态）。 从图中还可看到，进入TIME_WAIT状态的TCP连接需要经过2MSL才能回到初始状态，其中，MSL是指MaxSegment Lifetime，即数据包在网络中的最大生存时间。每种TCP协议的实现方法均要指定一个合适的MSL值，如RFC1122给出的建议值为2分钟，又如Berkeley体系的TCP实现通常选择30秒作为MSL值。这意味着TIME_WAIT的典型持续时间为1-4分钟。 TIME_WAIT状态存在的原因主要有两点： 1）为实现TCP这种全双工（full-duplex）连接的可靠释放 参考本文前面给出的TCP释放连接4次挥手示意图，假设发起active close的一方（图中为client）发送的ACK（4次交互的最后一个包）在网络中丢失，那么由于TCP的重传机制，执行passiveclose的一方（图中为server）需要重发其FIN，在该FIN到达client（client是active close发起方）之前，client必须维护这条连接的状态（尽管它已调用过close），具体而言，就是这条TCP连接对应的（local_ip, local_port）资源不能被立即释放或重新分配。直到romete peer重发的FIN达到，client也重发ACK后，该TCP连接才能恢复初始的CLOSED状态。如果activeclose方不进入TIME_WAIT以维护其连接状态，则当passive close方重发的FIN达到时，active close方的TCP传输层会以RST包响应对方，这会被对方认为有错误发生（而事实上，这是正常的关闭连接过程，并非异常）。 2）为使旧的数据包在网络因过期而消失 为说明这个问题，我们先假设TCP协议中不存在TIME_WAIT状态的限制，再假设当前有一条TCP连接：(local_ip, local_port, remote_ip,remote_port)，因某些原因，我们先关闭，接着很快以相同的四元组建立一条新连接。本文前面介绍过，TCP连接由四元组唯一标识，因此，在我们假设的情况中，TCP协议栈是无法区分前后两条TCP连接的不同的，在它看来，这根本就是同一条连接，中间先释放再建立的过程对其来说是“感知”不到的。这样就可能发生这样的情况：前一条TCP连接由local peer发送的数据到达remote peer后，会被该remot peer的TCP传输层当做当前TCP连接的正常数据接收并向上传递至应用层（而事实上，在我们假设的场景下，这些旧数据到达remote peer前，旧连接已断开且一条由相同四元组构成的新TCP连接已建立，因此，这些旧数据是不应该被向上传递至应用层的），从而引起数据错乱进而导致各种无法预知的诡异现象。作为一种可靠的传输协议，TCP必须在协议层面考虑并避免这种情况的发生，这正是TIME_WAIT状态存在的第2个原因。 具体而言，local peer主动调用close后，此时的TCP连接进入TIME_WAIT状态，处于该状态下的TCP连接不能立即以同样的四元组建立新连接，即发起active close的那方占用的local port在TIME_WAIT期间不能再被重新分配。由于TIME_WAIT状态持续时间为2MSL，这样保证了旧TCP连接双工链路中的旧数据包均因过期（超过MSL）而消失，此后，就可以用相同的四元组建立一条新连接而不会发生前后两次连接数据错乱的情况。 另一比较深入的说法 TIME_WAIT状态的存在有两个理由：（1）让4次握手关闭流程更加可靠；4次握手的最后一个ACK是是由主动关闭方发送出去的，若这个ACK丢失，被动关闭方会再次发一个FIN过来。若主动关闭方能够保持一个2MSL的TIME_WAIT状态，则有更大的机会让丢失的ACK被再次发送出去。（2）防止lost duplicate对后续新建正常链接的传输造成破坏。lost duplicate在实际的网络中非常常见，经常是由于路由器产生故障，路径无法收敛，导致一个packet在路由器A，B，C之间做类似死循环的跳转。IP头部有个TTL，限制了一个包在网络中的最大跳数，因此这个包有两种命运，要么最后TTL变为0，在网络中消失；要么TTL在变为0之前路由器路径收敛，它凭借剩余的TTL跳数终于到达目的地。但非常可惜的是TCP通过超时重传机制在早些时候发送了一个跟它一模一样的包，并先于它达到了目的地，因此它的命运也就注定被TCP协议栈抛弃。另外一个概念叫做incarnation connection，指跟上次的socket pair一摸一样的新连接，叫做incarnation of previous connection。lost duplicate加上incarnation connection，则会对我们的传输造成致命的错误。大家都知道TCP是流式的，所有包到达的顺序是不一致的，依靠序列号由TCP协议栈做顺序的拼接；假设一个incarnation connection这时收到的seq=1000, 来了一个lost duplicate为seq=1000, len=1000, 则tcp认为这个lost duplicate合法，并存放入了receive buffer，导致传输出现错误。通过一个2MSL TIME_WAIT状态，确保所有的lost duplicate都会消失掉，避免对新连接造成错误。 滑动窗口从上面的图可以看到滑动窗口左边的是已发送并且被确认的分组，滑动窗口右边是还没有轮到的分组。滑动窗口里面也分为两块，一块是已经发送但是未被确认的分组，另一块是窗口内等待发送的分组。随着已发送的分组不断被确认，窗口内等待发送的分组也会不断被发送。整个窗口就会往右移动，让还没轮到的分组进入窗口内。 可以看到滑动窗口起到了一个限流的作用，也就是说当前滑动窗口的大小决定了当前 TCP 发送包的速率，而滑动窗口的大小取决于拥塞控制窗口和流量控制窗口的两者间的最小值。 接着就讲讲什么是流量控制窗口，什么是拥塞控制窗口。 先讲流量控制： TCP 是全双工的，客户端和服务器均可作为发送方或接收方，我们现在假设一个发送方向接收方发送数据的场景来讲解流量控制。首先我们的接收方有一块接收缓存，当数据来到时会先把数据放到缓存中，上层应用等缓存中有数据时就会到缓存中取数据。假如发送方没有限制地不断地向接收方发送数据，接收方的应用程序又没有及时把接收缓存中的数据读走，就会出现缓存溢出，数据丢失的现象，为了解决这个问题，我们引入流量控制窗口。 假设应用程序最后读走的数据序号是 lastByteRead，接收缓存中接收到的最后一个数据序号是 lastByteRcv，接收缓存的大小为 RcvSize，那么必须要满足 lastByteRcv - lastByteRead &lt;= RcvSize 才能保证接收缓存不会溢出，所以我们定义流量窗口为接收缓存剩余的空间，也就是Rcv = RcvSize - (lastByteRcv - lastByteRead)。只要接收方在响应 ACK 的时候把这个窗口的值带给发送方，发送方就能知道接收方的接收缓存还有多大的空间，进而设置滑动窗口的大小。 接着讲解拥塞控制： 拥塞控制是指发送方先设置一个小的窗口值作为发送速率，当成功发包并接收到ACK时，便以指数速率增大发送窗口的大小，直到遇到丢包（超时/三个冗余ACK），才停止并调整窗口的大小。这么做能最大限度地利用带宽，又不至于让网络环境变得太过拥挤。 最终滑动窗口的值将设置为流量控制窗口和拥塞控制窗口中的较小值。 Q: 编写 TCP/SOCK_STREAM 服务程序时，SO_REUSEADDR到底什么意思？ A: 这个套接字选项通知内核，如果端口忙，但TCP状态位于 TIME_WAIT ，可以重用端口。如果端口忙，而TCP状态位于其他状态，重用端口时依旧得到一个错误信息， 指明”地址已经使用中”。如果你的服务程序停止后想立即重启，而新套接字依旧 使用同一端口，此时 SO_REUSEADDR 选项非常有用。必须意识到，此时任何非期 望数据到达，都可能导致服务程序反应混乱，不过这只是一种可能，事实上很不可能。 CLOSE_WAIT： 这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。 5. 讲一下HTTP与HTTPS的区别HTTP和HTTPS的主要区别在于HTTP协议传递的是明文数据，而HTTPS传递的是加密过的数据，也就是说HTTPS更具有安全性。也正由HTTPS需要保证安全性，所以它的性能要比HTTP差一点。 单说安全性肯定是不够的，我打算扩展讲一下HTTPS是怎么解决安全性问题的，通过这些HTTP没有机制，反映出HTTPS与HTTP的区别。下面尝试把HTTPS加密的过程推导出来。推导过程不涉及复杂的实现细节： 如何安全地进行数据传输？假设现在A和B要进行安全的通信，那么究竟怎样才算是安全的通信？很自然地会想到：A和B之间传递数据，这些数据只有A和B才看得懂，中间人就算截取了信息但也看不懂，这才算得上安全。 安全通信的处理手段：为了能让A和B才能看懂，就必须要对数据进行加密，而且首先想到的就是对称加密。对称加密的意思是A和B各持有一个相同的密钥，它们传递信息时会用密钥给信息加密，在消息到达端给消息解密，完成安全通信。 在对称加密中又会涉及到加密算法的选择问题。现实世界中，通常是多个客户端面向一个服务器的情况，不可能让每个客户端和服务器之间都采用相同的加密算法，如果是这样那和没加密差不多。所以注定每个客户端和服务器之间都会采用不同的加密方式。 如何让每个客户端与服务器之间都采用不同的加密方式？要想对不同的机器使用不同的加密方式，最直接想到的就是使用随机数。也就说客户端和服务器之间每次都基于一个随机数产生加密算法。（具体实现时为了保证随机，用到还不止一个随机数） 这个产生加密算法的过程称之为协商，现在问题是协商的过程是透明的，也就是说中间人可以截获协商的过程，从而知道我们的加密方式。为了解决这个问题，我们需要对协商的过程进行加密。 如何对协商的过程进行加密？之所以能来到这一步，是因为我们一开始就选择使用了对称加密，也就说一开始的对称加密导致了现在的问题，所以这时我们不能再使用对称加密了，否则会陷入死循环。 在密码学领域，还有一种加密过程叫非对称加密，它的逻辑是这样的：通信双方一方持有私钥，一方持有公钥，经过私钥加密的信息，都能通过公钥进行解密。但是经过公钥加密的数据，只有私钥可以解密。 按照非对称加密的规则，我们让服务器持有私钥，让客户端持有公钥。这样就能保证客户端给服务器发送消息的时候是安全的（相反，服务器给客户端发送消息就是不安全的），我们可以把协商时重要的逻辑安排在客户端给服务器发送信息的过程中，从而保证了协商过程的安全性。 客户端如何获得公钥？现在用非对称加密算法解决了协商的安全问题，但是非对称加密的前提是客户端需要获得公钥，这又是一个问题了，客户端与服务器打交道之前是互不知道双方身份的，怎么才能让客户端获得公钥呢？ 也就只有两种办法： 客户端向服务器要公钥 客户端向一个远程的公共服务器获取公钥 方法2显然是不行的，尚且不说多了一个访问节点，如何找到公共服务器的地址也是一个待解决的问题，所以还是使用方法1。 但是方法1存在一个问题：如果中间人把服务器发送给客户端的公钥调包了怎么办？也就是说客户端无法知道发送公钥的是否是正真的服务器。 引入第三方机构解决问题客户端无法辨识服务端和中间人的问题称为“身份验证”问题，也就是说我们需要为服务器向客户端发送公钥的过程进行加密。 这下完了，之前我们因遇到对称加密的瓶颈选择了非对称加密，现在使用非对称加密也遇到了瓶颈。显然这两种加密方式都是不可用的了，否则会再次陷入死循环。 接下来我们只好通过第三方机构的介入，解决这个问题。首先我们自己保存有第三方权威机构的公钥，然后第三方机构使用私钥对服务器将要发送给客户端的公钥进行加密，客户端接收到这个经加密的公钥后（数字证书），就能通过自己保存的第三方机构公钥进行解密。 到这里为止，我们解释了HTTPS中使用到的对称加密，非对称加密，CA，数字证书的概念，但是还差一个叫数字签名的概念没有解释。 在现实生活中，CA不单止会给我们正常公司发放证书，还会给中间人的坏公司发放证书，如果中间人把发放的证书调包了怎么办？这时我们仍能用CA的私钥进行解密，但是证书已经被调包了。 那么客户端怎样验证证书的真伪呢？答案是证书本身会告诉客户端如何辨认真伪。比方说证书上面有一个证书编号，还有一个如何计算证书编号的方法，客户端可以根据计算证书编号的方法计算出自己要获得的证书的编号，然后把这个编号和证书上的编号进行比对，如果一样证明没有被调包。 这里的证书编号指的就是数字签名，证书指的就是数字证书。 总结一下HTTPS：HTTPS想要保证客户端与服务器之间的通信安全，就得使用对称加密算法进行加密。协商对称加密算法的过程通过非对称加密算法来保证。在非对称加密算法中，客户端获得公钥的过程需要第三方机构（CA）通过颁发数字证书保证安全性。 总得来说通过这一系列机制协商出了一个对称加密算法后，客户端与服务器之间就能通过该算法进行安全的通信了 进程、线程、协程概念性区别对于进程、线程，都是有内核进行调度，有CPU时间片的概念，进行抢占式调度（有多种调度算法）。 对于协程(用户级线程)，这是对内核透明的，也就是系统并不知道有协程的存在，是完全由用户的程序自己调度的，因为是由用户程序自己控制，那么就很难像抢占式调度那样做到强制的CPU控制权切换到其他进程/线程，通常只能进行协作式调度，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到。 goroutine 和协程区别 本质上，goroutine 就是协程。 不同的是，Golang 在 runtime、系统调用等多方面对 goroutine 调度进行了封装和处理，当遇到长时间执行或者进行系统调用时，会主动把当前 goroutine 的CPU (P) 转让出去，让其他 goroutine 能被调度并执行，也就是 Golang 从语言层面支持了协程。 其他方面不同 3.1 内存消耗方面 每个 goroutine (协程) 默认占用内存远比 Java 、C 的线程少。goroutine: 2KB线程: 8MB 3.2 线程/goroutine 切换(调度)开销方面 线程/goroutine 切换开销方面，goroutine 远比线程小线程: 涉及模式切换(从用户态切换到内核态)、16个寄存器、PC、SP…等寄存器的刷新等。goroutine: 只有三个寄存器的值修改 - PC / SP / DX. 进程是程序执行的一个实例, 担当分担系统资源的实体. 进程是分配资源的基本单位，也是我们说的隔离。线程作为独立运行和独立调度的基本单位 进程切换只发生在内核态 线程(用户级线程/内核级线程) 线程是进程的一个执行流, 线程是操作系统能够进行运算调度的最小单位 对于进程和线程,都是有内核进行调度,有 CPU 时间片的概念, 进行抢占式调度 线程可以在启动前设置栈的大小,启动后,线程的栈大小就固定了 内核由系统内核进行调度, 系统为了实现并发,会不断地切换线程执行, 由此会带来线程的上下文切换. 协程 Goroutine 是协程的go语言实现 协程(用户态线程)是对内核透明的, 也就是系统完全不知道有协程的存在, 完全由用户自己的程序进行调度 在栈大小分配方便,且每个协程占用的默认占用内存很小,只有 2kb ,而线程需要 8mb,相较于线程,因为协程是对内核透明的,所以栈空间大小可以按需增大减小 在调度方面, 相较于线程,go 有自己的一套运行时调度系统,go的调度器类似于内核调度器, 而他不需要进行内核的上下文切换, 所以重新调度一个 Goroutine 的开销会小于重新调度线程的开销 协程与线程主要区别是它将不再被内核调度，而是交给了程序自己而线程是将自己交给内核调度，所以也不难理解golang中调度器的存在 cpp 一个C++对象的大小由哪些因素决定？基类，成员，内存对齐，虚函数。 C++对象的成员函数对对象大小有什么影响？是否有虚函数，虚函数的个数多少对对象大小有什么影响？ 一个C++对象的初始化顺序是什么？ 虚析构函数有什么用途？ new operator和operator new什么区别和联系？ 什么是placement new？ STL迭代器按照支持的操作分为哪几类？ Map和UnorderedMap的主要区别是什么？如何选择？ UnorderedMap如何解决Hash冲突？ Deque和Vector有什么区别？ 什么是RAII机制？ 在C++中，如何避免内存泄漏？ 智能指针有哪些？什么用途？ linux 个进程的多个线程之间，那些资源是共享的，哪些是私有的？ 多个线程之间，线程同步和通讯的原语主要有哪些？ 进程间通讯的方式有哪些？（共享内存，消息队列，管道，信号量，信号等） 程序崩溃了，如何定位崩溃点？ 程序崩溃时，常见的主要有那些信号？ 内存泄漏如何调试？如何预防？ SSD和机械硬盘的主要区别是什么？ SSD的写放大是什么意思？ 不懂Linux的，Linux相关的问题可以不知道。 \\6. 数据库的事务的4个特性是什么？并发事务会带来什么问题？ 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 并发事务的问题： 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。 不可重复读（Unrepeatableread）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 事务隔离的级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。（MySQL默认） SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 上机面试问题 1）TCP/IP协议 1）三次握手/四次挥手过程 2）TIME_WAIT状态 1）主动关闭/被动关闭 2）需要的原因 3）缓解措施 4）有没有方式不出现TIME_WAIT状态 3）RST出现的场景 4）滑动窗口2）网络编程 1）EPOLL/SELECT的区别 2）边沿触发/水平触发 3）事件触发的场景 1）读事件 有哪些场景 2）写事件 有哪些场景 4）READ调用返回值场景 1）0 2）-1 3）&gt;0 5）UDP客户端可以CONNECT不，那CONNECT和不CONNECT有啥区别3）后台编程 1）FORK的用途，FORK区分父子进程方式 2）进程间通信方式 3）僵尸进程 4）内存模型，有哪些段构成 5）进程/线程/协程的区别4）常见中间件 1）MYSQL 1）为啥不建议SELECT * 2）覆盖索引 3）分页优化 2）ZOOKEEPER 1）有哪些WATCH以及对应唤醒事件 3）KAFKA 1）分区分服 2）生产者 3）消费者5）语言 1）JAVA语言 1）内存管理6）设计模式 1）单例模式7）项目中的难点、挑战点 22989-腾讯云网络后台开发工程师(CSIG全资子公司)（西安） 建议用online ddl（网上可以查）修改，就是逗号后面的参数另外，添加字段要加上after，根据表结构看看fromWanIp适合在哪个字段后ALTER TABLE cEip ALTER COLUMN ispId SET DEFAULT -1, ALGORITHM=INPLACE, LOCK=NONE; python1. 基础语法 可变类型与不可变类型，如何判断一个变量是可变还是不可变 python的函数传参是值传递还是引用传递 逻辑表达式中，哪些值是假？（0，空串，空容器，False，None） 列表和元组有什么不同？ range和xrange有什么区别？ for循环如何同时遍历索引和值 什么是静态方法，如何定义 静态方法和类方法的区别是什么？ list如何去重？ 如何判断字符串是否含有某个字串（in比str.find好）为什么？ is None和== None有什么区别？ 什么是GIL, 多线程多进程 type isinstance区别 字符串拼接用 join和+的区别 list、set、tuple 区别，实现细节、效率 python中的封装、继承、多态 2. python编码 python实现单例（多种） python实现带参数、带返回值的装饰器（统计函数执行时间为例等，函数名覆盖问题） 12345678910111213141516171819 import functoolsimport timedef timer(func): @functools.wraps(func) def wrapper(*args, **kwargs): start_time = time.time() result = func(*args, **kwargs) end_time = time.time() print(f'{func.__name__} took {end_time - start_time:.6f}s.') return result return wrapper @timer def my_func(x, y): time.sleep(1) return x + y result = my_func(3, 4) print(result) 如果需要传递额外参数给装饰器，可以在装饰器外层再添加一层函数，例如： 123456789101112131415161718def repeat(n=3): def decorator(func): @functools.wraps(func) def wrapper(*args, **kwargs): for i in range(n): result = func(*args, **kwargs) return result return wrapper return decorator@repeat(n=5)def my_func(x, y): time.sleep(1) return x + yresult = my_func(3, 4)print(result) repeat是一个外层函数，用于接收额外参数n，并返回一个内层函数decorator。decorator函数则是真正的装饰器函数，接受一个函数作为参数，并返回一个内部函数wrapper。wrapper函数接受任意数量的位置参数和关键字参数，并调用原函数，重复执行n次，并返回最后一次函数执行结果。 总之，Python的装饰器是一种强大的语法特性，可以用于对函数进行增强、统计函数执行时间等操作，提高程序的可维护性和可扩展性。在使用装饰器时，应该注意保留原函数名，避免装饰器对函数名造成覆盖。 合并两个数组、排序","link":"/2023/10/08/technology/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A1%E4%B9%8B%E7%BC%96%E7%A0%81/"},{"title":"面试八股之操作系统","text":"面试八股之操作系统1. Basic Concept进程、线程、协程概念性区别 对于进程、线程，都是==由内核进行调度，有CPU时间片的概念，进行抢占式调度（有多种调度算法）==。 对于协程(用户级线程)，这是对内核透明的，也就是系统并不知道有协程的存在，是完全==由用户的程序自己调度的，因为是由用户程序自己控制，那么就很难像抢占式调度那样做到强制的CPU控制权切换到其他进程/线程，通常只能进行协作式调度，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到==。 进程是程序执行的一个实例, 担当分担系统资源的实体.进程是分配资源的基本单位，也是我们说的隔离。进程切换只发生在内核态。 线程作为独立运行和独立调度的基本单元。线程(用户级线程/内核级线程)，线程是进程的一个执行流，线程是操作系统能够进行运算调度的最小单位, 对于进程和线程,都是由内核进行调度,有 CPU 时间片的概念, 进行抢占式调度,线程可以在启动前设置栈的大小,启动后,线程的栈大小就固定了, 内核由系统内核进行调度, 系统为了实现并发,会不断地切换线程执行, 由此会带来线程的上下文切换. 协程(用户态线程)是对内核透明的, 也就是系统完全不知道有协程的存在, 完全由用户自己的程序进行调度，在栈大小分配方便,且每个协程占用的默认占用内存很小,只有 2kb ,而线程需要 8mb,相较于线程,因为协程是对内核透明的,所以栈空间大小可以按需增大减小， 在调度方面, 相较于线程，协程与线程主要区别是它将不再被内核调度，而是交给了程序自己而线程是将自己交给内核调度。python中threading创建的是内核级线程，gevent创建的是用户级线程（即线程） 进程间通信的方式有哪些，以及各自的优劣？ 最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。匿名管道顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则。 消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。 每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程，主要有以下两个原因：1. 安全性：操作系统为了保障系统的安全性，在进程间进行数据传输时，需要对数据进行检查和验证。这个过程需要从用户态切换到内核态，然后再切换回用户态，因此会导致数据拷贝。2. 数据结构不同：内核态和用户态的地址空间是分离的，它们所使用的数据结构也不同。当一个进程想要向消息队列中写入或读取数据时，需要将数据从当前进程的用户态地址空间复制到内核态的地址空间中；而另一个进程想要读取数据时，需要将数据从内核态的地址空间复制到当前进程的用户态地址空间中。这种数据结构不同也会导致数据拷贝。虽然数据拷贝会带来一定的开销，但是由于操作系统需要对数据进行检查和验证，而且内核态和用户态的数据结构不同，因此无法避免每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。消息队列是一种通过消息传递进行进程间通信的机制，它允许多个进程向一个共享的消息队列发送和接收数据。消息队列可以独立于发送和接收进程存在，因此可以轻松实现一对多或多对一的通信模式，而且可以选择不同的消息优先级。缺点是如果发送方频率过快，则接收方可能无法及时处理所有消息，导致消息队列溢出。 共享内存可以==解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，共享内存是一种高效的进程间通信方式，它可以直接将进程地址空间中的某一块区域映射到另一个进程的地址空间中。由于共享内存不需要进行数据的复制和拷贝，所以它可以提供高效的数据传输速度。==但是，由于多个进程访问同一块共享内存区域容易造成数据混乱和死锁问题，因此需要进行同步控制。它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。那么，就需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。 ==信号量是一种进程间同步和互斥机制。通过设置信号量来表示临界资源的使用情况，从而协调多个进程之间的并发访问。它主要用于解决系统中竞争资源的分配问题，如共享内存、文件等。但是，如果信号量的使用不当，可能会导致死锁或者饥饿等问题。==信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。信号量是一种进程间同步和互斥机制，它的主要作用是对临界资源进行保护。为了实现这个目的，信号量提供了两个基本操作：P（wait）和V（signal），它们分别用于对信号量的值进行减一和加一操作。具体来说，P操作和V操作的含义如下： P操作（等待操作）P操作用于申请对共享资源的访问权限。如果当前信号量的值大于0，则可以直接访问共享资源，并将信号量的值减一；否则需要阻塞等待，直到其他进程释放资源并通知该进程可以访问共享资源为止。 12345678P(semaphore) { while (semaphore &lt;= 0) { // 阻塞当前进程 sleep(); } semaphore--; } V操作（释放操作）V操作用于释放共享资源。当一个进程使用完共享资源之后，就需要将信号量的值加一，以便其他进程能够继续使用该资源。 12345V(semaphore) { semaphore++; // 唤醒一个等待该资源的进程 wakeup(); } 与信号量名字很相似的叫信号，它俩名字虽然相似，但功能一点儿都不一样。信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SIGSTOP，这是为了方便我们能在任何时候结束或停止某个进程 前面说到的通信机制，都是工作于同一台主机，如果要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。它具有通用性、可移植性和灵活性, 但是，由于套接字需要进行网络传输，因此会存在数据传输的延迟和不可靠性。 内核态和用户态区别？内核态的底层操作有什么？为什么要分两个不同的态？内核态和用户态是操作系统中的两种运行模式。它们的主要区别在于权限和可执行的操作：内核态（Kernel Mode）：==在内核态下，CPU 可以执行所有的指令和访问所有的硬件资源。这种模式下的操作具有更高的权限，主要用于操作系统内核的运行。内核态的底层操作主要包括：内存管理、进程管理、设备驱动程序控制、系统调用等。这些操作涉及到操作系统的核心功能，需要较高的权限来执行。==用户态（User Mode）：==在用户态下，CPU 只能执行部分指令集，无法直接访问硬件资源。这种模式下的操作权限较低，主要用于运行用户程序。==分为内核态和用户态的原因主要有以下几点： 安全性：通过对权限的划分，用户程序无法直接访问硬件资源，从而避免了恶意程序对系统资源的破坏。 稳定性：用户态程序出现问题时，不会影响到整个系统，避免了程序故障导致系统崩溃的风险。 隔离性：内核态和用户态的划分使得操作系统内核与用户程序之间有了明确的边界，有利于系统的模块化和维护。内核态和用户态的划分有助于保证操作系统的安全性、稳定性和易维护性 IO多路复用 ， 理解select和poll、epoll使用， epoll水平、边缘触发的区别，EAGAIN，accept处理新增链接Linux shell命令、问题排查、管道等一个进程的多个线程之间，那些资源是共享的，哪些是私有的？在进程中，线程是执行程序的最小单位。每个线程都有自己的栈空间和寄存器等私有资源，但是它们也可以共享进程的资源。进程中的多个线程可以共享以下资源： 进程地址空间：所有线程都可以访问进程的全局变量、静态变量、常量、堆区和代码段等资源 文件描述符：在UNIX系统中，每个进程都有一张打开文件的表格，其中每个打开文件对应一个文件描述符。这些文件描述符是共享的，因此，在不同的线程中打开或关闭文件可能会影响其他线程。 信号处理函数：进程中的所有线程都共享同样的信号处理函数。 进程中的多个线程各自拥有以下资源： 栈空间：每个线程都有自己的栈空间，用于保存局部变量、函数返回地址和参数等数据。 寄存器：每个线程都有自己的寄存器，用于保存临时变量和计算结果等数据。 线程ID：每个线程有自己独立的线程ID，用于表示该线程的唯一身份标识符。 CPU时间：每个线程都有自己的CPU时间，用于记录该线程在CPU上的执行时间。 多个线程之间，线程同步和通讯的原语主要有哪些？线程同步是指多个线程对共享资源进行访问或修改时，需要保证数据的一致性和正确性。为了实现线程同步，可以采用以下几种方式： 互斥锁。互斥锁是一种基本的线程同步机制，它通过给共享资源加锁来确保在任何时刻只有一个线程能够访问共享资源，从而避免数据竞争和冲突。 优点：简单易用，容易实现。可以有效地避免数据竞争和冲突。 缺点：常常会导致死锁问题。在高并发场景下，由于每个线程都需要抢占锁资源，可能会导致性能瓶颈。 条件变量条件变量是一种高级的线程同步机制，用于在多个线程之间进行通信。它允许线程等待某个条件成立后再继续执行，从而避免了线程忙等的情况。 优点：可以有效地避免线程忙等的情况。提供了更精细的线程同步控制。 缺点：实现相对较为复杂。可能会导致死锁问题。 屏障屏障是一种同步机制，用于控制多个线程在某一点上等待，直到所有线程都到达这一点后才能继续执行。它通常用于实现模拟多进程程序的并行计算，以及一些需要复杂同步的算法。 优点：提供了更精细的线程同步控制。可以有效地避免数据竞争和冲突。 缺点：实现相对较为复杂。在高并发场景下，可能会导致性能瓶颈。 读写锁读写锁是一种特殊的互斥锁，它允许多个线程同时读取共享资源，但只允许一个线程写入共享资源。读写锁可以提高程序的并发性能，适用于读多写少的场景。 优点：可以提高程序的并发性能。可以有效地避免数据竞争和冲突。 缺点：实现相对较为复杂。在高写并发场景下，可能会导致性能瓶颈。 原子操作原子操作是指不可中断的操作，即在执行过程中不能被其他线程打断。在多线程编程中，原子操作可以保证对共享数据的修改是原子的、不可分割的，从而避免了数据竞争和冲突。 优点：简单易用，容易实现。可以有效地避免数据竞争和冲突。可以提高程序的性能。 缺点：仅适用于对共享资源进行简单修改的场景。无法提供更精细的线程同步控制。总之，在多线程编程中，线程同步是确保程序正确性的关键所在。不同的线程同步方式各有优缺点，应该根据具体场景选择合适的方式，以获得最佳的性能和可靠性。 如何优化线程锁带来的效率问题？互斥锁是一种基本的线程同步机制，它通过给共享资源加锁来确保在任何时刻只有一个线程能够访问共享资源，从而避免数据竞争和冲突。然而，在高并发场景下，由于每个线程都需要抢占锁资源，可能会导致性能瓶颈。为了优化互斥锁带来的线程同步的性能问题，可以采用以下几种策略： 减小锁粒度如果一个共享资源被多个线程频繁访问，但实际上只有很少的代码段需要对其进行修改，那么可以将锁的粒度减小到这些代码段上，从而降低锁的争用率。例如，可以使用读写锁或者细粒度锁等方式来减小锁粒度。 避免长时间持有锁如果一个线程需要在临界区内执行耗时较长的操作，那么最好在操作之前先释放锁资源，待操作完成后再重新获取锁资源。这样可以减少其他线程的等待时间，提高程序的并发性能。 线程局部存储对于一些只在单个线程中使用的变量，可以将其存储在该线程的局部存储中，避免使用互斥锁来进行同步。这样可以减少线程之间的竞争，提高程序的执行效率。 无锁算法对于一些数据结构和算法，可以使用无锁算法来实现线程间同步。无锁算法通过原子操作和内存屏障等技术来保证数据的一致性和正确性，从而避免了锁带来的性能瓶颈。 使用协程或异步编程协程和异步编程是一种基于事件驱动的程序设计模式，在其内部实现中通常不需要使用互斥锁来进行同步。因此，如果能够采用协程或异步编程的方式来重构代码，也可以有效地提高程序的并发性能。 总之，在优化互斥锁带来的线程同步的性能问题时，需要根据具体情况选择合适的策略，以获得最佳的性能和可靠性。同时，需要注意在优化过程中不要引入新的竞争条件和安全漏洞。 根据不同的场景使用不同的锁- 无锁算法来实现线程间同步无锁算法是一种多线程编程的技术，它通过使用原子操作和内存屏障等底层机制来实现对共享资源的访问和修改，从而避免了使用锁所带来的性能瓶颈。具体来说，无锁算法通常具有以下几个特点： 原子操作 无锁算法通常使用原子操作来保证对共享资源的修改是原子的、不可分割的。原子操作是指一组操作在任何情况下都是不可中断的，在执行过程中不能被其他线程打断。例如，C++11标准中提供的std::atomic类型就可以用来实现原子操作。 内存屏障 无锁算法还通常使用内存屏障来保证数据的一致性和正确性。内存屏障是一种CPU指令，可以强制处理器按照程序员指定的顺序执行内存操作，从而确保数据的正确性。例如，在x86架构下，可以使用MFENCE指令来创建内存屏障。 自旋 由于无锁算法不使用锁来进行同步，因此在高并发场景下可能会出现多个线程竞争同一个共享资源的情况。为了解决这个问题，无锁算法通常使用自旋来等待共享资源的可用性。自旋是指线程在访问共享资源时不断地重试，直到资源可用为止。 总之，无锁算法通过使用原子操作和内存屏障等底层机制来保证对共享资源的访问和修改是安全的、不会出现数据竞争和冲突的。相比于锁机制，无锁算法可以提高程序的并发能力，减少锁带来的性能瓶颈。但是，无锁算法的实现比较复杂，容易引入新的竞争条件和安全漏洞，需要谨慎使用和调试。 程序崩溃了，如何定位崩溃点？ 程序崩溃时，常见的主要有那些信号？ 内存泄漏如何调试？如何预防？ SSD和机械硬盘的主要区别是什么？ SSD的写放大是什么意思？ 不懂Linux的，Linux相关的问题可以不知道。 进程&amp;线程 ，常用进程通讯方式、线程间资源竞争问题，线程同步问题 Proactor、reactor模式区别，知道通过多线程线程提高并发\\6. 数据库的事务的4个特性是什么？并发事务会带来什么问题？ 原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； 隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 多线程锁是什么多线程锁是一种用来保护共享资源的机制。在多线程编程中，如果多个线程同时访问同一个共享资源，可能会发生竞态条件（Race Condition），导致程序的行为出现未定义的情况。为了避免这种情况的发生，可以使用多线程锁来保护共享资源。 多线程锁的基本思想是，在访问共享资源之前先获取锁，访问完成之后再释放锁。这样可以保证同一时刻只有一个线程可以访问共享资源，从而避免竞态条件的发生。 常见的多线程锁包括==互斥锁、读写锁、条件变量==等。其中，互斥锁用于保护共享资源的访问，读写锁用于在读多写少的情况下提高并发性能，条件变量用于线程之间的同步和通信。 select/epoll的区别select 和 poll 的缺陷在于，当客户端越多，也就是 Socket 集合越大，Socket 集合的遍历和拷贝会带来很大的开销，因此也很难应对 C10K。 epoll 是解决 C10K 问题的利器，通过两个方面解决了 select/poll 的问题。 epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。 epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。 IO特别密集时epoll效率还高吗答：可以考虑select/poll，这种情况轮询也很高效，且结构简单。 补充： 可以先解释io特别密集时为什么 epoll 效率不高。原因是： 连接密集（短连接特别多），使用epoll的话，每一次连接需要发生epoll_wait-&gt;accpet-&gt;epoll_ctl调用，而使用select只需要select-&gt;accpet，减少了一次系统调用。 读写密集的话，如果收到数据，我们需要响应数据的话，使用epoll的情况下， read 完后也需要epoll_ctl 加入写事件，相比select多了一次系统调用 讲一讲ET、LT模式epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。 这两个术语还挺抽象的，其实它们的区别还是很好理解的。 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完； 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取； 举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。 这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。 如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。 如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I/O 搭配使用，程序会一直执行 I/O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。 一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。 对于一个后端服务，提升性能可以从以下几个方面入手： 优化算法和数据结构 在编写程序时，应该选择合适的算法和数据结构，以尽量减少程序的计算和存储时间。例如，在进行大规模数据处理时，应该使用散列表或者树型结构，而不是线性查找等慢速算法。 减少I/O操作 I/O操作通常是一个后端服务中最耗时的部分，因此应该尽量减少I/O操作的次数和时间。例如，在读取和写入文件时，可以使用缓冲区来批量读取和写入，从而减少I/O操作的次数。 使用多线程和异步编程 多线程和异步编程可以将一个任务拆分为多个子任务，并行执行，从而提高程序的处理能力和响应速度。例如，可以将一个数据处理任务拆分为多个线程或者进程，并使用消息队列来协调任务之间的数据传输。 应用缓存和内存池 缓存和内存池可以将一些常用的数据和资源预先加载到内存中，并重复利用这些数据和资源，从而减少程序的计算和存储时间。例如，在处理大量图片和视频时，可以使用缓存来缓存已经处理过的数据，避免重复计算。 负载均衡和服务治理 负载均衡和服务治理可以将一个后端服务分发到多个服务器上，从而提高程序的处理能力和稳定性。例如，可以使用Nginx等负载均衡软件来将请求分发到多个服务器上，并使用Zookeeper等服务治理软件来监控和管理服务器的状态和资源。 总之，对于一个后端服务，提升性能可以通过优化算法和数据结构、减少I/O操作、使用多线程和异步编程、应用缓存和内存池、以及负载均衡和服务治理等手段来实现。在实际编程中，应该根据具体情况选择合适的方法，并进行持续优化和监控，以确保程序的高效和稳定运行。 Linux内存管理、分配、回收、OOM问题。https://mp.weixin.qq.com/s/EsU9FT9D9K5Rt1BM0ySVmw 先来说说第一个问题：虚拟内存有什么作用？（如果你还不知道虚拟内存概念，可以看这篇：真棒！20 张图揭开内存管理的迷雾，瞬间豁然开朗） 第一，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的。这就解决了多进程之间地址冲突的问题。 第二，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。 然后今天主要是聊聊第二个问题，「系统内存紧张时，会发生什么？」 发车！ 内存分配的过程是怎样的？应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。 当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生缺页中断，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。 缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。 如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。 后台内存回收（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。 直接内存回收（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。 如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——触发 OOM （Out of Memory）机制。 OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。 申请物理内存的过程如下图： 哪些内存可以被回收？系统内存紧张的时候，就会进行回收内测的工作，那具体哪些内存是可以被回收的呢？ 主要有两类内存可以被回收，而且它们的回收方式也不同。 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。 匿名页（Anonymous Page）：应用程序通过 mmap 动态分配的堆内存叫作匿名页，这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。 文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中： active_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页； inactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页； 越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。 活跃和非活跃的内存页，按照类型的不同，又分别分为文件页和匿名页。可以从 /proc/meminfo 中，查询它们的大小，比如： 1# grep表示只保留包含active的指标（忽略大小写）# sort表示按照字母顺序排序[root@xiaolin ~]# cat /proc/meminfo | grep -i active | sortActive: 901456 kBActive(anon): 227252 kBActive(file): 674204 kBInactive: 226232 kBInactive(anon): 41948 kBInactive(file): 184284 kB 回收内存带来的性能影响在前面我们知道了回收内存有两种方式。 一种是后台内存回收，也就是唤醒 kswapd 内核线程，这种方式是异步回收的，不会阻塞进程。 一种是直接内存回收，这种方式是同步回收的，会阻塞进程，这样就会造成很长时间的延迟，以及系统的 CPU 利用率会升高，最终引起系统负荷飙高。 可被回收的内存类型有文件页和匿名页： 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。 可以看到，回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡。 下面针对回收内存导致的性能影响，说说常见的解决方式。 调整文件页和匿名页的回收倾向从文件页和匿名页的回收操作来看，文件页的回收操作对系统的影响相比匿名页的回收操作会少一点，因为文件页对于干净页回收是不会发生磁盘 I/O 的，而匿名页的 Swap 换入换出这两个操作都会发生磁盘 I/O。 Linux 提供了一个 /proc/sys/vm/swappiness 选项，用来调整文件页和匿名页的回收倾向。 swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页。 1[root@xiaolin ~]# cat /proc/sys/vm/swappiness0 一般建议 swappiness 设置为 0（默认就是 0），这样在回收内存的时候，会更倾向于文件页的回收，但是并不代表不会回收匿名页。 尽早触发 kswapd 内核线程异步回收内存 如何查看系统的直接内存回收和后台内存回收的指标？ 我们可以使用 sar -B 1 命令来观察： 图中红色框住的就是后台内存回收和直接内存回收的指标，它们分别表示： pgscank/s : kswapd(后台回收线程) 每秒扫描的 page 个数。 pgscand/s: 应用程序在内存申请过程中每秒直接扫描的 page 个数。 pgsteal/s: 扫描的 page 中每秒被回收的个数（pgscank+pgscand）。 如果系统时不时发生抖动，并且在抖动的时间段里如果通过 sar -B 观察到 pgscand 数值很大，那大概率是因为「直接内存回收」导致的。 针对这个问题，解决的办法就是，可以通过尽早的触发「后台内存回收」来避免应用程序进行直接内存回收。 什么条件下才能触发 kswapd 内核线程回收内存呢？ 内核定义了三个内存阈值（watermark，也称为水位），用来衡量当前剩余内存（pages_free）是否充裕或者紧张，分别是： 页最小阈值（pages_min）； 页低阈值（pages_low）； 页高阈值（pages_high）； 这三个内存阈值会划分为四种内存使用情况，如下图： kswapd 会定期扫描内存的使用情况，根据剩余内存（pages_free）的情况来进行内存回收的工作。 图中绿色部分：如果剩余内存（pages_free）大于 页高阈值（pages_high），说明剩余内存是充足的； 图中蓝色部分：如果剩余内存（pages_free）在页高阈值（pages_high）和页低阈值（pages_low）之间，说明内存有一定压力，但还可以满足应用程序申请内存的请求； 图中橙色部分：如果剩余内存（pages_free）在页低阈值（pages_low）和页最小阈值（pages_min）之间，说明内存压力比较大，剩余内存不多了。这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值（pages_high）为止。虽然会触发内存回收，但是不会阻塞应用程序，因为两者关系是异步的。 图中红色部分：如果剩余内存（pages_free）小于页最小阈值（pages_min），说明用户可用内存都耗尽了，此时就会触发直接内存回收，这时应用程序就会被阻塞，因为两者关系是同步的。 可以看到，当剩余内存页（pages_free）小于页低阈值（pages_low），就会触发 kswapd 进行后台回收，然后 kswapd 会一直回收到剩余内存页（pages_free）大于页高阈值（pages_high）。 也就是说 kswapd 的活动空间只有 pages_low 与 pages_min 之间的这段区域，如果剩余内测低于了 pages_min 会触发直接内存回收，高于了 pages_high 又不会唤醒 kswapd。 页低阈值（pages_low）可以通过内核选项 /proc/sys/vm/min_free_kbytes （该参数代表系统所保留空闲内存的最低限）来间接设置。 min_free_kbytes 虽然设置的是页最小阈值（pages_min），但是页高阈值（pages_high）和页低阈值（pages_low）都是根据页最小阈值（pages_min）计算生成的，它们之间的计算关系如下： 1pages_min = min_free_kbytespages_low = pages_min*5/4pages_high = pages_min*3/2 如果系统时不时发生抖动，并且通过 sar -B 观察到 pgscand 数值很大，那大概率是因为直接内存回收导致的，这时可以增大 min_free_kbytes 这个配置选项来及早地触发后台回收，然后继续观察 pgscand 是否会降为 0。 增大了 min_free_kbytes 配置后，这会使得系统预留过多的空闲内存，从而在一定程度上降低了应用程序可使用的内存量，这在一定程度上浪费了内存。极端情况下设置 min_free_kbytes 接近实际物理内存大小时，留给应用程序的内存就会太少而可能会频繁地导致 OOM 的发生。 所以在调整 min_free_kbytes 之前，需要先思考一下，应用程序更加关注什么，如果关注延迟那就适当地增大 min_free_kbytes，如果关注内存的使用量那就适当地调小 min_free_kbytes。 NUMA 架构下的内存回收策略 什么是 NUMA 架构？ 再说 NUMA 架构前，先给大家说说 SMP 架构，这两个架构都是针对 CPU 的。 SMP 指的是一种多个 CPU 处理器共享资源的电脑硬件架构，也就是说每个 CPU 地位平等，它们共享相同的物理资源，包括总线、内存、IO、操作系统等。每个 CPU 访问内存所用时间都是相同的，因此，这种系统也被称为一致存储访问结构（UMA，Uniform Memory Access）。 随着 CPU 处理器核数的增多，多个 CPU 都通过一个总线访问内存，这样总线的带宽压力会越来越大，同时每个 CPU 可用带宽会减少，这也就是 SMP 架构的问题。 SMP 与 NUMA 架构 为了解决 SMP 架构的问题，就研制出了 NUMA 结构，即非一致存储访问结构（Non-uniform memory access，NUMA）。 NUMA 架构将每个 CPU 进行了分组，每一组 CPU 用 Node 来表示，一个 Node 可能包含多个 CPU 。 每个 Node 有自己独立的资源，包括内存、IO 等，每个 Node 之间可以通过互联模块总线（QPI）进行通信，所以，也就意味着每个 Node 上的 CPU 都可以访问到整个系统中的所有内存。但是，访问远端 Node 的内存比访问本地内存要耗时很多。 NUMA 架构跟回收内存有什么关系？ 在 NUMA 架构下，当某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。 具体选哪种模式，可以通过 /proc/sys/vm/zone_reclaim_mode 来控制。它支持以下几个选项： 0 （默认值）：在回收本地内存之前，在其他 Node 寻找空闲内存； 1：只回收本地内存； 2：只回收本地内存，在本地回收内存时，可以将文件页中的脏页写回硬盘，以回收内存。 4：只回收本地内存，在本地回收内存时，可以用 swap 方式回收内存。 在使用 NUMA 架构的服务器，如果系统出现还有一半内存的时候，却发现系统频繁触发「直接内存回收」，导致了影响了系统性能，那么大概率是因为 zone_reclaim_mode 没有设置为 0 ，导致当本地内存不足的时候，只选择回收本地内存的方式，而不去使用其他 Node 的空闲内存。 虽然说访问远端 Node 的内存比访问本地内存要耗时很多，但是相比内存回收的危害而言，访问远端 Node 的内存带来的性能影响还是比较小的。因此，zone_reclaim_mode 一般建议设置为 0。 如何保护一个进程不被 OOM 杀掉呢？在系统空闲内存不足的情况，进程申请了一个很大的内存，如果直接内存回收都无法回收出足够大的空闲内存，那么就会触发 OOM 机制，内核就会根据算法选择一个进程杀掉。 Linux 到底是根据什么标准来选择被杀的进程呢？这就要提到一个在 Linux 内核里有一个 oom_badness() 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。 进程得分的结果受下面这两个方面影响： 第一，进程已经使用的物理内存页面数。 第二，每个进程的 OOM 校准值 oom_score_adj。它是可以通过 /proc/[pid]/oom_score_adj 来配置的。我们可以在设置 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。 函数 oom_badness() 里的最终计算方法是这样的： 1// points 代表打分的结果// process_pages 代表进程已经使用的物理内存页面数// oom_score_adj 代表 OOM 校准值// totalpages 代表系统总的可用页面数points = process_pages + oom_score_adj*totalpages/1000 用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大。 每个进程的 oom_score_adj 默认值都为 0，所以最终得分跟进程自身消耗的内存有关，消耗的内存越大越容易被杀掉。我们可以通过调整 oom_score_adj 的数值，来改成进程的得分结果： 如果你不想某个进程被首先杀掉，那你可以调整该进程的 oom_score_adj，从而改变这个进程的得分结果，降低该进程被 OOM 杀死的概率。 如果你想某个进程无论如何都不能被杀掉，那你可以将 oom_score_adj 配置为 -1000。 我们最好将一些很重要的系统服务的 oom_score_adj 配置为 -1000，比如 sshd，因为这些系统服务一旦被杀掉，我们就很难再登陆进系统了。 但是，不建议将我们自己的业务程序的 oom_score_adj 设置为 -1000，因为业务程序一旦发生了内存泄漏，而它又不能被杀掉，这就会导致随着它的内存开销变大，OOM killer 不停地被唤醒，从而把其他进程一个个给杀掉。 参考资料： https://time.geekbang.org/column/article/277358 https://time.geekbang.org/column/article/75797 https://www.jianshu.com/p/e40e8813842f 总结内核在给应用程序分配物理内存的时候，如果空闲物理内存不够，那么就会进行内存回收的工作，主要有两种方式： 后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。 直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。 可被回收的内存类型有文件页和匿名页： 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。 文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能。 针对回收内存导致的性能影响，常见的解决方式。 设置 /proc/sys/vm/swappiness，调整文件页和匿名页的回收倾向，尽量倾向于回收文件页； 设置 /proc/sys/vm/min_free_kbytes，调整 kswapd 内核线程异步回收内存的时机； 设置 /proc/sys/vm/zone_reclaim_mode，调整 NUMA 架构下内存回收策略，建议设置为 0，这样在回收本地内存之前，会在其他 Node 寻找空闲内存，从而避免在系统还有很多空闲内存的情况下，因本地 Node 的本地内存不足，发生频繁直接内存回收导致性能下降的问题； 在经历完直接内存回收后，空闲的物理内存大小依然不够，那么就会触发 OOM 机制，OOM killer 就会根据每个进程的内存占用情况和 oom_score_adj 的值进行打分，得分最高的进程就会被首先杀掉。 我们可以通过调整进程的 /proc/[pid]/oom_score_adj 值，来降低被 OOM killer 杀掉的概率。面试问题 1）TCP/IP协议 1）三次握手/四次挥手过程 2）TIME_WAIT状态 1）主动关闭/被动关闭 2）需要的原因 3）缓解措施 4）有没有方式不出现TIME_WAIT状态 3）RST出现的场景 4）滑动窗口2）网络编程 1）EPOLL/SELECT的区别 2）边沿触发/水平触发 3）事件触发的场景 1）读事件 有哪些场景 2）写事件 有哪些场景 4）READ调用返回值场景 1）0 2）-1 3）&gt;0 5）UDP客户端可以CONNECT不，那CONNECT和不CONNECT有啥区别3）后台编程 1）FORK的用途，FORK区分父子进程方式 2）进程间通信方式 3）僵尸进程 4）内存模型，有哪些段构成 5）进程/线程/协程的区别4）常见中间件 1）MYSQL 1）为啥不建议SELECT * 2）覆盖索引 3）分页优化 2）ZOOKEEPER 1）有哪些WATCH以及对应唤醒事件 3）KAFKA 1）分区分服 2）生产者 3）消费者5）语言 1）JAVA语言 1）内存管理6）设计模式 1）单例模式7）项目中的难点、挑战点 22989-腾讯云网络后台开发工程师(CSIG全资子公司)（西安） 建议用online ddl（网上可以查）修改，就是逗号后面的参数另外，添加字段要加上after，根据表结构看看fromWanIp适合在哪个字段后ALTER TABLE cEip ALTER COLUMN ispId SET DEFAULT -1, ALGORITHM=INPLACE, LOCK=NONE; FORK的用途，FORK区分父子进程方式fork()是Unix/Linux操作系统中一个重要的系统调用，它的主要作用是创建一个新的进程。下面是fork()函数的一些具体用途： 多进程并发 使用fork()函数可以创建一个与当前进程完全相同的子进程，并且这个子进程所拥有的数据、资源和代码段等都复制自父进程。这样，在不同进程之间就可以实现并发执行，提高程序的执行效率。 资源隔离和保护 在多进程并发的情况下，需要考虑如何进行资源隔离和保护。通过使用fork()函数创建多个进程，可以将不同的任务分配到不同的进程中运行，并且使用信号量、共享内存等机制来进行进程间的通信和同步，从而实现资源的隔离和保护。 守护进程 守护进程（daemon）是一种在后台运行的进程，独立于控制终端并且没有用户交互界面。在Unix/Linux操作系统中，守护进程通常是由fork()函数创建的子进程，并且使用setsid()函数将子进程转换为守护进程。 区分父子进程的方式包括以下两种： fork()函数的返回值 在父进程中，fork()函数返回子进程的PID（进程ID），在子进程中则返回0。通过判断fork()函数的返回值，可以区分父子进程。 进程ID（PID） 每个进程都有一个唯一的PID，可以通过系统调用getpid()来获取当前进程的PID，也可以通过fork()函数返回的PID来获取子进程的PID。在父进程和子进程中，它们分别具有不同的PID，从而可以区分父子进程。 总之，fork()函数是Unix/Linux操作系统中一个重要的系统调用，它可以创建一个新的进程，并且复制父进程的数据、资源和代码段等。通过使用fork()函数，可以实现多进程并发、资源隔离和保护、守护进程等功能。同时，它还可以通过进程ID和返回值来区分父子进程。","link":"/2023/10/08/technology/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A1%E4%B9%8B%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"title":"高效使用搜索","text":"高效使用搜索 排除关键词用减号 -： 锤子 -锤子手机 全词匹配用双引号扣起来 指定网站内搜索： site:zhihu.com 量化 指定文件格式：filetype:pdf 平凡的世界 指定标题搜索 intitle:关键词 指定范围搜索： Intext正文中包含 ：手机 intext:苹果 ulr中包含：inurl 正文包含多个关键词 allintext:后面加多个关键词，空格分割 叠加使用： site:douban.com 亲密关系 intext:罗兰 -爱情 注意： 所有符号都是半角，即英文符号 关键词之间加空格， 比如电脑蓝屏，换成：电脑 蓝屏 办法","link":"/2020/06/08/technology/%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8%E6%90%9C%E7%B4%A2/"},{"title":"面试问题汇总","text":"面试问题汇总1）TCP/IP协议 1）三次握手/四次挥手过程 2）TIME_WAIT状态 1）主动关闭/被动关闭 2）需要的原因 3）缓解措施 4）有没有方式不出现TIME_WAIT状态 3）RST出现的场景 4）滑动窗口2）网络编程 1）EPOLL/SELECT的区别 2）边沿触发/水平触发 3）事件触发的场景 1）读事件 有哪些场景 2）写事件 有哪些场景 4）READ调用返回值场景 1）0 2）-1 3）&gt;0 5）UDP客户端可以CONNECT不，那CONNECT和不CONNECT有啥区别3）后台编程 1）FORK的用途，FORK区分父子进程方式 2）进程间通信方式 3）僵尸进程 4）内存模型，有哪些段构成 5）进程/线程/协程的区别4）常见中间件 1）MYSQL 1）为啥不建议SELECT * 2）覆盖索引 3）分页优化 2）ZOOKEEPER 1）有哪些WATCH以及对应唤醒事件 3）KAFKA 1）分区分服 2）生产者 3）消费者5）语言 1）JAVA语言 1）内存管理6）设计模式 1）单例模式7）项目中的难点、挑战点","link":"/2023/08/19/technology/%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"},{"title":"投资基金","text":"投资基金风险评估 影响因素： 收入，年龄 保守型 5-10， 平衡 货币基金 沪深300指数基金, 大企 纯债式基金 中证500指数基金， 中小企 混合型基金 下一年初，调回平衡 天天基金， 参考前三的债股比例 。多留意市场动向。 稳健型-5， 11-16 % 不要货币基金（稳，收益低） 长期定投 积极法：加多一个行业板块股票基金 ，未来：生物医药， 人工智能， 新零售 进取型 -10， 17-25% 300+500+混+行业 更多的学习和关注 怎么买， 哪里买 除货币基金，其他都 要收费， 1.5% 平均的申购费 可以：基金公司，代销机构， 第三方 基金公司：易方达，华夏， 博时， 只能买到该公司的， 基乎不要申购费 代销：银行和证券公司，全，但不打折，证券账户， 太贵 第三方：基金大超市， 天天基金， 蚂蚁财富，腾讯理财通， 全而打折，适合小白。 推荐：天天基金搭配蚂蚁或腾讯 前端收费：买入时就给申购费（买入量大小 后端收费：卖时才收费（持有时间 长 卖出： 赎回费， 时间 越长越便宜 特殊：管理费，托管费，服务 费 单位净值， 份额 累计净值：单位净值 加 分红， 过去业绩或表现好不好 判断历史业绩 怎么看， 纵向对比： 同类基金中同一段时间的对比， 至少看3年历史 4433法则：好买基金网， - 4：选择两年，三年， 五年，今年以来业绩排名在同类基金中排名前1/4的基金 - 4：选择一年期业绩排名，在同类基金中提成名前1/4的基金 - 3：近6月在同类中排名前1/3 - 3: 近三个月业绩排名， 在同类基金中排名前1/3的 橫向对比，同期大盘涨跌参考 晨星评级， 天天基金的评级， 三年以上才有，晨星 4星或五星，天天基金国内至少两家机构的五星基金经理： 从业年限，穿越牛熊， 八年以上 历史业绩：管理过的基金， 从业期间表现如何。 天天基金 管理的基金数：不要超过6只， 除非是指数基金 指数基金（复制指数，按照指数的比例投资于成分股， 跟市场走， 无需加入主观的投资判断）， 超短债权基金（没有太大的升值空间， 好与坏在回报率上没有多大差别， ），对技术选股信赖比较深的基金：若基金依赖技术选股的程度很深，采用的技术模式非常多， 那么人为因素影响就会变得非常小， ——-以上，不需要特别关注基金经理的变化 基金公司 如：南方基金， 华夏基金， 易方达， 嘉实基金 风险评估 夏普比率：单位风险所获得的超额回报率， 即都 承担同样风险的情况下，看谁能获得更多的收益 ，预期收益同样的情况下，谁的风险更小。—– 较高时， 更好 标准 差： 越高，波多性越大。 低些好 如何判断高低： 晨星网， 以上， 可以按不同的侧重排优先级该拿出多少钱买基金 最佳状态：保证生活品质的同时，增值 标准普尔家庭资产象限图： 要花的钱：短期要用的。3-6月的生活费 保命的钱：社保等，保险。年收入的10% ， 一勺财商教育 风险投资，生钱的钱：股票， 基金 ， 100法则： （100-年龄） 保本：债权， 信托，银行理财 不要一刀切 三大策略 长线投资： 分散投资： 不同类型的基金， 组合， 低相关性， 有对冲性的分散。 分散在不同的基金公司和不同的基金经理， 国内与海外分散。 分段投资: 定投。 投多少只 四五只基金 ， 要有对冲意义的 基金定投 和单买的区别： 为什么定投： 强制储蓄， 积少成多 分批买入，摊分成本 无须择时，避免跟风 定投时间 周期： 目的： 长远规划， 月金额低一些， 一月一次， 10年以上 止盈定投： 两周或一周一次， 什么类型的基金适合定投 股票，指数， 混合—波动大的更适合定投 周期频率： 年， 月， 周 （周略优于月， 长远来看差不多） 哪一天扣款入市： 金股：黑色周四， 月末， 季末， 月投: 月末， 周：周四 熊市是否停止定投 继续投， 牛市要谨慎， 降低频率和金额。 智能定投： 判断高低位，牛熊市。 均线定投：跌多买， 涨少买， 风险承受能力高的 趋势定投：风险承受能力低的， 留 心频繁的转换基金产生的手续费 估值定投：PE市盈率， 长期持有 基金交易规则 T+1, 15点之前 分红方式选 择：红利再投资 计算收益： EXCEL-&gt;XIRR: 2013/08/12 -10000","link":"/2021/06/08/technology/fin/%E6%8A%95%E8%B5%84%E5%9F%BA%E9%87%91/"},{"title":"MACD教程","text":"MACD教程1. 基本概念口诀 1.多空分界在零轴，水下少操作，能不做就不做 2.水下金叉多反弹，一坑更比一坑低, 水下死叉 ，弱更弱 3.水上金叉多上涨，一山更比一山高 4.抄底要看水下底背离，股价创新低MACD没有创新低 5.逃顶要看水上顶背离，股价创新高MACD没有创新高 6.水上金叉，多头信号，二次金叉，强转更强 7.水上死叉，不一定看空，也可能是上升过程中的回档调整 8.其中量价齐升初步走强时，macd刚上零轴形成的第一个死叉，多数是休整期，二次金叉突破是转强买点 9.价格走势累积了一定幅度，量升价不涨，盘整中出现Macd死叉，多数是真正的空头期。 10.倒鸭子-将金不金=高概率下杀，看似回踩完毕，股价要向上突破的时候，就差临门一脚，转头向下，本次反弹或突破是假的， 或者风向突然变卦，接下来股价大概率下杀， 线上线下都要注意。 11.拈花佛手-将死不死=高概率上攻：在形成金叉后（0轴上）， 股价修整，眼看macd要死叉， 股价突然扭转局面向上突破，使得macd再次开口向上，说明有资金护盘，形成上涨拐点，建立背景是要在0轴上方。 12.起死回生-短期有大阳，macd形成死叉，3天内又重新拉回成金叉，大量阳线强行扭转，后市还会有一次拉升动作，建立背景0轴以上。 13.不可救药-扶不起的反弹，在上涨之后出现回调，然后反弹的过程中出现金叉，3天内又被扭转成死叉，说明反弹极弱， 短期内还有一次探底。如果出现在0轴以下则更加危险。 火烧连营：macd在零轴上方了，之前至少大于一个月全部是红柱，没有绿柱，价格没有大涨，配合成交量往往出现阳线倍量柱，以为资金在积极吸筹，适合回落时低点潜伏，因为一旦爆发速度极快。eg:联创股份，2021.5.11–6.23, 安记食品2021.2.18–4.1 背离有预警作用，越大周期的背离，也不容易化解。背离可以是两个点，也可以是更多的点，顶背离的预警效果底背离更强。底背离抄底不一定可行，可能还有更低。背离想要化解需要放量，需要钱。 2. 线上死叉多回调，箱体下轨要低吸 3. 先下回抽到零轴， 反弹多数要到头 4.线上回抽到零轴，就算不涨也反弹 5.顶底背离挺管用，就怕量能来捣乱。 合格的底背离就不应该再创新低， 前提是底背离时缩量，如果放量，或被破坏 合格的顶背离不应该再创新高，前提是顶背离时缩量，如果放量，或被破坏 量比1 概念 量比=现在每分钟的成交量/过去5日平均每分钟的成交量 比值越大，成交量爆发的强度越高 短线很有用 量比在0.8-1.5 正常水平 1.5-2.5 温和放量， 股价将维持原来的上涨或下跌趋势 2.5-5 明显放量，如果股价突破了重要的压力位， 突破的有效性很高 5倍甚至10倍， 剧烈放量， 如果出现在一段上涨趋势之后，那么见顶的几率很高。如果出现在底部，见底的概率也很大 超过10倍，一定要反向操作，方巨量下跌，看涨，放巨量上涨看跌。 成交量，放量上涨和缩量下跌好不好 低位尚未启动，温和放量，换手率3-5，主力开始吸筹了，后市可期，但不一定立马突破，在关键位置可能继续震荡，温和放量，突破箱体（关键压力位）有机会跟进. 可以加自选等一等， 均匀放量，此时股价往往是在拉升阶段，市场会出现大阳线，且上涨持续性较好，是短线买点。 60日量均线几乎是走平的状态，这样往往能走的更远，如果不停的往上打量，走的波段会比较快，走快之后，一般要有个回打的过程。而对于均匀放量的，60量线不会翘头，很多牛股60量线基本走平，上涨过程中阳量基本是在60量线上，整体很均匀的量，持续力度都是月级别的。多半是机构持股 。底部温和放量之后，突破之后量级高一点，均匀放量。 巨量上涨有两种情况：1.低位巨量要震荡，低位巨量标明有主力介入，但同时卖出盘也很大，其主要原因是上方的套牢盘太多，后期股价大概率还要震荡一段时间，以消化上方的套牢盘，低位巨量不一定代表主动买盘多，量分多空，量大其实也是分歧大，2。高位巨量很危险，股价高位上涨（或下跌）放大量，意味着高分歧，而买入的资金多是短线资金，后市很难再有往上推的动力，一旦情况不对，短线资金出逃，多方变成空方，后市危险，这时多是卖点。大阴线放巨量，基本就到头了。 缩量上涨，代表只要花少量的资金就能拉升股价，此时强烈看好后市，这种情况多是主力高度控盘的情况。低位放量上涨，之后量能缩小，但是股价没有明显的回调，而是保持小斜率的上涨，交易量持续缩小，突破之后压力线下线上都缩量，线中关键位置放量突破，线上股价不跌，完美多头。 威廉指标 WR6,10改成40， 40 WR在50以下为持股周期 WR在50以上为持币周期 WR从上往下穿过50为买点 WR从下往上穿过50为卖点 换手率 股价在低位，成交量在60线以下，股性不活跃，不用关注，一旦温和放量持续在60线以上，关注度提高了，不管阴阳，每天换手率保持在3–5之间，人气扭转，说明主力开始吸筹，可以关注买入时机 换手率8–15， 标明主力资金大笔流入，这时股价一旦突破平台瓶颈线，量柱合理，股价往往迎来加速上涨，如果换手+量柱太高，分歧比较大，大概率还有冲高回落，或二次洗盘，震荡调整。而两三倍的量柱和8–15的换手率去突破压力位，比较正常可信。也是突破性买点。 换手率接近或大于25%， 而且股价在高位，一般代表主力在出货。量柱比突破瓶颈是还要大，高位高换手，出大量，都代表高位分歧很大。出货特征 换手率超过70%， 死亡换手率，主力疯狂出货，立即卖出，不报任何幻想。 新股刚开板，换手率大于50%， 然后维持在20%左右，说明后市还有空间。 开板回落在618，50位置企稳，换手率维持在20左右，量能放大，代表承接较好，这是第一个承接点。第二个是突破压力位时，换手能维持在30，突破压力后再冲出去一段的概率很高 波段做T，高抛低吸,降低成本做T不要贪心，目标是降成本，目标要明确。行情好的时候可以先吸后抛，以免抛飞。 日内T+0，分时图 顶背离：股价与成交量背离，股价与macd背离（包括指标线的背离或者红绿柱的背离，比如macd不创新高或红柱比之前变少，但股价还在冲高）。两个背离都出现时大概率是到顶了要回撤，可以先卖出。这里量价背离的准确率更高，因为量能可以扭转一切指标背离。关注平均成本线的支撑和压力 底背离： macd底背离，先买后卖 V型：分时图上，低位阳量反包之前的阴量，二次低点不创新低，macd0轴上可以做低吸。相反高位阴量反包可高抛 养成习惯，分时图也多画线 低点出阴量，今天不低明天低，不要低吸了 趋势决定方向，成本决定高低， 开盘前15分钟一般是昨夜情绪的一个释放，15分钟后会慢慢修复，按大方向走 分钟或日K图上做高抛低吸（没时间看盘）指标ene日线加5分钟 expma（12，50）, macdene（基于股价乖离）改成10， 11， 9 用在日线图里， 下降通道ene回打下轨时一般会拉会修复，产生了低吸的机会，结合5分钟的分钟图，构成反弹的三要素：1.价格不创新低，2.绿柱缩小或者出现了底背离，绿柱比上一次探到地点时要小，说明空头能量衰减，3.expma构成金叉，日线股价反弹到ene中轨，高抛掉。行情差的时候，注意有时候到下轨有可能继续下跌 宽幅震荡通道：日线反弹到ene上轨高抛。 可以分多次做，如果没有机会就不做。如果基本面出现系统性风险，赶紧出来， 只做确定性最高的。 分时看盘 以阴度阳，从分时盘口看主力资金撤退的痕迹 不健康的涨停板：板上出货。在高点的时候应该出现阳高量，如果没出现甚至出现高音量。开板的量大于封板的量，后面封板的时候量不够，全天的高量是开板时的高阴量。这不正常。对于大阳线也可以应用。出货板之后的几天，不要轻易去抄底，有可能会跌很多 主力出货：对敲开涨停，涨停价大量委卖营造氛围，然后抽单转身再挂。主力有通道可以把买单撤掉。 健康的涨停板：放量突破，调整再放量上涨，封板时方大量阳线 高点大阴量（卖出的单子多），高位绿帽子，资金在撤退，要减仓。如果那个大阴量是全天最大量，尾盘清仓 什么样的涨停板不能追 涨停之后，次日尾盘拉升， 尾盘拉升的原因有两个可能：1是主力实力不济，先前资金用完了，只能在尾盘来一下，以便于次日高开出货；2是早盘多空激烈博弈，分歧比较大，虽然尾盘多方占优，但做多能力消耗差不多了，后续拉升比较困难，可能震荡调整。短线滞涨，都不适合再追 涨停之后，再爆出倍量不封板，意味着有较大的分歧，说明后面可能走补跌的过程，当然分歧也可能转一致，继续向上。 涨停之后大幅低开，短线散户情绪恐慌，一般难以维持股价。如果主力不护盘，主力甚至可能顺势打压再吸筹 涨停封板之后炸板，抛盘较大，有出货嫌疑。如果15-30分钟内能重新封板还可以做。 高开的，上午没有出现回调绿盘，下午还有可能有动作拉升。如果拉高又跳水，有出货的嫌疑 涨停之后，次日上午震荡，下午拉升之后跳水，诱多嫌疑 持仓股票高开怎么办越早拉升越强，注意拉升过程出现背离- 前半个小时是交易最活跃的时候，也是主力下场操纵情绪的时候- 高开封涨停，继续持有，同时在不破板的情况下，看尾盘封单成交比，对后市的溢价有个预期。尾盘买一封板的量除以全天成交量，如果超过10%， 表示封单很强，继续珍惜，可能连板。比值3-10%之间，大概溢价还有5个点。比值小于三，就冲个三四给点。如果比值小于1，尾盘可以减仓，第二天如果低开就出局。- 高开快速拉升五浪，但是没有涨停，减仓。量跟不上，如果日k在高位，有诱多的嫌疑- 高开已1，2个点，震荡不收绿， 守到下午。下午可能有动作- 高开快速下杀，30分钟不能翻红，减仓。早盘一般是杀情绪，不要着急，高开本来是强开局，如果能翻红，更能证明早上在杀情绪，下午可能还有动作。如果一直翻不上来，证明今天比较弱，注意后续可能继续下跌的风险，注意支撑位，如果破位，减仓- 高开平走，下午拉涨停，减仓。像是强弩之末，后面冲劲不太强。- 高开涨停，盘中炸板，15分钟能够拉会，还可以，烂板出牛股。开闸放水，让想进来做多的跟风盘进来合力封板。如果不能重新封板，没有跟风盘进来，可能顺势下杀，或风向已经变了，减仓。同类题材都出现开闸放水，有可能风向变了。十大误区 抄底不抄年线以下 短线不要买10日线在上，五日线在下的 犹豫不决时坚决不买，只买看得懂，有信心的 股价在上涨如果要做T, 应该先买再卖， 以免做丢 坚决不买新闻股，热点股，不买不亏 个股高开五个点以上， 没有能够直接封板，直接出局 永远不要一次性满仓 不要在跌停板补仓，涨停板加仓，失败概率太大 拿得住、割的狠， 严格按交易计划执行 不要看到个股业绩报告好，就去买， 散户看到的都是滞后信息 分时图 大盘：白色加权指数，黄色是未加权的， 可以理解为白色是大盘，黄色是小盘， 二八分化，二是大盘股 大盘上涨 ，黄上白下， 权重搭台，题材唱戏， 既赚指数又赚钱， 积极参与 大盘上涨，黄下白上， 题材唱罢， 权重登台， 只赚指数不赚钱，高抛低吸，要轮动 大盘下跌，黄上白下，权重拆台， 题材等待， 只亏指数，不亏钱，逢高减仓， 御寒冬。 大盘下跌，黄下白上，题材退场，权重收队， 既亏指数又亏钱， 多看少动， 忌伸手。 大盘震荡，黄上白下，权重沉默，题材冒头， 此时，重个股轻指数。 大盘震荡，黄下白上，题材沉默，权重冒头，此时，就地卧倒，少操作。 个股：白色是实时价格，黄色是当日平均买卖成本，黄线有支撑和压力作用 白线远离黄线向上，但出现成交量反而越来越小，或macd红柱顶背离，高概率要回档 白线远离黄线向下，macd水下金叉，股价有反弹。不建议新股建仓，但是如果本来持有，可以先低吸后抛出。 分时图股价在黄线下方，坚决不买股 分时图股价在黄线上方可以买，放量拉升时买，或者拉升之后缩量整理靠近黄线时买入，不放量不买。 分时图中若股价缩量拉升，有诱多的成分，无量上行走不远，不应该买入，如果持有，应该逢高减仓 虎踞龙盘，分时攻击波 板上星涨停板突破平台或楔形，+ 高开的试盘十字星 + 跳空缺口（可以是涨停那天也可以是十字星那天）， 十字星最低价不会踩到前一天的涨停板+ 个股是热点或风口= 十字星那天尾盘介入，值博率很高 庄家洗盘目的是为了减少后续拉升股价时的压力。方便后续拉升。 机构洗盘：边拉边洗，两步一停，三步一卡，阳放阴缩（价格阴跌时缩量），上升斜率大了之后，亦可能出现放量阴。月线季线半年线多头排列，60日成交量比较恒定，量能在一个区间，不会突兀的放大，关键位置会护盘， 游资洗盘：游资一般爱热点股，持续周期比较短，时间有限，所以一般拉升完没有横盘，直接砸盘，甚至借助利空消息故意挖坑。如果卖错，股价重新涨回时可以再杀进去。一般会先拉出30-50%的空间。洗盘一定要在收回失地。 推算庄家成本价通过测算锁定建仓期间的均价来测算庄家成本，当出现明显放量的大底部区域，可视为庄家建仓的成本区。 底部盘整放量的那段时间的股票均价*1.3=庄家成本。 说明：低位放量才是是收集筹码，另外庄家有交易和融资成本 庄家初步目标是50%， 这时可能会兑现一部分，股价回档 进一步目标是100%，此时有可能回档甚至出货下跌 涨停板 低位涨停，最好获利比例超过90%，甚至达到100%， 这样后市将高效上涨 中位涨停板，看是否突破关键位，量能要放大， 最好一口气吃掉及突破前期套牢盘 高位涨停板，看换手率， 小于5%， 还可以继续拿， 超过20%的换手率就危险，建议获利了结 主力洗盘洗盘的目的是洗掉高位的套牢盘筹码，以及低位的获利盘筹码， 目的是为了后面更容易的拉升。 如果你不是套牢盘，就不要硬挤到主力压力区，或者短线远离的位置了。 都是追高惹的祸。 RSI指标 概念短线指标，注意下面趋势和波段的区别20以下为超卖， RSI上传20平行线为趋势买点80以上为超买， RSI下穿80平行线为趋势卖点20-50波段低位， RSI9金叉RSI24为波段买点50-80波段高位， RSI9死叉RSI24为波段卖点数值50以上宜持股， 50以下宜持币 实操改参数为9，9， 24， 三线变两线添加20， 50， 80 三条基准线 模型520买入条件：5日线上穿20日线， 成交量5上穿20， macd在0轴上， dif上穿dea 关键K线决定是否止盈 放量上涨的阳线，找到关键防守位置 不跌破关键k线底部就一直持股 随着股价继续突破，产生新的关键k线， 防守位置上移到这个k线 依次递进，所谓移动止盈 个股开盘三十分钟内走势反映当天的走势 股价先跌后涨，反弹没有超过开盘价，该股当天大概率是弱势 股价先涨后跌， 并且跌破了开盘价，据此可以判断， 下午两点之后会有一波下跌，要卖的趁早 股价先涨后跌，但是没有跌破开盘价，主力在洗盘，下午两点以后上涨的可能性很大，盘中低点可以买 开盘三十分钟内出现小幅拉升，最好不超过3%，同时分时上图上股价出现稳步上扬，主力快要拉升了，找位置坐好 季报业绩与股价 炒股炒的是预期， 预期业绩增长主力会提前进场，就会上涨，否则会下跌 合理估值p1(历史回归获得)， 业绩公布后的当前估值p2, p2&gt;p1下跌，p2&lt;p1上涨 举例，假如某行业不景气，公司季报发出之前，市场已经预期不好，股价一直下跌，导致股价估值过低，季报发布后，反而有可能开始反弹。 集合竞价 9.15–9.20可以随意挂单并撤销 9.20–9.25 可以挂单，不可以撤单，挂单大小进行匹配，并以最大匹配量的价格，定为开盘价—-9.25 9.25–9.30 继续挂单，继续匹配但不成交- 匹配的单子越来越多了（小圆点），且成交量放大，标明主力匹配医院很强 多单为红色，空单为绿色，已匹配的在下方，未匹配的在上方，如果红色越来越多，代表主力强势多单匹配过程中 假如前五分钟有大量买单，但中间五分钟却急剧下降，主力手段注意风险 只能提高成功率，不能太依赖 抄底-识别底部形态 不创新低，反新高， 即低点越来越高，高点越来越高 上涨放量，下跌缩量。 颈线被突破，颈线突破回踩可以放心买 严格止损，顺势而为，入市果断，心态平和，止损坚决，亏小赚大","link":"/2019/06/08/technology/fin/MACD%E6%95%99%E7%A8%8B/"},{"title":"短线技巧跟庄，长线看趋势","text":"短线技巧跟庄，长线看趋势短线技巧跟庄，长线看趋势风险识别 二次突破 &lt;自律的交易者&gt;心态80%+20%技术","link":"/2021/06/08/technology/fin/%E7%9F%AD%E7%BA%BF%E6%8A%80%E5%B7%A7%E8%B7%9F%E5%BA%84%EF%BC%8C%E9%95%BF%E7%BA%BF%E7%9C%8B%E8%B6%8B%E5%8A%BF/"},{"title":"面试八股之网络","text":"面试八股之网络1.基本概念TCP连接中间会有什么操作在TCP连接中，客户端和服务器之间会进行以下操作： 握手阶段：客户端向服务器发送SYN包（同步包），请求建立连接。服务器收到SYN包后，向客户端发送SYN+ACK包（同步确认包），表示可以建立连接。客户端收到SYN+ACK包后，再向服务器发送ACK包（确认包），表示连接建立成功。 数据传输阶段：连接建立成功后，客户端和服务器之间可以进行数据的传输。客户端向服务器发送数据包，服务器接收数据包并进行处理，然后向客户端发送响应包。客户端收到响应包后，可以再次向服务器发送数据包，以此类推。 断开连接阶段：当客户端或服务器不再需要连接时，可以发送FIN包（结束包）来请求断开连接。对方收到FIN包后，也发送FIN包进行响应，表示同意断开连接。当两端都收到对方的FIN包后，连接才真正关闭。 需要注意的是，在TCP连接中可能会出现丢包、拥塞等情况，需要进行相应的处理，例如重传丢失的数据包、调整发送窗口大小等 TCP 三次握手 TCP 三次握手中，客户端收到的第二次握手中 ack 确认号不是自己期望的，会发生什么？是直接丢弃 or 回 RST 报文？ 什么情况下会收到不正确的 ack（第二次握手中的 ack） 呢？不卖关子，直接说这个问题，是回 RST 报文。过程如下图： 三次握手避免历史连接 当客户端连续发送多次建立连接的 SYN 报文，然后在网络拥堵的情况，就会发生客户端收到不正确的 ack 的情况。具体过程如下： 客户端先发送了 SYN（seq = 90） 报文，但是被网络阻塞了，服务端并没有收到，接着客户端又重新发送了 SYN（seq = 100） 报文，注意不是重传 SYN，重传的 SYN 的序列号是一样的。 「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端，那么此时服务端就会回一个 SYN + ACK 报文给客户端，此报文的确认号是 91（90+1）。 客户端收到后，发行自己期望收到的确认号应该是 100+1，而不是 90 + 1，于是就会回 RST 报文。 服务端收到 RST 报文后，就会中止连接。 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。 上述中的「旧 SYN 报文」称为历史连接，TCP 使用三次握手建立连接的最主要原因就是防止「历史连接」初始化了连接。 我们也可以从 RFC 793 知道 TCP 连接使用三次握手的首要原因： The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion. 简单来说，三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。RFC 给出的三次握手防止历史连接的案例图如下： RFC 793 如果是两次握手连接，就无法阻止历史连接，那为什么 TCP 两次握手为什么无法阻止历史连接呢？ 我先直接说结论，主要是因为在两次握手的情况下，「被动发起方」没有中间状态给「主动发起方」来阻止历史连接，导致「被动发起方」可能建立一个历史连接，造成资源浪费。 你想想，两次握手的情况下，「被动发起方」在收到 SYN 报文后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据给，但是「主动发」起方此时还没有进入 ESTABLISHED 状态，假设这次是历史连接，主动发起方判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而「被动发起方」在第一次握手的时候就进入 ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。 两次握手无法阻止历史连接 可以看到，上面这种场景下，「被动发起方」在向「主动发起方」发送数据前，并没有阻止掉历史连接，导致「被动发起方」建立了一个历史连接，又白白发送了数据，妥妥地浪费了「被动发起方」的资源。 因此，要解决这种现象，最好就是在「被动发起方」发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手。 我说回 RST 就回 RST 吗？当然不是了，肯定得用源码证明我说的这个结论。 听到要源码分析，可能有的同学就怂了。 其实要分析我们今天这个问题，只要懂 if else 就行了，我也会用中文来表述代码的逻辑，所以单纯看我的文字也是可以的。 这次我们重点分析的是，在 SYN_SENT 状态下，收到不正确的确认号的 syn+ack 报文是如何处理的。 处于 SYN_SENT 状态下的客户端，在收到服务端的 syn+ack 报文后，最终会调用 tcp_rcv_state_process，在这里会根据 TCP 状态做对应的处理，这里我们只关注 SYN_SENT 状态。 // net/ipv4/tcp_ipv4.c int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb) { ... int queued = 0; ... switch (sk-&gt;sk_state) { case TCP_CLOSE: ... case TCP_LISTEN: ... case TCP_SYN_SENT: .... queued = tcp_rcv_synsent_state_process(sk, skb, th); if (queued &gt;= 0) return queued; ... } 可以看到，接下来，会继续调用 tcp_rcv_synsent_state_process 函数。 static int tcp_rcv_synsent_state_process(struct sock *sk, struct sk_buff *skb, const struct tcphdr *th) { .... if (th-&gt;ack) { /* rfc793: * &quot;If the state is SYN-SENT then * first check the ACK bit * If the ACK bit is set * If SEG.ACK =&lt; ISS, or SEG.ACK &gt; SND.NXT, send * a reset (unless the RST bit is set, if so drop * the segment and return)&quot; */ // ack 的确认号不是预期的 if (!after(TCP_SKB_CB(skb)-&gt;ack_seq, tp-&gt;snd_una) || after(TCP_SKB_CB(skb)-&gt;ack_seq, tp-&gt;snd_nxt)) //回 RST 报文 goto reset_and_undo; ... } 从上面的函数，就可以得知了，客户端在 SYN_SENT 状态下，收到不正确的确认号的 syn+ack 报文会回 RST 报文。 小结 TCP 三次握手中，客户端收到的第二次握手中 ack 确认号不是自己期望的，会发生什么？是直接丢弃 or 回 RST 报文？ 回 RST 报文。 什么情况下会收到不正确的 ack（第二次握手中的 ack） 呢？ 当客户端发起多次 SYN 报文，然后网络拥堵的情况下，「旧的 SYN 报文」比「新的 SYN 报文」早抵达服务端，此时服务端就会按照收到的「旧的 SYN 报文」回复 syn+ack 报文，而此报文的确认号并不是客户端期望收到的，于是客户端就会回 RST 报文。 四次挥手虽然我们在学习 TCP 挥手时，学到的是需要四次来完成 TCP 挥手，但是在一些情况下， TCP 四次挥手是可以变成 TCP 三次挥手的。 而且在用 wireshark 工具抓包的时候，我们也会常看到 TCP 挥手过程是三次，而不是四次，如下图： 先来回答为什么 RFC 文档里定义 TCP 挥手过程是要四次？ 再来回答什么情况下，什么情况会出现三次挥手？ 为什么 TCP 挥手需要四次？TCP 四次挥手的过程如下： 具体过程： 客户端主动调用关闭连接的函数，于是就会发送 FIN 报文，这个 FIN 报文代表客户端不会再发送数据了，进入 FIN_WAIT_1 状态； 服务端收到了 FIN 报文，然后马上回复一个 ACK 确认报文，此时服务端进入 CLOSE_WAIT 状态。在收到 FIN 报文的时候，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，这个 EOF 会被放在已排队等候的其他已接收的数据之后，所以必须要得继续 read 接收缓冲区已接收的数据； 接着，当服务端在 read 数据的时候，最后自然就会读到 EOF，接着 read() 就会返回 0，这时服务端应用程序如果有数据要发送的话，就发完数据后才调用关闭连接的函数，如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，这时服务端就会发一个 FIN 包，这个 FIN 报文代表服务端不会再发送数据了，之后处于 LAST_ACK 状态； 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态； 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态； 客户端经过 2MSL 时间之后，也进入 CLOSE 状态； 你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。 为什么 TCP 挥手需要四次呢？服务器收到客户端的 FIN 报文时，内核会马上回一个 ACK 应答报文，但是服务端应用程序可能还有数据要发送，所以并不能马上发送 FIN 报文，而是将发送 FIN 报文的控制权交给服务端应用程序： 如果服务端应用程序有数据要发送的话，就发完数据后，才调用关闭连接的函数； 如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数， 从上面过程可知，是否要发送第三次挥手的控制权不在内核，而是在被动关闭方（上图的服务端）的应用程序，因为应用程序可能还有数据要发送，由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送 FIN 报文了，所以服务端的 ACK 和 FIN 一般都会分开发送。 FIN 报文一定得调用关闭连接的函数，才会发送吗？ 不一定。 如果进程退出了，不管是不是正常退出，还是异常退出（如进程崩溃），内核都会发送 FIN 报文，与对方完成四次挥手。 粗暴关闭 vs 优雅关闭前面介绍 TCP 四次挥手的时候，并没有详细介绍关闭连接的函数，其实关闭的连接的函数有两种函数： close 函数，同时 socket 关闭发送方向和读取方向，也就是 socket 不再有发送和接收数据的能力。如果有多进程/多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 FIN 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出 FIN 报文。 shutdown 函数，可以指定 socket 只关闭发送方向而不关闭读取方向，也就是 socket 不再有发送数据的能力，但是还是具有接收数据的能力。如果有多进程/多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用，然后发出 FIN 报文，如果有别的进程企图使用该 socket，将会受到影响。 如果客户端是用 close 函数来关闭连接，那么在 TCP 四次挥手过程中，如果收到了服务端发送的数据，由于客户端已经不再具有发送和接收数据的能力，所以客户端的内核会回 RST 报文给服务端，然后内核会释放连接，这时就不会经历完成的 TCP 四次挥手，所以我们常说，调用 close 是粗暴的关闭。 当服务端收到 RST 后，内核就会释放连接，当服务端应用程序再次发起读操作或者写操作时，就能感知到连接已经被释放了： 如果是读操作，则会返回 RST 的报错，也就是我们常见的Connection reset by peer。 如果是写操作，那么程序会产生 SIGPIPE 信号，应用层代码可以捕获并处理信号，如果不处理，则默认情况下进程会终止，异常退出。 相对的，shutdown 函数因为可以指定只关闭发送方向而不关闭读取方向，所以即使在 TCP 四次挥手过程中，如果收到了服务端发送的数据，客户端也是可以正常读取到该数据的，然后就会经历完整的 TCP 四次挥手，所以我们常说，调用 shutdown 是优雅的关闭。 但是注意，shutdown 函数也可以指定「只关闭读取方向，而不关闭发送方向」，但是这时候内核是不会发送 FIN 报文的，因为发送 FIN 报文是意味着我方将不再发送任何数据，而 shutdown 如果指定「不关闭发送方向」，就意味着 socket 还有发送数据的能力，所以内核就不会发送 FIN。 什么情况会出现三次挥手？当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。 然后因为 TCP 延迟确认机制是默认开启的，所以导致我们抓包时，看见三次挥手的次数比四次挥手还多。 什么是 TCP 延迟确认机制？ 当发送没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。 为了解决 ACK 传输效率低问题，所以就衍生出了 TCP 延迟确认。 TCP 延迟确认的策略： 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK 延迟等待的时间是在 Linux 内核中定义的，如下图： 关键就需要 HZ 这个数值大小，HZ 是跟系统的时钟频率有关，每个操作系统都不一样，在我的 Linux 系统中 HZ 大小是 1000，如下图： 知道了 HZ 的大小，那么就可以算出： 最大延迟确认时间是 200 ms （1000/5） 最短延迟确认时间是 40 ms （1000/25） 怎么关闭 TCP 延迟确认机制？ 如果要关闭 TCP 延迟确认机制，可以在 Socket 设置里启用 TCP_QUICKACK，启用 TCP_QUICKACK，就相当于关闭 TCP 延迟确认机制。 // 1 表示开启 TCP_QUICKACK，即关闭 TCP 延迟确认机制int value = 1;setsockopt(socketfd, IPPROTO_TCP, TCP_QUICKACK, (char*)&amp; value, sizeof(int)); 实验验证实验一接下来，来给大家做个实验，验证这个结论： 当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。 服务端的代码如下，做的事情很简单，就读取数据，然后当 read 返回 0 的时候，就马上调用 close 关闭连接。因为 TCP 延迟确认机制是默认开启的，所以不需要特殊设置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; #include &lt;errno.h&gt; #include &lt;string.h&gt; #include &lt;netdb.h&gt; #include &lt;sys/types.h&gt; #include &lt;netinet/in.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netinet/tcp.h&gt; #define MAXLINE 1024 int main(int argc, char *argv[]) { // 1. 创建一个监听 socket int listenfd = socket(AF_INET, SOCK_STREAM, 0); if(listenfd &lt; 0) { fprintf(stderr, &quot;socket error : %s\\n&quot;, strerror(errno)); return -1; } // 2. 初始化服务器地址和端口 struct sockaddr_in server_addr; bzero(&amp;server_addr, sizeof(struct sockaddr_in)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htonl(INADDR_ANY); server_addr.sin_port = htons(8888); // 3. 绑定地址+端口 if(bind(listenfd, (struct sockaddr *)(&amp;server_addr), sizeof(struct sockaddr)) &lt; 0) { fprintf(stderr,&quot;bind error:%s\\n&quot;, strerror(errno)); return -1; } printf(&quot;begin listen....\\n&quot;); // 4. 开始监听 if(listen(listenfd, 128)) { fprintf(stderr, &quot;listen error:%s\\n\\a&quot;, strerror(errno)); exit(1); } // 5. 获取已连接的socket struct sockaddr_in client_addr; socklen_t client_addrlen = sizeof(client_addr); int clientfd = accept(listenfd, (struct sockaddr *)&amp;client_addr, &amp;client_addrlen); if(clientfd &lt; 0) { fprintf(stderr, &quot;accept error:%s\\n\\a&quot;, strerror(errno)); exit(1); } printf(&quot;accept success\\n&quot;); char message[MAXLINE] = {0}; while(1) { //6. 读取客户端发送的数据 int n = read(clientfd, message, MAXLINE); if(n &lt; 0) { // 读取错误 fprintf(stderr, &quot;read error:%s\\n\\a&quot;, strerror(errno)); break; } else if(n == 0) { // 返回 0 ，代表读到 FIN 报文 fprintf(stderr, &quot;client closed \\n&quot;); close(clientfd); // 没有数据要发送，立马关闭连接 break; } message[n] = 0; printf(&quot;received %d bytes: %s\\n&quot;, n, message); } close(listenfd); return 0; } 客户端代码如下，做的事情也很简单，与服务端连接成功后，就发送数据给服务端，然后睡眠一秒后，就调用 close 关闭连接，所以客户端是主动关闭方： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; #include &lt;errno.h&gt; #include &lt;string.h&gt; #include &lt;netdb.h&gt; #include &lt;sys/types.h&gt; #include &lt;netinet/in.h&gt; #include &lt;sys/socket.h&gt; int main(int argc, char *argv[]) { // 1. 创建一个监听 socket int connectfd = socket(AF_INET, SOCK_STREAM, 0); if(connectfd &lt; 0) { fprintf(stderr, &quot;socket error : %s\\n&quot;, strerror(errno)); return -1; } // 2. 初始化服务器地址和端口 struct sockaddr_in server_addr; bzero(&amp;server_addr, sizeof(struct sockaddr_in)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;); server_addr.sin_port = htons(8888); // 3. 连接服务器 if(connect(connectfd, (struct sockaddr *)(&amp;server_addr), sizeof(server_addr)) &lt; 0) { fprintf(stderr,&quot;connect error:%s\\n&quot;, strerror(errno)); return -1; } printf(&quot;connect success\\n&quot;); char sendline[64] = &quot;hello, i am xiaolin&quot;; //4. 发送数据 int ret = send(connectfd, sendline, strlen(sendline), 0); if(ret != strlen(sendline)) { fprintf(stderr,&quot;send data error:%s\\n&quot;, strerror(errno)); return -1; } printf(&quot;already send %d bytes\\n&quot;, ret); sleep(1); //5. 关闭连接 close(connectfd); return 0; } 编译服务端和客户端的代码： 先启用服务端： 然后用 tcpdump 工具开始抓包，命令如下： tcpdump -i lo tcp and port 8888 -s0 -w /home/tcp_close.pcap 然后启用客户端，可以看到，与服务端连接成功后，发完数据就退出了。 此时，服务端的输出： 接下来，我们来看看抓包的结果。 可以看到，TCP 挥手次数是 3 次。 所以，下面这个结论是没问题的。 结论：当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制（默认会开启）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。 实验二我们再做一次实验，来看看关闭 TCP 延迟确认机制，会出现四次挥手吗？ 客户端代码保持不变，服务端代码需要增加一点东西。 在上面服务端代码中，增加了打开了 TCP_QUICKACK （快速应答）机制的代码，如下： 编译好服务端代码后，就开始运行服务端和客户端的代码，同时用 tcpdump 进行抓包。 抓包的结果如下，可以看到是四次挥手。 所以，当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」，同时「关闭了 TCP 延迟确认机制」，那么就会是四次挥手。 设置 TCP_QUICKACK 的代码，为什么要放在 read 返回 0 之后？ 我也是多次实验才发现，在 bind 之前设置 TCP_QUICKACK 是不生效的，只有在 read 返回 0 的时候，设置 TCP_QUICKACK 才会出现四次挥手。 网上查了下资料说，设置 TCP_QUICKACK 并不是永久的，所以每次读取数据的时候，如果想要立刻回 ACK，那就得在每次读取数据之后，重新设置 TCP_QUICKACK。 而我这里的实验，目的是为了当收到客户端的 FIN 报文（第一次挥手）后，立马回 ACK 报文，所以就在 read 返回 0 的时候，设置 TCP_QUICKACK。 当然，实际应用中，没人会在我这个位置设置 TCP_QUICKACK，因为操作系统都通过 TCP 延迟确认机制帮我们把四次挥手优化成了三次挥手了，这本来就是一件好事呀。 总结当被动关闭方在 TCP 挥手过程中，如果「没有数据要发送」，同时「没有开启 TCP_QUICKACK（默认情况就是没有开启，没有开启 TCP_QUICKACK，等于就是在使用 TCP 延迟确认机制）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。 所以，出现三次挥手现象，是因为 TCP 延迟确认机制导致的。 TCP 拥塞控制TCP如何保证可靠性TCP 拆包沾包原因TCP 拆包和沾包现象是由于 TCP 协议的特性以及网络传输过程中的各种因素所导致的。TCP 协议是基于字节流的传输层协议，没有固定的分包边界。发送方将数据分成多个小的数据包进行传输，接收方再将这些数据包组合成完整的数据。在这个过程中，可能会出现拆包和沾包现象。网络传输中的延迟和拥塞会影响数据包发送的速度和到达接收方的顺序。这可能导致数据包的拆分和组合不规律，从而出现拆包和沾包现象。接收方的缓冲区大小限制。当接收方的缓冲区不足以容纳一个完整的数据包时，可能会将数据包拆分成多个部分，导致拆包现象。为了解决 TCP 拆包和沾包的问题，可以采用以下方法：在应用层实现数据包的边界识别，例如通过添加包头，包头中包含数据包长度等信息，使得接收方能够准确地将数据包进行拼接。使用固定长度的数据包或者特殊的分隔符，以便于接收方识别数据包的边界。使用更高级的传输层协议，如 WebSocket，它在 TCP 基础上增加了数据帧的概念，可以更好地解决拆包和沾包问题。 TCP粘包问题怎么解决 答：特殊标记 追问：打断，如果使用特殊标记解决会遇到什么问题 答：正文转义字符 补充： 1、固定长度的消息 这种是最简单方法，即每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。 但是这种方式灵活性不高，实际中很少用。 2、特殊字符作为边界 我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。 HTTP 是一个非常好的例子。 HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。 有一点要注意，这个作为边界点的特殊字符，如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。 3、自定义消息结构 我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。 比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。 struct { u_int32_t message_length; char message_data[]; } message; 当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。 输入网址后发生了什么？应用层 DNS 解析，传输层 TCP 连接，网络层 IP，数据链路 MAC，真实物理层，接收到之后再一层层扒皮。 http报文长度判断udp为啥不可靠性。服务端挂了，客户端的 TCP 连接会发生什么？如果「服务端挂掉」指的是「服务端进程崩溃」，那么这个读者猜的想法是对的，服务端的进程在发生崩溃的时候，内核会发送 FIN 报文，与客户端进行四次挥手。 但是，如果「服务端挂掉」指的是「服务端主机宕机」，那么是不会发生四次挥手的，具体后续会发生什么？还要看客户端会不会发送数据？ 如果客户端会发送数据，由于服务端已经不存在，客户端的数据报文会超时重传，当重传次数达到一定阈值后，会断开 TCP 连接； 如果客户端一直不会发送数据，再看客户端有没有开启 TCP keepalive 机制？ 如果有开启，客户端在一段时间后，检测到服务端的 TCP 连接已经不存在，则会断开自身的 TCP 连接； 如果没有开启，客户端的 TCP 连接会一直存在，并不会断开。 详细介绍一下TCP的四次挥手机制，为什么要有TIME_WAIT状态，为什么需要四次握手？服务器出现了大量CLOSE_WAIT状态如何解决当客户端要服务器断开连接时，客户端 TCP 会向服务器发送一个特殊的报文段，该报文段的 FIN 标志位会被置1，接着服务器会向客户端发送一个确认报文段。然后服务器也会客户端发送一个 FIN 标志位为1的终止报文段，随后客户端回送一个确认报文段，服务器立即断开连接。客户端等待一段时间后也断开连接。 其实四次挥手的过程是很容易理解的，由于 TCP 协议是全双工的，也就是说客户端和服务端都可以发起断开连接。两边各发起一次断开连接的申请，加上各自的两次确认，看起来就像执行了四次挥手。 为什么要有 TIME_WAIT 状态？因为客户端最后向服务器发送的确认 ACK 是有可能丢失的，当出现超时，服务端会再次发送 FIN 报文段，如果客户端已经关闭了就收不到了。还有一点是避免新旧连接混杂。 大量 CLOSE_WAIT 表示程序出现了问题，对方的 socket 已经关闭连接，而我方忙于读或写没有及时关闭连接，需要检查代码，特别是释放资源的代码，或者是处理请求的线程配置 \\3. TIME_WAIT状态 经过前面的铺垫，终于要讲到与本文主题相关的内容了。 ^_^ 从TCP状态迁移图可知，只有首先调用close()发起主动关闭的一方才会进入TIME_WAIT状态，而且是必须进入（图中左下角所示的3条状态迁移线最终均要进入该状态才能回到初始的CLOSED状态）。 从图中还可看到，进入TIME_WAIT状态的TCP连接需要经过2MSL才能回到初始状态，其中，MSL是指MaxSegment Lifetime，即数据包在网络中的最大生存时间。每种TCP协议的实现方法均要指定一个合适的MSL值，如RFC1122给出的建议值为2分钟，又如Berkeley体系的TCP实现通常选择30秒作为MSL值。这意味着TIME_WAIT的典型持续时间为1-4分钟。 TIME_WAIT状态存在的原因主要有两点： 1）为实现TCP这种全双工（full-duplex）连接的可靠释放 参考本文前面给出的TCP释放连接4次挥手示意图，假设发起active close的一方（图中为client）发送的ACK（4次交互的最后一个包）在网络中丢失，那么由于TCP的重传机制，执行passiveclose的一方（图中为server）需要重发其FIN，在该FIN到达client（client是active close发起方）之前，client必须维护这条连接的状态（尽管它已调用过close），具体而言，就是这条TCP连接对应的（local_ip, local_port）资源不能被立即释放或重新分配。直到romete peer重发的FIN达到，client也重发ACK后，该TCP连接才能恢复初始的CLOSED状态。如果activeclose方不进入TIME_WAIT以维护其连接状态，则当passive close方重发的FIN达到时，active close方的TCP传输层会以RST包响应对方，这会被对方认为有错误发生（而事实上，这是正常的关闭连接过程，并非异常）。 2）为使旧的数据包在网络因过期而消失 为说明这个问题，我们先假设TCP协议中不存在TIME_WAIT状态的限制，再假设当前有一条TCP连接：(local_ip, local_port, remote_ip,remote_port)，因某些原因，我们先关闭，接着很快以相同的四元组建立一条新连接。本文前面介绍过，TCP连接由四元组唯一标识，因此，在我们假设的情况中，TCP协议栈是无法区分前后两条TCP连接的不同的，在它看来，这根本就是同一条连接，中间先释放再建立的过程对其来说是“感知”不到的。这样就可能发生这样的情况：前一条TCP连接由local peer发送的数据到达remote peer后，会被该remot peer的TCP传输层当做当前TCP连接的正常数据接收并向上传递至应用层（而事实上，在我们假设的场景下，这些旧数据到达remote peer前，旧连接已断开且一条由相同四元组构成的新TCP连接已建立，因此，这些旧数据是不应该被向上传递至应用层的），从而引起数据错乱进而导致各种无法预知的诡异现象。作为一种可靠的传输协议，TCP必须在协议层面考虑并避免这种情况的发生，这正是TIME_WAIT状态存在的第2个原因。 具体而言，local peer主动调用close后，此时的TCP连接进入TIME_WAIT状态，处于该状态下的TCP连接不能立即以同样的四元组建立新连接，即发起active close的那方占用的local port在TIME_WAIT期间不能再被重新分配。由于TIME_WAIT状态持续时间为2MSL，这样保证了旧TCP连接双工链路中的旧数据包均因过期（超过MSL）而消失，此后，就可以用相同的四元组建立一条新连接而不会发生前后两次连接数据错乱的情况。 另一比较深入的说法 TIME_WAIT状态的存在有两个理由：（1）让4次握手关闭流程更加可靠；4次握手的最后一个ACK是是由主动关闭方发送出去的，若这个ACK丢失，被动关闭方会再次发一个FIN过来。若主动关闭方能够保持一个2MSL的TIME_WAIT状态，则有更大的机会让丢失的ACK被再次发送出去。（2）防止lost duplicate对后续新建正常链接的传输造成破坏。lost duplicate在实际的网络中非常常见，经常是由于路由器产生故障，路径无法收敛，导致一个packet在路由器A，B，C之间做类似死循环的跳转。IP头部有个TTL，限制了一个包在网络中的最大跳数，因此这个包有两种命运，要么最后TTL变为0，在网络中消失；要么TTL在变为0之前路由器路径收敛，它凭借剩余的TTL跳数终于到达目的地。但非常可惜的是TCP通过超时重传机制在早些时候发送了一个跟它一模一样的包，并先于它达到了目的地，因此它的命运也就注定被TCP协议栈抛弃。另外一个概念叫做incarnation connection，指跟上次的socket pair一摸一样的新连接，叫做incarnation of previous connection。lost duplicate加上incarnation connection，则会对我们的传输造成致命的错误。大家都知道TCP是流式的，所有包到达的顺序是不一致的，依靠序列号由TCP协议栈做顺序的拼接；假设一个incarnation connection这时收到的seq=1000, 来了一个lost duplicate为seq=1000, len=1000, 则tcp认为这个lost duplicate合法，并存放入了receive buffer，导致传输出现错误。通过一个2MSL TIME_WAIT状态，确保所有的lost duplicate都会消失掉，避免对新连接造成错误。 滑动窗口从上面的图可以看到滑动窗口左边的是已发送并且被确认的分组，滑动窗口右边是还没有轮到的分组。滑动窗口里面也分为两块，一块是已经发送但是未被确认的分组，另一块是窗口内等待发送的分组。随着已发送的分组不断被确认，窗口内等待发送的分组也会不断被发送。整个窗口就会往右移动，让还没轮到的分组进入窗口内。 可以看到滑动窗口起到了一个限流的作用，也就是说当前滑动窗口的大小决定了当前 TCP 发送包的速率，而滑动窗口的大小取决于拥塞控制窗口和流量控制窗口的两者间的最小值。 接着就讲讲什么是流量控制窗口，什么是拥塞控制窗口。 先讲流量控制： TCP 是全双工的，客户端和服务器均可作为发送方或接收方，我们现在假设一个发送方向接收方发送数据的场景来讲解流量控制。首先我们的接收方有一块接收缓存，当数据来到时会先把数据放到缓存中，上层应用等缓存中有数据时就会到缓存中取数据。假如发送方没有限制地不断地向接收方发送数据，接收方的应用程序又没有及时把接收缓存中的数据读走，就会出现缓存溢出，数据丢失的现象，为了解决这个问题，我们引入流量控制窗口。 假设应用程序最后读走的数据序号是 lastByteRead，接收缓存中接收到的最后一个数据序号是 lastByteRcv，接收缓存的大小为 RcvSize，那么必须要满足 lastByteRcv - lastByteRead &lt;= RcvSize 才能保证接收缓存不会溢出，所以我们定义流量窗口为接收缓存剩余的空间，也就是Rcv = RcvSize - (lastByteRcv - lastByteRead)。只要接收方在响应 ACK 的时候把这个窗口的值带给发送方，发送方就能知道接收方的接收缓存还有多大的空间，进而设置滑动窗口的大小。 接着讲解拥塞控制： 拥塞控制是指发送方先设置一个小的窗口值作为发送速率，当成功发包并接收到ACK时，便以指数速率增大发送窗口的大小，直到遇到丢包（超时/三个冗余ACK），才停止并调整窗口的大小。这么做能最大限度地利用带宽，又不至于让网络环境变得太过拥挤。 最终滑动窗口的值将设置为流量控制窗口和拥塞控制窗口中的较小值。 Q: 编写 TCP/SOCK_STREAM 服务程序时，SO_REUSEADDR到底什么意思？ A: 这个套接字选项通知内核，如果端口忙，但TCP状态位于 TIME_WAIT ，可以重用端口。如果端口忙，而TCP状态位于其他状态，重用端口时依旧得到一个错误信息， 指明”地址已经使用中”。如果你的服务程序停止后想立即重启，而新套接字依旧 使用同一端口，此时 SO_REUSEADDR 选项非常有用。必须意识到，此时任何非期 望数据到达，都可能导致服务程序反应混乱，不过这只是一种可能，事实上很不可能。 CLOSE_WAIT： 这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。 UDP客户端可以CONNECT不，那CONNECT和不CONNECT有啥区别在UDP协议中，没有真正的连接（connection）的概念，因此UDP客户端不能像TCP客户端那样通过connect()函数来建立连接。 使用connect()函数的主要目的是为了简化代码和提高安全性。当TCP客户端调用connect()函数时，操作系统会自动为其分配一个socket文件描述符，并将该socket与远程服务器的IP地址和端口号绑定起来。这样，在之后的数据通信中，客户端只需要向该socket发送数据即可，而不必每次都指定远程服务器的IP地址和端口号。另外，connect()函数还可以对发送的数据进行一些验证和过滤，以提高数据传输的安全性。 在UDP协议中，由于不存在真正的连接，因此也就不需要使用connect()函数来建立连接。UDP客户端每次发送数据时，都需要指定远程服务器的IP地址和端口号，这样才能确保数据能够正确地被发送到目标地址。因此，在UDP协议中，没有connect()函数的概念。 总之，UDP客户端没有连接（connection）的概念，因此不能像TCP客户端那样使用connect()函数来建立连接。每次发送数据时，UDP客户端需要显式地指定远程服务器的IP地址和端口号。如果需要简化代码和提高安全性，可以使用其他技术手段，例如使用加密算法和数字证书来保证数据传输的安全性。 5. 讲一下HTTP与HTTPS的区别HTTP和HTTPS的主要区别在于HTTP协议传递的是明文数据，而HTTPS传递的是加密过的数据，也就是说HTTPS更具有安全性。也正由HTTPS需要保证安全性，所以它的性能要比HTTP差一点。 单说安全性肯定是不够的，我打算扩展讲一下HTTPS是怎么解决安全性问题的，通过这些HTTP没有机制，反映出HTTPS与HTTP的区别。下面尝试把HTTPS加密的过程推导出来。推导过程不涉及复杂的实现细节： 如何安全地进行数据传输？假设现在A和B要进行安全的通信，那么究竟怎样才算是安全的通信？很自然地会想到：A和B之间传递数据，这些数据只有A和B才看得懂，中间人就算截取了信息但也看不懂，这才算得上安全。 安全通信的处理手段：为了能让A和B才能看懂，就必须要对数据进行加密，而且首先想到的就是对称加密。对称加密的意思是A和B各持有一个相同的密钥，它们传递信息时会用密钥给信息加密，在消息到达端给消息解密，完成安全通信。 在对称加密中又会涉及到加密算法的选择问题。现实世界中，通常是多个客户端面向一个服务器的情况，不可能让每个客户端和服务器之间都采用相同的加密算法，如果是这样那和没加密差不多。所以注定每个客户端和服务器之间都会采用不同的加密方式。 如何让每个客户端与服务器之间都采用不同的加密方式？要想对不同的机器使用不同的加密方式，最直接想到的就是使用随机数。也就说客户端和服务器之间每次都基于一个随机数产生加密算法。（具体实现时为了保证随机，用到还不止一个随机数） 这个产生加密算法的过程称之为协商，现在问题是协商的过程是透明的，也就是说中间人可以截获协商的过程，从而知道我们的加密方式。为了解决这个问题，我们需要对协商的过程进行加密。 如何对协商的过程进行加密？之所以能来到这一步，是因为我们一开始就选择使用了对称加密，也就说一开始的对称加密导致了现在的问题，所以这时我们不能再使用对称加密了，否则会陷入死循环。 在密码学领域，还有一种加密过程叫非对称加密，它的逻辑是这样的：通信双方一方持有私钥，一方持有公钥，经过私钥加密的信息，都能通过公钥进行解密。但是经过公钥加密的数据，只有私钥可以解密。 按照非对称加密的规则，我们让服务器持有私钥，让客户端持有公钥。这样就能保证客户端给服务器发送消息的时候是安全的（相反，服务器给客户端发送消息就是不安全的），我们可以把协商时重要的逻辑安排在客户端给服务器发送信息的过程中，从而保证了协商过程的安全性。 客户端如何获得公钥？现在用非对称加密算法解决了协商的安全问题，但是非对称加密的前提是客户端需要获得公钥，这又是一个问题了，客户端与服务器打交道之前是互不知道双方身份的，怎么才能让客户端获得公钥呢？ 也就只有两种办法： 客户端向服务器要公钥 客户端向一个远程的公共服务器获取公钥 方法2显然是不行的，尚且不说多了一个访问节点，如何找到公共服务器的地址也是一个待解决的问题，所以还是使用方法1。 但是方法1存在一个问题：如果中间人把服务器发送给客户端的公钥调包了怎么办？也就是说客户端无法知道发送公钥的是否是正真的服务器。 引入第三方机构解决问题客户端无法辨识服务端和中间人的问题称为“身份验证”问题，也就是说我们需要为服务器向客户端发送公钥的过程进行加密。 这下完了，之前我们因遇到对称加密的瓶颈选择了非对称加密，现在使用非对称加密也遇到了瓶颈。显然这两种加密方式都是不可用的了，否则会再次陷入死循环。 接下来我们只好通过第三方机构的介入，解决这个问题。首先我们自己保存有第三方权威机构的公钥，然后第三方机构使用私钥对服务器将要发送给客户端的公钥进行加密，客户端接收到这个经加密的公钥后（数字证书），就能通过自己保存的第三方机构公钥进行解密。 到这里为止，我们解释了HTTPS中使用到的对称加密，非对称加密，CA，数字证书的概念，但是还差一个叫数字签名的概念没有解释。 在现实生活中，CA不单止会给我们正常公司发放证书，还会给中间人的坏公司发放证书，如果中间人把发放的证书调包了怎么办？这时我们仍能用CA的私钥进行解密，但是证书已经被调包了。 那么客户端怎样验证证书的真伪呢？答案是证书本身会告诉客户端如何辨认真伪。比方说证书上面有一个证书编号，还有一个如何计算证书编号的方法，客户端可以根据计算证书编号的方法计算出自己要获得的证书的编号，然后把这个编号和证书上的编号进行比对，如果一样证明没有被调包。 这里的证书编号指的就是数字签名，证书指的就是数字证书。 总结一下HTTPS：HTTPS想要保证客户端与服务器之间的通信安全，就得使用对称加密算法进行加密。协商对称加密算法的过程通过非对称加密算法来保证。在非对称加密算法中，客户端获得公钥的过程需要第三方机构（CA）通过颁发数字证书保证安全性。 总得来说通过这一系列机制协商出了一个对称加密算法后，客户端与服务器之间就能通过该算法进行安全的通信了 TCP消息和UDP的主要区别 Epoll比起select/poll，主要优化点在哪里？ Post和Get有什么区别？ 接收时，如何确定一个HTTP消息已经读取完毕 从一个命令行下载一个网页，会涉及哪些网络协议？（DNS，TCP，HTTP，如果有ARP和SSL更好） HTTP/2主要优化点 \\1. C++中具体是怎么实现多态的？构造函数可以是虚函数吗？构造函数可以调用虚函数吗？编译器发现一个类中有虚函数，便会立即为此类生成虚函数表 vtable。虚函数表的各表项为指向对应虚函数的指针。构造函数不可以是虚函数，也不能调用虚函数，因为此时虚函数表还未生成。 \\2. 操作系统中进程、线程的区别，进程间通信通信的方式？进程： 进程是资源（CPU、内存等）分配的基本单位，具有一定功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。线程：线程是进程的一个实体，是独立运行和独立调度的基本单位（CPU上真正运行的是线程）。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。进程通信的方式：管道，有名管道，信号量，消息队列，信号,共享内存,套接字. \\3. python中的多线程能充分利用多核CPU吗？如果要充分利用的话应该怎么做？python的多线程不能充分利用多CPU，因为python解释器有一个全局锁；要想利用多CPU只能使用多进程模型，或者使用C++ \\4. http属于OSI分层协议中的哪一层？TCP/UDP是属于哪一层？TCP的三次握手的过程是怎样的？为什么要有三次握手？http属于应用层，TCP/UDP属于传输层； 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。 \\5. TCP怎么实现可靠传输的？ TCP滑动窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 不同地区的用户的请求怎么打到附近的地区呢？答：讲了CDN 补充： CDN 将内容资源分发到位于多个地理位置机房中的服务器上，这样我们在访问内容资源的时候，不用访问源服务器。而是直接访问离我们最近的 CDN 节点 ，这样一来就省去了长途跋涉的时间成本，从而实现了网络加速。 找到离用户最近的 CDN 节点是由 CDN 的全局负载均衡器（Global Sever Load Balance，GSLB）负责的。 那 GSLB 是在什么时候起作用的呢？在回答这个问题前，我们先来看看在没有 CDN 的情况下，访问域名时发生的事情。 在没有 CDN 的情况下，当我们访问域名时，DNS 服务器最终会返回源服务器的地址。 比如，当我们在浏览器输入 www.xiaolin.com 域名后，在本地 host 文件找不到域名时，客户端就会访问本地 DNS 服务器。 这时候: 如果本地 DNS 服务器有缓存该网站的地址，则直接返回网站的地址； 如果没有就通过递归查询的方式，先请求根 DNS，根 DNS 返回顶级 DNS（.com）的地址；再请求 .com 顶级 DNS 得到 xiaolin.com 的域名服务器地址，再从 xiaolin.com 的域名服务器中查询到 www.xiaolin.com 对应的 IP 地址，然后返回这个 IP 地址，同时本地 DNS 缓存该 IP 地址，这样下一次的解析同一个域名就不需要做 DNS 的迭代查询了。 但加入 CDN 后就不一样了。 会在 xiaolin.com 这个 DNS 服务器上，设置一个 CNAME 别名，指向另外一个域名 www.xiaolin.cdn.com，返回给本地 DNS 服务器。 接着继续解析该域名，这个时候访问的就是 xiaolin.cdn.com 这台 CDN 专用的 DNS 服务器，在这个服务器上，又会设置一个 CNAME，指向另外一个域名，这次指向的就是 CDN 的 GSLB。 接着，本地 DNS 服务器去请求 CDN 的 GSLB 的域名，GSLB 就会为用户选择一台合适的 CDN 节点提供服务，选择的依据主要有以下几点： 看用户的 IP 地址，查表得知地理位置，找相对最近的 CDN 节点； 看用户所在的运营商网络，找相同网络的 CDN 节点； 看用户请求 URL，判断哪一台服务器上有用户所请求的资源； 查询 CDN 节点的负载情况，找负载较轻的节点； GSLB 会基于以上的条件进行综合分析后，找出一台最合适的 CDN 节点，并返回该 CDN 节点的 IP 地址给本地 DNS 服务器，然后本地 DNS 服务器缓存该 IP 地址，并将 IP 返回给客户端，客户端去访问这个 CDN 节点，下载资源。 TCP的close_wait在哪端，如果我们场景中出现了大量的close_wait，你觉得要怎么排查答：被动方，代码逻辑有问题，没close 补充： CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。 所以，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接。 那什么情况会导致服务端的程序没有调用 close 函数关闭连接？这时候通常需要排查代码。 我们先来分析一个普通的 TCP 服务端的流程： 创建服务端 socket，bind 绑定端口、listen 监听端口 将服务端 socket 注册到 epoll epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket 将已连接的 socket 注册到 epoll epoll_wait 等待事件发生 对方连接关闭时，我方调用 close 可能导致服务端没有调用 close 函数的原因，如下。 第一个原因：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。 不过这种原因发生的概率比较小，这种属于明显的代码逻辑 bug，在前期 read view 阶段就能发现的了。 第二个原因：第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。 发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。 第三个原因：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。 发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析 第四个原因：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。 可以发现，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close。 服务端出现大量 TIME_WAIT 状态的原因有哪些？我们先来看一下 TCP 四次挥手的流程吧，看看 TIME_WAIT 状态发生在哪一个阶段。 下面这个图，是由「客户端」作为「主动关闭方」的 TCP 四次挥手的流程。 TCP 四次挥手的流程 从上面我们可以知道，TIME_WAIT 状态是「主动关闭连接方」才会出现的状态。而且 TIME_WAIT 状态会持续 2MSL 时间才会进入到 close 状态。在 Linux 上 2MSL 的时长是 60 秒，也就是说停留在 TIME_WAIT 的时间为固定的 60 秒。 为什么需要 TIME_WAIT 状态？（老八股文了，帮大家复习一波）主要有两个原因： 保证「被动关闭连接」的一方，能被正确的关闭。TCP 协议在关闭连接的四次挥手中，在主动关闭方发送的最后一个 ACK 报文，有可能丢失，这时被动方会重新发 FIN 报文, 如果这时主动方处于 CLOSE 状态 ，就会响应 RST 报文而不是 ACK 报文。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSE。 防止历史连接中的数据，被后面相同四元组的连接错误的接收。TCP 报文可能由于路由器异常而 “迷路”，在迷途期间，TCP 发送端可能因确认超时而重发这个报文，迷途的报文在路由器修复后也会被送到最终目的地，这个原来的迷途报文就称为 lost duplicate。在关闭一个 TCP 连接后，马上又重新建立起一个相同的 IP 地址和端口之间的 TCP 连接，后一个连接被称为前一个连接的化身，那么有可能出现这种情况，前一个连接的迷途重复报文在前一个连接终止后出现，从而被误解成从属于新的化身。为了避免这个情 况， TIME_WAIT 状态需要持续 2MSL，因为这样就可以保证当成功建立一个 TCP 连接的时候，来自连接先前化身的重复报文已经在网络中消逝。 很多人误解以为只有客户端才会有 TIME_WAIT 状态，这是不对的。TCP 是全双工协议，哪一方都可以先关闭连接，所以哪一方都可能会有 TIME_WAIT 状态。 总之记住，谁先关闭连接的，它就是主动关闭方，那么 TIME_WAIT 就会出现在主动关闭方。 什么场景下服务端会主动断开连接呢？如果服务端出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务端主动断开了很多 TCP 连接。 问题来了，什么场景下服务端会主动断开连接呢？ 第一个场景：HTTP 没有使用长连接 第二个场景：HTTP 长连接超时 第三个场景：HTTP 长连接的请求数量达到上限 接下来，分别介绍下。 第一个场景：HTTP 没有使用长连接我们先来看看 HTTP 长连接（Keep-Alive）机制是怎么开启的。 在 HTTP/1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在请求的 header 中添加： Connection: Keep-Alive 然后当服务器收到请求，作出回应的时候，它也被添加到响应中 header 里： Connection: Keep-Alive 这样做，TCP 连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个 TCP 连接。这一直继续到客户端或服务器端提出断开连接。 从 HTTP/1.1 开始， 就默认是开启了 Keep-Alive，现在大多数浏览器都默认是使用 HTTP/1.1，所以 Keep-Alive 都是默认打开的。一旦客户端和服务端达成协议，那么长连接就建立好了。 如果要关闭 HTTP Keep-Alive，需要在 HTTP 请求或者响应的 header 里添加 Connection:close 信息，也就是说，只要客户端和服务端任意一方的 HTTP header 中有 Connection:close 信息，那么就无法使用 HTTP 长连接的机制。 关闭 HTTP 长连接机制后，每次请求都要经历这样的过程：建立 TCP -&gt; 请求资源 -&gt; 响应资源 -&gt; 释放连接，那么此方式就是 HTTP 短连接，如下图： HTTP 短连接 在前面我们知道，只要任意一方的 HTTP header 中有 Connection:close 信息，就无法使用 HTTP 长连接机制，这样在完成一次 HTTP 请求/处理后，就会关闭连接。 问题来了，这时候是客户端还是服务端主动关闭连接呢？ 在 RFC 文档中，并没有明确由谁来关闭连接，请求和响应的双方都可以主动关闭 TCP 连接。 不过，根据大多数 Web 服务的实现，不管哪一方禁用了 HTTP Keep-Alive，都是由服务端主动关闭连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。 客户端禁用了 HTTP Keep-Alive，服务端开启 HTTP Keep-Alive，谁是主动关闭方？ 当客户端禁用了 HTTP Keep-Alive，这时候 HTTP 请求的 header 就会有 Connection:close 信息，这时服务端在发完 HTTP 响应后，就会主动关闭连接。 为什么要这么设计呢？HTTP 是请求-响应模型，发起方一直是客户端，HTTP Keep-Alive 的初衷是为客户端后续的请求重用连接，如果我们在某次 HTTP 请求-响应模型中，请求的 header 定义了 connection：close 信息，那不再重用这个连接的时机就只有在服务端了，所以我们在 HTTP 请求-响应这个周期的「末端」关闭连接是合理的。 客户端开启了 HTTP Keep-Alive，服务端禁用了 HTTP Keep-Alive，谁是主动关闭方？ 当客户端开启了 HTTP Keep-Alive，而服务端禁用了 HTTP Keep-Alive，这时服务端在发完 HTTP 响应后，服务端也会主动关闭连接。 为什么要这么设计呢？在服务端主动关闭连接的情况下，只要调用一次 close() 就可以释放连接，剩下的工作由内核 TCP 栈直接进行了处理，整个过程只有一次 syscall；如果是要求 客户端关闭，则服务端在写完最后一个 response 之后需要把这个 socket 放入 readable 队列，调用 select / epoll 去等待事件；然后调用一次 read() 才能知道连接已经被关闭，这其中是两次 syscall，多一次用户态程序被激活执行，而且 socket 保持时间也会更长。 因此，当服务端出现大量的 TIME_WAIT 状态连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive，因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。 针对这个场景下，解决的方式也很简单，让客户端和服务端都开启 HTTP Keep-Alive 机制。 第二个场景：HTTP 长连接超时HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。 HTTP 长连接可以在同一个 TCP 连接上接收和发送多个 HTTP 请求/应答，避免了连接建立和释放的开销。 可能有的同学会问，如果使用了 HTTP 长连接，如果客户端完成一个 HTTP 请求后，就不再发起新的请求，此时这个 TCP 连接一直占用着不是挺浪费资源的吗？ 对没错，所以为了避免资源浪费的情况，web 服务软件一般都会提供一个参数，用来指定 HTTP 长连接的超时时间，比如 nginx 提供的 keepalive_timeout 参数。 假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。 HTTP 长连接超时 当服务端出现大量 TIME_WAIT 状态的连接时，如果现象是有大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据，那么大概率就是因为 HTTP 长连接超时，导致服务端主动关闭连接，产生大量处于 TIME_WAIT 状态的连接。 可以往网络问题的方向排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收到，以至于 HTTP 长连接超时。 第三个场景：HTTP 长连接的请求数量达到上限Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。 比如 nginx 的 keepalive_requests 这个参数，这个参数是指一个 HTTP 长连接建立之后，nginx 就会为这个连接设置一个计数器，记录这个 HTTP 长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。 keepalive_requests 参数的默认值是 100 ，意味着每个 HTTP 长连接最多只能跑 100 次请求，这个参数往往被大多数人忽略，因为当 QPS (每秒请求数) 不是很高时，默认值 100 凑合够用。 但是，对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候就 nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态。 针对这个场景下，解决的方式也很简单，调大 nginx 的 keepalive_requests 参数就行。 TIME_WAIT 状态过多有什么危害？过多的 TIME-WAIT 状态主要的危害有两种： 第一是占用系统资源，比如文件描述符、内存资源、CPU 资源等； 第二是占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 net.ipv4.ip_local_port_range参数指定范围。 客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。 如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。具体可以看我这篇文章：客户端的端口可以重复使用吗？ 因此，客户端（发起连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务端建立连接的话，当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务端建立连接了。 不过，即使是在这种场景下，只要连接的是不同的服务端，端口是可以重复使用的，所以客户端还是可以向其他服务端发起连接的，这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突。 如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源等。 如何优化 TIME_WAIT 状态？这里给出优化 TIME-WAIT 的几个方式，都是有利有弊： 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项； net.ipv4.tcp_max_tw_buckets 程序中使用 SO_LINGER ，应用强制使用 RST 关闭。 方式一：net.ipv4.tcp_tw_reuse 和 tcp_timestamps 开启 tcp_tw_reuse，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。 有一点需要注意的是，tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。 net.ipv4.tcp_tw_reuse = 1 使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即 net.ipv4.tcp_timestamps=1（默认即为 1） 这个时间戳的字段是在 TCP 头部的「选项」里，它由一共 8 个字节表示时间戳，其中第一个 4 字节字段用来保存发送该数据包的时间，第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。 由于引入了时间戳，可以使得重复的数据包会因为时间戳过期被自然丢弃，因此 TIME_WAIT 状态才可以被复用。 方式二：net.ipv4.tcp_max_tw_buckets 这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置，这个方法比较暴力。 net.ipv4.tcp_max_tw_buckets = 18000 方式三：程序中使用 SO_LINGER 我们可以通过设置 socket 选项，来设置调用 close 关闭连接行为。 struct linger so_linger; so_linger.l_onoff = 1; so_linger.l_linger = 0; setsockopt(s, SOL_SOCKET, SO_LINGER, &amp;so_linger,sizeof(so_linger)); 如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。 但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。 前面介绍的方法都是试图越过 TIME_WAIT状态的，这样其实不太好。虽然 TIME_WAIT 状态持续的时间是有一点长，显得很不友好，但是它被设计来就是用来避免发生乱七八糟的事情。 《UNIX网络编程》一书中却说道：TIME_WAIT 是我们的朋友，它是有助于我们的，不要试图避免这个状态，而是应该弄清楚它。 如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT。 服务端出现大量 CLOSE_WAIT 状态的原因有哪些？还是拿这张图： TCP 四次挥手的流程 从上面这张图我们可以得知，CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。 所以，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接。 那什么情况会导致服务端的程序没有调用 close 函数关闭连接？这时候通常需要排查代码。 我们先来分析一个普通的 TCP 服务端的流程： 创建服务端 socket，bind 绑定端口、listen 监听端口 将服务端 socket 注册到 epoll epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket 将已连接的 socket 注册到 epoll epoll_wait 等待事件发生 对方连接关闭时，我方调用 close 可能导致服务端没有调用 close 函数的原因，如下。 第一个原因：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。 不过这种原因发生的概率比较小，这种属于明显的代码逻辑 bug，在前期 read view 阶段就能发现的了。 第二个原因：第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。 发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。 第三个原因：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。 发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析 第四个原因：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。 可以发现，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close。面试问题 1）TCP/IP协议 1）三次握手/四次挥手过程 2）TIME_WAIT状态 1）主动关闭/被动关闭 2）需要的原因 3）缓解措施 4）有没有方式不出现TIME_WAIT状态 3）RST出现的场景 4）滑动窗口2）网络编程 1）EPOLL/SELECT的区别 2）边沿触发/水平触发 3）事件触发的场景 1）读事件 有哪些场景 2）写事件 有哪些场景 4）READ调用返回值场景 1）0 2）-1 3）&gt;0 5）UDP客户端可以CONNECT不，那CONNECT和不CONNECT有啥区别3）后台编程 1）FORK的用途，FORK区分父子进程方式 2）进程间通信方式 3）僵尸进程 4）内存模型，有哪些段构成 5）进程/线程/协程的区别4）常见中间件 1）MYSQL 1）为啥不建议SELECT * 2）覆盖索引 3）分页优化 2）ZOOKEEPER 1）有哪些WATCH以及对应唤醒事件 3）KAFKA 1）分区分服 2）生产者 3）消费者5）语言 1）JAVA语言 1）内存管理6）设计模式 1）单例模式7）项目中的难点、挑战点 22989-腾讯云网络后台开发工程师(CSIG全资子公司)（西安） 建议用online ddl（网上可以查）修改，就是逗号后面的参数另外，添加字段要加上after，根据表结构看看fromWanIp适合在哪个字段后ALTER TABLE cEip ALTER COLUMN ispId SET DEFAULT -1, ALGORITHM=INPLACE, LOCK=NONE; HTTP 长连接和 TCP 长连接有什么区别？其实就是HTTP 的 Keep-Alive 和 TCP 的 Keepalive 有什么区别？事实上，这两个完全是两样不同东西，实现的层面也不同： HTTP 的 Keep-Alive，是由应用层（用户态） 实现的，称为 HTTP 长连接； TCP 的 Keepalive，是由 TCP 层（内核态） 实现的，称为 TCP 保活机制； 接下来，分别说说它们。 HTTP 的 Keep-AliveHTTP 协议采用的是「请求-应答」的模式，也就是客户端发起了请求，服务端才会返回响应，一来一回这样子。 请求-应答 由于 HTTP 是基于 TCP 传输协议实现的，客户端与服务端要进行 HTTP 通信前，需要先建立 TCP 连接，然后客户端发送 HTTP 请求，服务端收到后就返回响应，至此「请求-应答」的模式就完成了，随后就会释放 TCP 连接。 一个 HTTP 请求 如果每次请求都要经历这样的过程：建立 TCP -&gt; 请求资源 -&gt; 响应资源 -&gt; 释放连接，那么此方式就是 HTTP 短连接，如下图： HTTP 短连接 这样实在太累人了，一次连接只能请求一次资源。 能不能在第一个 HTTP 请求完后，先不断开 TCP 连接，让后续的 HTTP 请求继续使用此连接？ 当然可以，HTTP 的 Keep-Alive 就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 HTTP 长连接。 HTTP 长连接 HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。 怎么才能使用 HTTP 的 Keep-Alive 功能？ 在 HTTP 1.0 中默认是关闭的，如果浏览器要开启 Keep-Alive，它必须在请求的包头中添加： Connection: Keep-Alive 然后当服务器收到请求，作出回应的时候，它也添加一个头在响应中： Connection: Keep-Alive 这样做，连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接。这一直继续到客户端或服务器端提出断开连接。 从 HTTP 1.1 开始， 就默认是开启了 Keep-Alive，如果要关闭 Keep-Alive，需要在 HTTP 请求的包头里添加： Connection:close 现在大多数浏览器都默认是使用 HTTP/1.1，所以 Keep-Alive 都是默认打开的。一旦客户端和服务端达成协议，那么长连接就建立好了。 HTTP 长连接不仅仅减少了 TCP 连接资源的开销，而且这给 HTTP 流水线技术提供了可实现的基础。 所谓的 HTTP 流水线，是客户端可以先一次性发送多个请求，而在发送过程中不需先等待服务器的回应，可以减少整体的响应时间。 举例来说，客户端需要请求两个资源。以前的做法是，在同一个 TCP 连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。HTTP 流水线机制则允许客户端同时发出 A 请求和 B 请求。 右边为 HTTP 流水线机制 但是服务器还是按照顺序响应，先回应 A 请求，完成后再回应 B 请求。 而且要等服务器响应完客户端第一批发送的请求后，客户端才能发出下一批的请求，也就说如果服务器响应的过程发生了阻塞，那么客户端就无法发出下一批的请求，此时就造成了「队头阻塞」的问题。 可能有的同学会问，如果使用了 HTTP 长连接，如果客户端完成一个 HTTP 请求后，就不再发起新的请求，此时这个 TCP 连接一直占用着不是挺浪费资源的吗？ 对没错，所以为了避免资源浪费的情况，web 服务软件一般都会提供 keepalive_timeout 参数，用来指定 HTTP 长连接的超时时间。 比如设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会启动一个定时器，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来释放该连接。 HTTP 长连接超时 TCP 的 KeepaliveTCP 的 Keepalive 这东西其实就是 TCP 的保活机制，它的工作原理我之前的文章写过，这里就直接贴下以前的内容。 如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。 所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，这个工作是在内核完成的。 TCP 保活机制 注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 SO_KEEPALIVE 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。 总结HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。 TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。 HTTPS 一定安全可靠吗？客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手。 具体过程如下： 客户端向服务端发起 HTTPS 建立连接请求时，然后被「假基站」转发到了一个「中间人服务器」，接着中间人向服务端发起 HTTPS 建立连接请求，此时客户端与中间人进行 TLS 握手，中间人与服务端进行 TLS 握手； 在客户端与中间人进行 TLS 握手过程中，中间人会发送自己的公钥证书给客户端，客户端验证证书的真伪，然后从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给中间人，中间人使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（A），后续客户端与中间人通信就用这个对称加密密钥来加密数据了。 在中间人与服务端进行 TLS 握手过程中，服务端会发送从 CA 机构签发的公钥证书给中间人，从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给服务端，服务端使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（B），后续中间人与服务端通信就用这个对称加密密钥来加密数据了。 后续的通信过程中，中间人用对称加密密钥（A）解密客户端的 HTTPS 请求的数据，然后用对称加密密钥（B）加密 HTTPS 请求后，转发给服务端，接着服务端发送 HTTPS 响应数据给中间人，中间人用对称加密密钥（B）解密 HTTPS 响应数据，然后再用对称加密密钥（A）加密后，转发给客户端。 从客户端的角度看，其实并不知道网络中存在中间人服务器这个角色。 那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据。相当于，中间人能够 “偷看” 浏览器与服务端之间的 HTTPS 请求和响应的数据。 但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。 中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。 如果用户执意点击「继续浏览此网站」，相当于用户接受了中间人伪造的证书，那么后续整个 HTTPS 通信都能被中间人监听了。 所以，这其实并不能说 HTTPS 不够安全，毕竟浏览器都已经提示证书有问题了，如果用户坚决要访问，那不能怪 HTTPS ，得怪自己手贱。 客户端是如何验证证书的？接下来，详细说一下实际中数字证书签发和验证流程。 如下图图所示，为数字证书签发和验证流程： 当服务端向 CA 机构申请证书的时候，CA 签发证书的过程，如上图左边部分： 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值； 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名； 最后将 Certificate Signature 添加在文件证书上，形成数字证书； 客户端校验服务端的数字证书的过程，如上图右边部分： 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1； 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ； 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。 但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级： 对于这种三级层级关系的证书的验证过程如下： 客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。 请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。 “GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任 baidu.com 证书。 在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。 操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多： 这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示： 如果你的电脑中毒了，被恶意导入了中间人的根证书，那么在验证中间人的证书的时候，由于你操作系统信任了中间人的根证书，那么等同于中间人的证书是合法的。 这种情况下，浏览器是不会弹出证书存在问题的风险提醒的。 这其实也不关 HTTPS 的事情，是你电脑中毒了才导致 HTTPS 数据被中间人劫持的。 所以，HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全。 为什么抓包工具能截取 HTTPS 数据？抓包工具 Fiddler 之所以可以明文看到 HTTPS 数据，工作原理与中间人一致的。 对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理: 中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份； 中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥； 中间人要拿到私钥只能通过如下方式： 去网站服务端拿到私钥； 去CA处拿域名签发私钥； 自己签发证书，且被浏览器信任； 不用解释，抓包工具只能使用第三种方式取得中间人的身份。 使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用。 Fiddler 能够抓包的关键是客户端会往系统受信任的根证书列表中导入 Fiddler 生成的证书，而这个证书会被浏览器信任，也就是 Fiddler 给自己创建了一个认证中心 CA。 客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。 如何避免被中间人抓取数据？我们要保证自己电脑的安全，不要被病毒乘虚而入，而且也不要点击任何证书非法的网站，这样 HTTPS 数据就不会被中间人截取到了。 当然，我们还可以通过 HTTPS 双向认证来避免这种问题。 一般我们的 HTTPS 是单向认证，客户端只会验证了服务端的身份，但是服务端并不会验证客户端的身份。 如果用了双向认证方式，不仅客户端会验证服务端的身份，而且服务端也会验证客户端的身份。 服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信。 客户端连接一个不存在的 IP 地址，会发生什么？客户端连接一个存在的 IP 地址但是端口不存在，会发生什么？PS：这里的「连接」指的是 TCP 连接。 Q1：客户端连接一个不存在的 IP 地址，会发生什么？ 这个问题要分两种情况来思考，不同的情况得到的结论是不同的。 第一个情况：目标 IP 地址和客户端的 IP 地址是同一个局域网（网络号相同）。 第一种情况，客户端无法发出 SYN 报文，主要卡在数据链路层。 因为目标地址不存在 IP 地址，客户端的内核在发 arp 请求的时候，广播询问这个目标 IP 地址是谁的，由于网络中不存在该目标 IP 地址，所以没有设备应答客户端的 arp 请求。 由于客户端无法拿到目标设备的 MAC，这样就没办法组装 MAC 头的信息，所以 SYN 报文无法发送出去。 第二个情况：目标 IP 地址和客户端的 IP 地址不在同一个局域网（网络号不同）。 第二种情况，客户端会先将 SYN 报文发给路由器，然后路由器会继续转发。 由于目标 IP 地址是不存在的，该 SYN 报文会在网络中消亡，因此客户端是不会收到对 SYN 报文的确认报文的，接着客户端会触发超时重传，重传 SYN 报文，直到重传的次数达到最大次数后，客户端的连接就会被释放。 可能有的同学好奇，为什么这种情况客户端的 SYN 报文可以发出来？ 因为当目标 IP 地址和客户端 IP 地址不在同一个局域网时，客户端客通过路由表的判断，判断到下一步是要将网络报文发送给路由器。 这时候数据链路层的 arp 请求，会广播询问 IP 地址（路由器 IP 地址）是谁的，路由器发现是自己的 IP 地址，于是就会将自己的 MAC 地址告诉客户端。 然后客户端的网络报文中 MAC 头的「目标 MAC 地址」填入的就是路由器的 MAC 地址，于是 SYN 报文就可以发送出去了。 由于目标 MAC 地址是路由器的，所以就会被路由器接收，然后路由器继续通过路由表的判断，转发给下一个路由器，直到找到目标设备。 Q2：客户端连接一个存在的 IP 地址但是端口不存在，会发生什么？ 客户端连接的目标 IP 地址是存在的，那么 SYN 报文就能正确的抵达到目标设备。 目标设备收到 SYN 报文后，发现端口号并没有被进程监听，这时候目标设备的内核就会回 RST 报文。 客户端收到 RST 报文后，就会释放连接。 ……. 至此，结论已说完。 不知道你们会不会觉得信息量很大，如果你觉得信息量大，那么你该补补网络知识啦。 第二题不难，难在的是第一题，如果你没有把两台电脑之间是怎么通信的搞清楚，那么你是无从下手回答的，所以建立好体系化的网络知识，面对这类的场景题目，就能做到举一反三了。 最近比较忙，偷懒了，没有画图，如果哪里没理解的，可以先看我以前写的这篇文章：探究！一个数据包在网络中的心路历程，有详细讲解每一层是怎么封装头部的，以及路由表是怎么判断的。 最后再提一个问题：****客户端发送了一个目标 IP 地址存在但是端口不存在的 UDP 报文，UDP 没有像 TCP 那样的 RST 报文，此时会发生什么？ 网络 TCP消息和UDP的主要区别 Epoll比起select/poll，主要优化点在哪里？ Post和Get有什么区别？ 接收时，如何确定一个HTTP消息已经读取完毕 从一个命令行下载一个网页，会涉及哪些网络协议？（DNS，TCP，HTTP，如果有ARP和SSL更好） HTTP/2主要优化点 \\1. C++中具体是怎么实现多态的？构造函数可以是虚函数吗？构造函数可以调用虚函数吗？编译器发现一个类中有虚函数，便会立即为此类生成虚函数表 vtable。虚函数表的各表项为指向对应虚函数的指针。构造函数不可以是虚函数，也不能调用虚函数，因为此时虚函数表还未生成。 \\2. 操作系统中进程、线程的区别，进程间通信通信的方式？进程： 进程是资源（CPU、内存等）分配的基本单位，具有一定功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。线程：线程是进程的一个实体，是独立运行和独立调度的基本单位（CPU上真正运行的是线程）。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。进程通信的方式：管道，有名管道，信号量，消息队列，信号,共享内存,套接字. python中的多线程能充分利用多核CPU吗？如果要充分利用的话应该怎么做？python的多线程不能充分利用多CPU，因为python解释器有一个全局锁；要想利用多CPU只能使用多进程模型，或者使用C++ http属于OSI分层协议中的哪一层？TCP/UDP是属于哪一层？TCP的三次握手的过程是怎样的？为什么要有三次握手？http属于应用层，TCP/UDP属于传输层； 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。 TCP怎么实现可靠传输的？ TCP滑动窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。","link":"/2022/10/08/technology/%E9%9D%A2%E8%AF%95%E5%85%AB%E8%82%A1%E4%B9%8B%E7%BD%91%E7%BB%9C/"},{"title":"股票资金管理","text":"股票资金管理理财配置富人投资比例： 家庭总的可支配收入减去家庭每年必须支出的费用（房贷，车贷，生活费）（也可以按月算），然后剩下的钱按下面的比例进行配置： 稳定无风险投资/股票基金有一定风险的/风投(高风险高收益)： 富人：6/3/1或5/4/1 普通人可以按：6/4, 7/3 来配置。 主动、被动投资指数型：沪深300ETF， 上证50ETF， 不要增强型, 长年可以跑赢大盘 基金也分：长期持有或波段操作，把k线用上来。 仓位管理基金分两仓 股票初期分四仓，每仓投入四分之一 投资计划胜兵先胜而后求战，败兵先战而后求胜年度计划-》月度计划-》分解短线!=高风险!=低收益!=不稳定长线!=低风险!=高收益!=稳定做长线还是短线取决于你的计划，你的精力投入。 先长后短 第一阶段亢龙有悔-大盘上用上涨回调更好，个股不确定因素太多 胜率80%， 盈亏比5：1， 所以机会很少 个股上如果用，找上升通道的， 慎用，成功率不高 个股两个形态：1. 底部反弹型：极速下跌，三根阴，有跳空更好，至少有一根大阴线， 在熊市末期反抽。 大趋势上涨，回调时出现，可以用。 大盘上找模型，个股上选：在上证50或沪深300成分股选， 第四日开盘买入 阶段一：无脑拿十天卖出 空间洗盘：低开高收不正常，是强庄所为 要点精讲补充条件（越像标准模型越好，以下条件越多符合越好）： 小阴线最好不被大阴线包含：实体被包含，最低价–最高价之间也被包含，不好， 拿不到十天 小阴线与大阴线对比越明显越好 大阴线最好跳空低开（实体不接就可以） 阳线的实体最好偏小， 如果太大，后续涨幅可能不会太大 全部3根k线的上影线都不要太长 卖点在大盘和个股上看都可以，有一个出现就算： 5日或10日内大阳线收盘价 任意阴线 止损设置： 跌破三根k线的最低价， 适用于大盘 个人感悟： 适合基本面没问题，蓝筹股，盘整震荡的个股 越不符合标准模型，拿的时间越短 要分仓，要设置止损，提前做好交易计划，根据和模型的匹配度来大致确定拿多久 扩展模型：七星落长空，一般在行情底部，直接用在个股上，不管阴线阳线的大小，次日开盘买入。不管三阴之前是啥。涨了就能卖， 不设止损。一般出现了大多是底部， 如果要设止损，就设在这段k线的最低价 纯时间理论，只看时间，只看阴阳。阴阳真假都能用， 大小也无所谓， 高开低开都行， 位置注意要在一段下跌后的底部，短线抄底，吃到利润就走。 胜率，盈亏比 价值投资与技术分析优劣 风险识别，量价关系诱多阳线 经常在顶部出现，物极必反的疯狂拉升 缩量的大阳线，相比昨天 阳线变动更大，但是量能反而小了 技术面和基本面结合选公司既要有热点还有看看有没有实力 上涨过程中抄底，不要在下跌过程抄底，买在底部也不一定涨，可能是横盘很久。应该在上涨突破时买入。 基金就买沪深300和上证50， 不要增强，场内可以做波段。 被套和拿不住 要有交易计划，包含：买点，卖点（根据行情，时间，空间），止损点，难点是找卖点。 上涨拿不住，计算预期涨幅， 移动止盈 葛式八法下跌、盘整过程中不买，上涨过程才买，才加仓 快10， 慢60 买点一周k线 在沪深300指数上用很不错，基金也可以做波段 卖点1， 物极必反的急速拉升之后，价格远离价值均线， 买点二，卖点二分仓：至少分四仓，每只股票至少分两次买入 加仓：上涨才加 任何一根k线收盘价不能突破到慢速均线下方， 开盘价，下影线可以突破，不要紧。 买点3弱势回调 ![image-20211216175700361](/Users/charles/Library/Application Support/typora-user-images/image-20211216175700361.png) 买点4 尽量不做， 短线博反弹， 别勉强 总结没有买点尽量不要勉强，分仓买入，做好止损计划 行情刚开始不容易出现急速拉升，不会太快翻转 止损 初始止损 行情止损 再推止损 日线神奇均线组合 风险识别，日线上高位阴包阳长线操作思路，避免无意义的亏损 短线精髓：买卖点要精准 长线精髓：买卖点要确定,不要没事天天看，别给自己找麻烦，看周线就只看周线 仓位管理，目的规避风险 分批建仓，别一上来就重仓 股票至少分四仓，进一步可以分十仓，每只股票分两到三次买入 加仓的唯一原则：顺势加仓 中线过程中可以再日线级别做加仓减仓。反向亢龙有悔可以减仓 神龙摆尾目标价位是涨停板收盘价*1.5 止损价格是涨停板开盘价 第一段的横盘超过一个月，第二个横盘一般超过一周，出现阳线，成交量必须比前一天明显放大 分仓投入+分批建仓+过程中推止损，有条件加仓或减仓 交易计划让你心里踏实，有理有据，不是赌徒，事后回顾复盘 量价时空 箱体理论：收盘价跌破或涨过箱体上下沿。箱体上下沿是最高价和最低价 箱体等高上下移 空间理论在个股上不好用，用在大盘上比较好 神龙摆尾222个交易日 买入后的实时价格探到涨停板上沿就卖出。 高位横盘要缩量 以逸待劳，主力洗盘 一箭双雕，主力中继洗盘,后续极速拉升 时间 空间理论在个股上不好用，用在大盘上比较好，越大的盘子越有效 四次回踩通道下沿不破，大概率往上突破 再谈资金管理 学到一个理论，先加自选股，模拟盘，跟踪观察，记下来验证 分仓，初期至少分四仓，后续可以考虑十仓 一只股票再分两三次买入 顺势加仓","link":"/2021/06/08/technology/fin/%E8%82%A1%E7%A5%A8%E8%B5%84%E9%87%91%E7%AE%A1%E7%90%86/"},{"title":"制定投资计划","text":"确定投资理财组合永久组合上世纪 80 年代，美国的专业投资人哈利·布朗就提出了永久组合，它以相等的权重，配置于四类非常常规并且“永久”的资产：25% 的股票、25% 的国债、25% 的黄金和 25% 的现金。股票和国债，我们在介绍股债组合的时候都熟悉了，新加入的黄金则是一把对抗通货膨胀的“利器”，而现金可以最大程度上削弱风险，并留出流动资金用沪深 300 指数代表股票资产，上证 5 年国债指数代表债券资产，黄金资产则用黄金期货指数来代表，现金资产呢，我们使用货币基金 耶鲁组合。我们用“万得 - 普通股票型基金指数”代表中国的主动股票型基金资产，使用“标普 500 人民币指数”代表美国股票资产，使用上证 5 年国债指数代表债券资产。按 30% 中国主动股基，10% 美国股票资产和 60% 债券的权重在 基金筛选 用基金评级结果进行初步筛选，剔除掉成立时间太短、基金经理近期换过、偏行业或主题型的主动股票基金和被动指数型基金，得到 3 到 5 只符合条件的备选基金； 把这 3 到 5 只基金放入价格比工具，和沪深 300 指数比较，看哪只价格比的曲线斜率更高，走势更平稳。 根据你的风险偏好，选出最适合你的那只基金。 在配置美股资产的时候，我建议直接选被动指数基金，既省心效果也不错投资美股时，投资 QDII 被动指数基金是一个兼顾收益率和便捷性的选择； 实操对于波动性比较小的债基，不同时点的建仓成本变化不大，所以没必要定投，直接一步到位就可以，分批定投反而会错失债券的时间收益。对于波动性比较大的股票型基金，比如说国内的普通股票型基金和标普 500 的指数基金，是可以考虑在 3 个月到半年这样的时间尺度上分批建仓的，因为这样可以平滑掉你的建仓时点选择的风险。另外，如果你的可投现金流是按月收到的，那就没得选，只能是定投，每月收到一笔钱投一笔。 作为普通投资者，只要我们在购买基金的时候进行了充足的分析，是没有必要在平时频繁查看这个配置组合的。我们只需要每隔一个季度，或者在市场出现大幅波动的时候，计算一下基金组合在几类资产上的配置比例是否因为价格的变化偏离过大。如果偏离不多，就可以不用管，如果偏离得比较大了，就把它再平衡一次，重新调回初始比例。 个人投资计划每月平均投资1万（每月6000定投股值+每季度12000的债券）一个季度3万= 3*6000+12000 = 30000 主动型占比30%， 月投入3000： 000803 工银研究精选股票 - 10% (每两周四定投500) 建信信息产业股票 (001070)–10%（每两周四定投500）； 700003 平安策略先锋混合 —10%（每两周四定投500） 混合型占比10% 易方达安心回馈（偏债） 10% （每两周四定投500） 美股 20% 博时标普500ETF联接A(050025 20% （每两周四定投1000） 债券 40% 天弘永利债券A(420002)-10%（每个季度投入3000） 鹏华可转债债券A – 10% （每季度3000） 160513 博时稳健回报债券 – 20%（每季度投入6000） 复盘 每个季度做一次再平衡 每个月检验一次支点： 是否五星评级，最大回撤不能超过15%，基金经理没有变动， 是买点吗遇到买点（后期看涨），买也行，不买也行，不卖 遇到卖点（后期看空），卖也行，不卖也行，不要买","link":"/2021/06/08/technology/fin/%E5%88%B6%E5%AE%9A%E6%8A%95%E8%B5%84%E8%AE%A1%E5%88%92/"},{"title":"技术指标","text":"技术指标均线 10月均线向上，中期指标 30月均线，长期指标 KDJ超买超卖，提示风险 月线 背离是辅助判断，不是买卖点。只是用来更加确认买卖点 MACD月线 以柱线为准，长期稳定 RSI月线，预测未来，不是仅短线用， CCI特定行情下发挥奇效的指标，震荡行情不适用 布林带震荡与趋势的抉择 回调百分百与黄金分割 成交量 趋势线和形态不能创越k线实体 多点相连，跨度适中 三角形必须有个直角边，水平线 缺口理论 均线组合","link":"/2021/06/08/technology/fin/%E6%8A%80%E6%9C%AF%E6%8C%87%E6%A0%87/"}],"tags":[{"name":"sinology","slug":"sinology","link":"/tags/sinology/"},{"name":"writ","slug":"writ","link":"/tags/writ/"},{"name":"softskills","slug":"softskills","link":"/tags/softskills/"},{"name":"read","slug":"read","link":"/tags/read/"},{"name":"cs","slug":"cs","link":"/tags/cs/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"tech","slug":"tech","link":"/tags/tech/"},{"name":"efficiency","slug":"efficiency","link":"/tags/efficiency/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"os","slug":"os","link":"/tags/os/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"ubuntu","slug":"ubuntu","link":"/tags/ubuntu/"},{"name":"centos","slug":"centos","link":"/tags/centos/"},{"name":"data","slug":"data","link":"/tags/data/"},{"name":"ai","slug":"ai","link":"/tags/ai/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"interview","slug":"interview","link":"/tags/interview/"},{"name":"cpp","slug":"cpp","link":"/tags/cpp/"},{"name":"intervew","slug":"intervew","link":"/tags/intervew/"},{"name":"job","slug":"job","link":"/tags/job/"},{"name":"fin","slug":"fin","link":"/tags/fin/"},{"name":"tcp","slug":"tcp","link":"/tags/tcp/"}],"categories":[{"name":"essay","slug":"essay","link":"/categories/essay/"},{"name":"softskills","slug":"softskills","link":"/categories/softskills/"},{"name":"technology","slug":"technology","link":"/categories/technology/"},{"name":"fin","slug":"technology/fin","link":"/categories/technology/fin/"}],"pages":[{"title":"about","text":"","link":"/about/index.html"}]}